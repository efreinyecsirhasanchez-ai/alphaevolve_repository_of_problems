{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ring loading problem"
      ],
      "metadata": {
        "id": "8D8QmJtaBces"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data and verification\n",
        "\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "solution = [(np.float64(0.8928570945587888), np.float64(0.05952382012678484)), (np.float64(0.44586335510090447), np.float64(0.5541366448990955)), (np.float64(0.48270810611962867), np.float64(0.4220537880782024)), (np.float64(0.3333332972264078), np.float64(0.6666667027735921)), (np.float64(0.2619047708053195), np.float64(0.23809522594859156)), (np.float64(0.32137957426389363), np.float64(0.6786204257361064)), (np.float64(0.7381442491666856), np.float64(0.14280815724670945)), (np.float64(0.49999999244019133), np.float64(0.49999999244019133)), (np.float64(0.14280815724670945), np.float64(0.7381442491666856)), (np.float64(0.6786204257361064), np.float64(0.32137957426389363)), (np.float64(0.23809522594859156), np.float64(0.2619047708053195)), (np.float64(0.6666667027735921), np.float64(0.3333332972264078)), (np.float64(0.4220537880782024), np.float64(0.48270810611962867)), (np.float64(0.5541366448990955), np.float64(0.44586335510090447)), (np.float64(0.05952382012678484), np.float64(0.8928570945587888))]\n",
        "\n",
        "\n",
        "def validate_input(u: list[float], v: list[float]):\n",
        "  \"\"\"Validates the input vectors u and v.\"\"\"\n",
        "  if len(u) != len(v):\n",
        "    raise ValueError('Input vectors u and v must have the same length.')\n",
        "  if not all(isinstance(x, (float, int)) for x in u) or not all(\n",
        "      isinstance(x, (float, int)) for x in v\n",
        "  ):\n",
        "    raise ValueError('Input vectors must contain only floats or integers.')\n",
        "  if not all(x \u003e= 0 for x in u) or not all(x \u003e= 0 for x in v):\n",
        "    raise ValueError('Input vectors must be non-negative.')\n",
        "  # Use a small tolerance for floating point comparisons\n",
        "  if not all(ui + vi \u003c= 1.000001 for ui, vi in zip(u, v)):\n",
        "    raise ValueError('Condition u_i + v_i \u003c= 1 must be met for all i.')\n",
        "  if any(np.isnan(x) for x in u) or any(np.isnan(x) for x in v):\n",
        "    raise ValueError('Input vectors cannot contain NaN values.')\n",
        "\n",
        "\n",
        "def compute_alpha_exact(u: list[float], v: list[float]) -\u003e tuple[float, float]:\n",
        "  \"\"\"Computes the smallest possible alpha (the min) for the given input vectors as well as alpha's smooth version.\"\"\"\n",
        "  validate_input(u, v)\n",
        "  m = len(u)\n",
        "  if m == 0:\n",
        "    return 0.0, 0.0\n",
        "\n",
        "  best_alpha = float('inf')\n",
        "\n",
        "  z_choices = [(vi, -ui) for ui, vi in zip(u, v)]\n",
        "  for z in itertools.product(*z_choices):\n",
        "    max_alpha_for_z = 0\n",
        "    if m \u003e 1:\n",
        "      max_alpha_for_z = max(abs(sum(z[:k]) - sum(z[k:])) for k in range(1, m))\n",
        "    best_alpha = min(best_alpha, max_alpha_for_z)\n",
        "\n",
        "  return best_alpha\n",
        "\n",
        "\n",
        "def get_score(params: list[tuple[float, float]], m: int) -\u003e float:\n",
        "  \"\"\"Calculates the score for a given set of (u, v) vector parameters.\"\"\"\n",
        "  assert isinstance(params, list), \"params must be a list\"\n",
        "  assert isinstance(m, int), \"m must be an integer\"\n",
        "  assert len(params) == m, \"Invalid number of parameters\"\n",
        "\n",
        "  u, v = [], []\n",
        "  for item in params:\n",
        "    if not isinstance(item, (tuple, list)) or len(item) != 2:\n",
        "      return -1.0\n",
        "    if not isinstance(item[0], (float, int)) or not isinstance(\n",
        "        item[1], (float, int)\n",
        "    ):\n",
        "      return -1.0\n",
        "    if np.isnan(item[0]) or np.isnan(item[1]):\n",
        "      return -1.0\n",
        "\n",
        "    ui, vi = abs(item[0]), abs(item[1])\n",
        "    s = ui + vi\n",
        "    if s \u003e 1.0:\n",
        "      ui /= s\n",
        "      vi /= s\n",
        "    assert s \u003c 1e9, \"Numerical instability\"\n",
        "    u.append(ui)\n",
        "    v.append(vi)\n",
        "\n",
        "  try:\n",
        "    exact_alpha = compute_alpha_exact(u, v)\n",
        "    return exact_alpha\n",
        "  except (ValueError, OverflowError):\n",
        "    return -1.0\n",
        "\n",
        "get_score(solution, 15)"
      ],
      "metadata": {
        "id": "lRSPCNA4BcFx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt used**\n",
        "\n",
        "Act as an expert in optimization and algorithm design. Your task is to solve the following problem:\n",
        "\n",
        "Given an integer m, find two lists of non-negative floats, u = [u_1, ..., u_m] and v = [v_1, ..., v_m], that satisfy the condition u_i + v_i \u003c= 1 for all i. The goal is to find the lists (u, v) that maximize a value alpha.\n",
        "\n",
        "This alpha is defined as the smallest value for which there exists a sequence z = [z_1, ..., z_m], where each z_i is chosen to be either v_i or -u_i, such that the following inequality holds for all k from 1 to m-1:\n",
        "\n",
        "|sum(z_i for i=1 to k) - sum(z_i for i=k+1 to m)| \u003c= alpha\n",
        "\n",
        "You need to write a search function that takes an integer m and searches for the best lists u and v of that length. The construction you should return is a list of tuples [(u_1, v_1), (u_2, v_2), ..., (u_m, v_m)].\n",
        "\n",
        "Your solution will be evaluated by the following scoring function, which you have access to and can call as many times as you want. The function calculates a smooth version of alpha, which you should aim to maximize.\n",
        "\n",
        "```\n",
        "def get_score(params: list[tuple[float, float]], m: int) -\u003e float:\n",
        "    \"\"\"Calculates the score for a given set of (u, v) vector parameters.\"\"\"\n",
        "    if not isinstance(params, list) or len(params) != m:\n",
        "        return -1.0\n",
        "\n",
        "u, v = [], []\n",
        "for item in params:\n",
        "    ui, vi = abs(item[0]), abs(item[1])\n",
        "    s = ui + vi\n",
        "    if s \u003e 1.0:\n",
        "        ui /= s\n",
        "        vi /= s\n",
        "    u.append(ui)\n",
        "    v.append(vi)\n",
        "\n",
        "try:\n",
        "    # This external function computes the score (smooth_alpha).\n",
        "    exact_alpha = compute_alpha_exact(u, v)\n",
        "    return exact_alpha\n",
        "except (ValueError, OverflowError):\n",
        "    return -1.0\n",
        "```\n",
        "\n",
        "You do not need to implement the get_score or the compute_alpha_exact functions, they are already present in the codebase, you have access to them. Your task is to implement the search function search_for_best_vectors(m). It has 2000 seconds to run. If it hasn't returned after that time, it will be terminated.\n",
        "\n",
        "You can access the previously found best constructions through the best_vectors_10 global variable (where the 10 should be replaced by your m).\n",
        "\n",
        "Big important hint: if your score is between 0.999 and 1.000, or between 1.099 and 1.100, it might be that you are stuck in a big local optima! Scores higher than 1.101 are easily possible, so try your best to get out of that local optimum. It is believed that the optimal score that can be achieved is 1.1111 (which is 10/9), try to aim for that if you can!\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "yYJ_b1FxhAGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initial program used (evolved by an earlier AlphaEvolve experiment on the same problem)\n",
        "\n",
        "def search_for_best_vectors(m: int) -\u003e list[tuple[float, float]]:\n",
        "  \"\"\"Searches for the best (u, v) vectors of length m that maximize alpha.\n",
        "\n",
        "  A simple random search is implemented as a starting point.\n",
        "  \"\"\"\n",
        "  variable_name = f'best_vectors_{m}'\n",
        "  if variable_name in globals():\n",
        "    params = globals()[variable_name]\n",
        "  else:\n",
        "    # Initialize randomly, tending to make u_i + v_i = 1 as per get_score implicit normalization\n",
        "    params = []\n",
        "    for _ in range(m):\n",
        "      ui = np.random.rand()\n",
        "      # Make u_i + v_i = 1 with high probability (e.g., 80%), otherwise allow \u003c 1\n",
        "      vi = (\n",
        "          1.0 - ui\n",
        "          if np.random.rand() \u003c 0.8\n",
        "          else np.random.uniform(0.0, 1.0 - ui)\n",
        "      )\n",
        "      params.append((ui, vi))\n",
        "\n",
        "  best_score = get_score(params, m)\n",
        "  best_params = copy.deepcopy(params)\n",
        "  print(f'Initial score for m={m}: {best_score}')\n",
        "\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Define the objective function for the optimizer.\n",
        "  # It takes a flat numpy array and returns the negative score.\n",
        "  def objective(x, m):\n",
        "    params_list = [(x[i], x[m + i]) for i in range(m)]\n",
        "    score = get_score(params_list, m)\n",
        "    return (\n",
        "        -score if score \u003e 0 else float('inf')\n",
        "    )  # Return a very large value for invalid scores.\n",
        "\n",
        "  x_best = np.array([p[0] for p in best_params] + [p[1] for p in best_params])\n",
        "\n",
        "  # Iterated Local Search (ILS) loop.\n",
        "  total_runtime = np.random.randint(100, 2000)\n",
        "  while time.time() - start_time \u003c total_runtime:\n",
        "    # 1. Perturbation: Hybrid Strategy\n",
        "    x_start = x_best.copy()\n",
        "\n",
        "    perturbation_type = np.random.rand()\n",
        "\n",
        "    # 60% chance: Small Gaussian noise to a few elements (fine-tuning)\n",
        "    if perturbation_type \u003c 0.6:\n",
        "      num_to_mutate = np.random.randint(\n",
        "          1, max(2, m // 4 + 1)\n",
        "      )  # Mutate 1 to m/4 elements\n",
        "      indices_to_mutate = np.random.choice(m, num_to_mutate, replace=False)\n",
        "      noise_std = 0.05  # Small noise\n",
        "      for idx in indices_to_mutate:\n",
        "        ui_current = x_start[idx]\n",
        "        vi_current = x_start[idx + m]\n",
        "\n",
        "        new_ui = np.clip(ui_current + np.random.normal(0, noise_std), 0.0, 1.0)\n",
        "        # Adjust v_i to maintain sum property then re-clip, prioritizing u_i+v_i \u003c= 1\n",
        "        current_sum = ui_current + vi_current\n",
        "        if current_sum \u003e 0:  # Avoid division by zero\n",
        "          # Maintain original u_i:v_i ratio for change, but within u_i+v_i\u003c=1\n",
        "          new_vi_raw = vi_current / current_sum * (new_ui + vi_current)\n",
        "          new_vi = np.clip(new_vi_raw, 0.0, 1.0 - new_ui)\n",
        "        else:  # If sum was 0, just make new_vi 1-new_ui\n",
        "          new_vi = 1.0 - new_ui\n",
        "\n",
        "        x_start[idx] = new_ui\n",
        "        x_start[idx + m] = new_vi\n",
        "\n",
        "    # 20% chance: Snap some elements to privileged values or new random values (stronger local jump)\n",
        "    elif perturbation_type \u003c 0.8:\n",
        "      privileged_u_values = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "      num_to_mutate = np.random.randint(\n",
        "          1, max(2, m // 3 + 1)\n",
        "      )  # Mutate 1 to m/3 elements\n",
        "      indices_to_mutate = np.random.choice(m, num_to_mutate, replace=False)\n",
        "      for idx in indices_to_mutate:\n",
        "        if np.random.rand() \u003c 0.7:  # 70% chance to snap to privileged\n",
        "          ui = random.choice(privileged_u_values)\n",
        "        else:  # 30% chance to assign completely random\n",
        "          ui = np.random.rand()\n",
        "\n",
        "        # Tend to make u_i + v_i = 1 for these jumps, as per get_score behavior\n",
        "        vi = 1.0 - ui\n",
        "\n",
        "        x_start[idx] = ui\n",
        "        x_start[idx + m] = vi\n",
        "\n",
        "    # 10% chance: Block mutation (introduce symmetry/patterns)\n",
        "    elif perturbation_type \u003c 0.9:\n",
        "      if m \u003e 1:\n",
        "        block_size = np.random.randint(\n",
        "            1, min(m, 3) + 1\n",
        "        )  # Mutate 1 to 3 elements\n",
        "        start_idx = np.random.randint(0, m - block_size + 1)\n",
        "\n",
        "        # Choose a common value for the block\n",
        "        common_ui = np.random.rand()\n",
        "        common_vi = 1.0 - common_ui  # Again, force u_i + v_i = 1 for block\n",
        "\n",
        "        for i in range(start_idx, start_idx + block_size):\n",
        "          # Add tiny noise to break exact equality sometimes, while keeping general pattern\n",
        "          x_start[i] = np.clip(common_ui + np.random.normal(0, 0.01), 0.0, 1.0)\n",
        "          x_start[i + m] = np.clip(\n",
        "              common_vi + np.random.normal(0, 0.01), 0.0, 1.0 - x_start[i]\n",
        "          )\n",
        "      else:  # m=1, act like single element snap\n",
        "        ui = np.random.rand()\n",
        "        vi = 1.0 - ui\n",
        "        x_start[0] = ui\n",
        "        x_start[m] = vi\n",
        "\n",
        "    # 10% chance: Global reset with u_i + v_i = 1 (strongest perturbation)\n",
        "    else:\n",
        "      for idx in range(m):\n",
        "        ui = np.random.rand()\n",
        "        vi = 1.0 - ui  # Force u_i + v_i = 1\n",
        "        x_start[idx] = ui\n",
        "        x_start[idx + m] = vi\n",
        "\n",
        "    # 2. Local Search:\n",
        "    bounds = [(0.0, 1.0)] * (2 * m)\n",
        "    constraints = [\n",
        "        {'type': 'ineq', 'fun': lambda x, i=i: 1.0 - x[i] - x[m + i]}\n",
        "        for i in range(m)\n",
        "    ]\n",
        "\n",
        "    res = optimize.minimize(\n",
        "        objective,\n",
        "        x_start,\n",
        "        args=(m,),\n",
        "        method='SLSQP',\n",
        "        bounds=bounds,\n",
        "        constraints=constraints,\n",
        "        options={'maxiter': 100, 'ftol': 1e-7},\n",
        "    )\n",
        "\n",
        "    # 3. Selection:\n",
        "    current_score = -res.fun\n",
        "    if current_score \u003e best_score:\n",
        "      best_score = current_score\n",
        "      x_best = res.x\n",
        "      print(f'New best score: {best_score}')\n",
        "\n",
        "  best_params = [(x_best[i], x_best[m + i]) for i in range(m)]\n",
        "  print(f'Final score after ILS: {best_score}')\n",
        "  return best_params"
      ],
      "metadata": {
        "cellView": "form",
        "id": "h8JFslpusXva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Code evolved by AlphaEvolve\n",
        "\n",
        "import itertools\n",
        "import logging\n",
        "import time\n",
        "from scipy import integrate\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "import warnings\n",
        "import random\n",
        "import re\n",
        "from collections.abc import Callable, Mapping\n",
        "from typing import Any, List, Tuple, Dict\n",
        "import scipy.linalg as la\n",
        "import collections\n",
        "import copy\n",
        "import math\n",
        "import numba\n",
        "\n",
        "njit = numba.njit\n",
        "\n",
        "\n",
        "def search_for_best_vectors(m: int) -\u003e list[tuple[float, float]]:\n",
        "  \"\"\"Searches for the best (u, v) vectors of length m that maximize alpha.\n",
        "\n",
        "  A simple random search is implemented as a starting point.\n",
        "  \"\"\"\n",
        "  from scipy.fft import dct, idct\n",
        "  # Initialize with a structured, symmetric guess (a linear ramp).\n",
        "  # This construction satisfies u_i + v_i = 1, with v_i = u_{m-1-i}.\n",
        "  if m == 1:\n",
        "      u_init_ramp = np.array([0.5])\n",
        "  else:\n",
        "      # Linear ramp from 1/3 to 2/3. With v_i = u_{m-1-i}, this satisfies u_i+v_i=1.\n",
        "      u_init_ramp = np.linspace(1/3, 2/3, m)\n",
        "  params_ramp = [(u_init_ramp[i], u_init_ramp[m - 1 - i]) for i in range(m)]\n",
        "  score_ramp = get_score(params_ramp, m)\n",
        "\n",
        "  # Initialize with the theoretically-motivated 3-piece structure for 10/9 target.\n",
        "  u_init_theoretical = np.zeros(m)\n",
        "  # Values for 10/9 target based on theory.\n",
        "  # C_L is for u_i, C_R for v_i, C_M for middle element if m is odd.\n",
        "  # Since v_i = u_{m-1-i} is enforced, this implies u_i = C_L and u_{m-1-i} = C_R.\n",
        "  # For symmetry u_i + u_{m-1-i} \u003c= 1, and for specific 10/9 structure values from literature.\n",
        "  C_L, C_M, C_R = 1/3, 0.5, 2/3\n",
        "\n",
        "  N_pairs = m // 2\n",
        "  for i in range(N_pairs):\n",
        "      u_init_theoretical[i] = C_L\n",
        "      u_init_theoretical[m - 1 - i] = C_R\n",
        "  if m % 2 == 1: # Middle element for odd m\n",
        "      u_init_theoretical[N_pairs] = C_M\n",
        "\n",
        "  # Ensure the symmetric condition u_i + u_{m-1-i} \u003c= 1 is met for this initialization\n",
        "  # For the chosen C_L, C_R (1/3, 2/3), their sum is 1.0. For C_M=0.5, u_middle + v_middle = 0.5+0.5=1.0.\n",
        "  # So, direct assignment is fine, no explicit clipping/scaling here.\n",
        "  params_theoretical = [(u_init_theoretical[i], u_init_theoretical[m - 1 - i]) for i in range(m)]\n",
        "  score_theoretical = get_score(params_theoretical, m)\n",
        "\n",
        "  # Choose the best initial guess among ramp, theoretical, and loaded previous best.\n",
        "  params = params_ramp\n",
        "  best_score = score_ramp\n",
        "\n",
        "  if score_theoretical \u003e best_score:\n",
        "      params = params_theoretical\n",
        "      best_score = score_theoretical\n",
        "\n",
        "  variable_name = f'best_vectors_{m}'\n",
        "  if variable_name in globals():\n",
        "    initial_params_loaded = globals()[variable_name]\n",
        "    u_old = np.array([p[0] for p in initial_params_loaded])\n",
        "    v_old = np.array([p[1] for p in initial_params_loaded])\n",
        "    u_loaded_symmetric = np.zeros(m)\n",
        "    for i in range(m):\n",
        "      u_loaded_symmetric[i] = (u_old[i] + v_old[m - 1 - i]) / 2.0\n",
        "    params_loaded = [(u_loaded_symmetric[i], u_loaded_symmetric[m - 1 - i]) for i in range(m)]\n",
        "    score_loaded = get_score(params_loaded, m)\n",
        "    if score_loaded \u003e best_score:\n",
        "      params = params_loaded\n",
        "      best_score = score_loaded\n",
        "\n",
        "  best_params = copy.deepcopy(params)\n",
        "  print(f'Initial score for m={m}: {best_score}')\n",
        "\n",
        "  start_time = time.time()\n",
        "  total_runtime_budget_seconds = 1950.0 # Total runtime budget for the search part (excluding initial setup)\n",
        "\n",
        "  # NEW PHASE: Simple Breakthrough Random Search\n",
        "  # Goal: Quickly find *any* solution with score \u003e 1.0 to escape initial low scores.\n",
        "  # This phase uses a small fraction of the total budget or stops early if score \u003e 1.0.\n",
        "  simple_breakthrough_timeout_factor = 0.03 # Allocate 3% of total time for this phase (e.g., ~58.5s)\n",
        "  simple_breakthrough_timeout = simple_breakthrough_timeout_factor * total_runtime_budget_seconds\n",
        "  simple_breakthrough_start_time = time.time()\n",
        "  num_simple_attempts = 0\n",
        "\n",
        "  print(\"Starting simple breakthrough random search phase...\")\n",
        "  # Loop condition: within time budget AND score is still below target (1.0001 to account for float precision)\n",
        "  while (time.time() - simple_breakthrough_start_time \u003c simple_breakthrough_timeout) and best_score \u003c 1.0001:\n",
        "      num_simple_attempts += 1\n",
        "      current_params = []\n",
        "      for _ in range(m):\n",
        "          ui = np.random.rand()\n",
        "          vi = np.random.rand() # Let get_score handle the u_i + v_i \u003e 1 normalization\n",
        "          current_params.append((ui, vi))\n",
        "\n",
        "      current_score = get_score(current_params, m)\n",
        "\n",
        "      if current_score \u003e best_score:\n",
        "          best_score = current_score\n",
        "          best_params = copy.deepcopy(current_params)\n",
        "          print(f\"Found new best score in simple random search: {best_score:.4f} (attempt {num_simple_attempts})\")\n",
        "          if best_score \u003e 1.0: # Stop this phase early if score \u003e 1.0 is achieved\n",
        "              print(\"Score \u003e 1.0 achieved, exiting simple random search early.\")\n",
        "              break # Exit simple breakthrough phase\n",
        "\n",
        "  print(f\"Finished simple breakthrough random search phase. Best score: {best_score:.4f} after {num_simple_attempts} attempts.\")\n",
        "  time_spent_in_simple_phase = time.time() - simple_breakthrough_start_time\n",
        "  print(f\"Time spent in simple random search: {time_spent_in_simple_phase:.2f} seconds.\")\n",
        "\n",
        "  # Now, start the aggressive random search phase, using the remaining budget.\n",
        "  # Use a proportion of the *remaining* total budget, ensuring it's not too short.\n",
        "  # The factor of 0.5 now applies to the time left after the simple phase.\n",
        "  aggressive_random_search_timeout_factor = 0.5 # Allocate 50% of *remaining* time for aggressive random search\n",
        "  remaining_time_after_simple = max(0.0, total_runtime_budget_seconds - time_spent_in_simple_phase)\n",
        "  random_search_timeout = aggressive_random_search_timeout_factor * remaining_time_after_simple\n",
        "  random_search_start_time = time.time() # Reset start time for aggressive phase\n",
        "  num_random_attempts = 0 # Reset counter for aggressive phase\n",
        "  # No fixed max_random_attempts_per_phase, rely on time and score for stopping.\n",
        "\n",
        "  print(\"Starting aggressive random search phase...\")\n",
        "  # Aggressive random search stopping condition: Stop if time runs out OR a sufficiently good score is found.\n",
        "\n",
        "  # Define probabilities for different random search strategies, now all symmetric.\n",
        "  # Focusing on strategies that are known to yield good results for symmetric configurations.\n",
        "  p_perturbed_theoretical = 0.4   # 40% chance for perturbed theoretical values (1/3, 1/2, 2/3)\n",
        "  p_dct_random = 0.3              # 30% chance for smooth DCT-based generation\n",
        "  p_random_symmetric_fixed_sum = 0.3 # 30% chance for simple random symmetric pairs with u_i+v_i=1\n",
        "\n",
        "  C_L_ideal, C_M_ideal, C_R_ideal = 1/3, 0.5, 2/3 # Ideal values for 10/9 structure\n",
        "\n",
        "  while (time.time() - random_search_start_time \u003c random_search_timeout):\n",
        "      num_random_attempts += 1\n",
        "\n",
        "      roll = np.random.rand()\n",
        "      u_new = np.zeros(m)\n",
        "\n",
        "      if roll \u003c p_perturbed_theoretical and m \u003e 1:\n",
        "          # Perturbed Theoretical Random Search (High probability due to effectiveness)\n",
        "          noise_scale_theoretical = 0.05 + np.random.rand() * 0.08 # Variable noise: 0.05 to 0.13 (slightly higher max)\n",
        "\n",
        "          n_half = m // 2\n",
        "          for i in range(n_half):\n",
        "              u_new[i] = np.clip(C_L_ideal + np.random.normal(0, noise_scale_theoretical), 0.0, 1.0)\n",
        "              u_new[m - 1 - i] = np.clip(C_R_ideal + np.random.normal(0, noise_scale_theoretical), 0.0, 1.0)\n",
        "\n",
        "              # Ensure u_i + u_{m-1-i} \u003c= 1.0 after perturbation. Bias towards 1.0.\n",
        "              current_sum = u_new[i] + u_new[m-1-i]\n",
        "              target_sum = 1.0 - np.random.rand() * 0.05 # Aim slightly below 1.0, but mostly at 1.0\n",
        "              if current_sum \u003e target_sum:\n",
        "                  scale_factor = target_sum / current_sum\n",
        "                  u_new[i] *= scale_factor\n",
        "                  u_new[m-1-i] *= scale_factor\n",
        "\n",
        "          if m % 2 == 1:\n",
        "              u_new[n_half] = np.clip(C_M_ideal + np.random.normal(0, noise_scale_theoretical), 0.0, 0.5)\n",
        "\n",
        "          v_new = u_new[::-1]\n",
        "          current_params = list(zip(u_new, v_new))\n",
        "\n",
        "      elif roll \u003c p_perturbed_theoretical + p_dct_random:\n",
        "          # DCT-based Random Search to generate smooth candidates\n",
        "          c_rand_scale = np.random.uniform(0.5, 2.0)\n",
        "          decay_rate = np.random.uniform(m / 8.0, m / 2.0) if m \u003e 1 else 1.0\n",
        "          freq_weights = c_rand_scale * (0.5 ** (np.arange(m) / decay_rate))\n",
        "          c_rand = np.random.normal(size=m) * freq_weights\n",
        "\n",
        "          u_new = idct(c_rand, type=2, norm='ortho')\n",
        "\n",
        "          # Project u to be feasible: map to [0,1] then enforce sum constraint\n",
        "          min_u, max_u = np.min(u_new), np.max(u_new)\n",
        "          if max_u - min_u \u003e 1e-6:\n",
        "              u_new = (u_new - min_u) / (max_u - min_u)\n",
        "          u_new = np.clip(u_new, 0.0, 1.0)\n",
        "\n",
        "          for i in range(m // 2 + 1):\n",
        "              s = u_new[i] + u_new[m - 1 - i]\n",
        "              if s \u003e 1.0:\n",
        "                  u_new[i] /= s\n",
        "                  u_new[m - 1 - i] /= s\n",
        "\n",
        "          v_new = u_new[::-1]\n",
        "          current_params = list(zip(u_new, v_new))\n",
        "\n",
        "      else:\n",
        "          # Simple Symmetric Random with Fixed Sum (replacing unstructured)\n",
        "          # Generate u_i such that u_i + u_{m-1-i} = 1 and v_i = u_{m-1-i}.\n",
        "          # This greatly simplifies the search space and focuses on symmetric solutions\n",
        "          # with full sum.\n",
        "          n_half = m // 2\n",
        "          for i in range(n_half):\n",
        "              ui = np.random.rand() # ui is in [0,1]\n",
        "              u_new[i] = ui\n",
        "              u_new[m - 1 - i] = 1.0 - ui # Ensures u_i + u_{m-1-i} = 1\n",
        "\n",
        "          if m % 2 == 1:\n",
        "              u_new[n_half] = 0.5 # For middle element, u_middle + v_middle = 0.5 + 0.5 = 1.0\n",
        "\n",
        "          v_new = u_new[::-1] # Enforces v_i = u_{m-1-i} due to the way u_new is constructed.\n",
        "          current_params = list(zip(u_new, v_new))\n",
        "\n",
        "      current_score = get_score(current_params, m)\n",
        "\n",
        "      if current_score \u003e best_score:\n",
        "          best_score = current_score\n",
        "          best_params = copy.deepcopy(current_params) # Store the potentially non-symmetric params if they are better\n",
        "          print(f\"Found new best score in random search: {best_score:.4f} (attempt {num_random_attempts})\")\n",
        "          # If a very good score is found, we can potentially exit early from aggressive random search\n",
        "          # to give more time to ILS. The hint mentions 1.101+ is good.\n",
        "          if best_score \u003e= 1.101:\n",
        "              print(\"Score \u003e= 1.101 achieved, exiting aggressive random search early.\")\n",
        "              break # Exit random search early if we hit a high score\n",
        "\n",
        "  print(f\"Finished aggressive random search phase. Best score: {best_score:.4f} after {num_random_attempts} attempts.\")\n",
        "  print(f\"Time spent in random search: {time.time() - random_search_start_time:.2f} seconds.\")\n",
        "\n",
        "  u_current_from_best_params = np.array([p[0] for p in best_params])\n",
        "  v_current_from_best_params = np.array([p[1] for p in best_params])\n",
        "\n",
        "  u_best_initial = np.zeros(m)\n",
        "  for i in range(m):\n",
        "      # Average u_i and v_{m-1-i} from the current best to enforce symmetry.\n",
        "      # This creates a symmetric starting point for the ILS.\n",
        "      u_best_initial[i] = (u_current_from_best_params[i] + v_current_from_best_params[m - 1 - i]) / 2.0\n",
        "  u_best_initial = np.clip(u_best_initial, 0.0, 1.0)  # Ensure it's within bounds after averaging\n",
        "\n",
        "  # Convert the best u-space vector to DCT-space (c-space). The ILS will operate on c.\n",
        "  c_best = dct(u_best_initial, type=2, norm='ortho')\n",
        "\n",
        "  # Initialize a buffer to store successful c vectors for future diversification\n",
        "  memory_buffer = [c_best.tolist()]\n",
        "  memory_size = 5\n",
        "\n",
        "  # Define the objective function for the optimizer, operating in DCT-space.\n",
        "  # It takes DCT coefficients `c`, transforms them to `u`, projects to the\n",
        "  # feasible set, and then returns the negative score.\n",
        "  def objective_dct(c, m):\n",
        "    # Transform from DCT-space (c) to vector-space (u)\n",
        "    u = idct(c, type=2, norm='ortho')\n",
        "\n",
        "    # Project u back into the feasible set.\n",
        "    u = np.clip(u, 0.0, 1.0)\n",
        "    for i in range(m // 2 + 1):\n",
        "        s = u[i] + u[m - 1 - i]\n",
        "        if s \u003e 1.0:\n",
        "            # Scale to satisfy the constraint u_i + u_{m-1-i} \u003c= 1\n",
        "            # Note: s will not be zero because u elements are non-negative and s \u003e 1.\n",
        "            u[i] /= s\n",
        "            u[m-1-i] /= s\n",
        "\n",
        "    v = u[::-1] # Enforce symmetry v_i = u_{m-1-i}\n",
        "    params_list = list(zip(u, v))\n",
        "    score = get_score(params_list, m)\n",
        "    return -score if score \u003e 0 else float('inf')\n",
        "\n",
        "  # Iterated Local Search (ILS) loop.\n",
        "  # Constraints are now handled inside objective_dct by projection, so the\n",
        "  # explicit constraints for the optimizer are removed.\n",
        "  constraints = []\n",
        "\n",
        "  # Parameters for adaptive noise and advanced perturbation\n",
        "  unimproved_iterations_counter, max_unimproved_iterations = 0, 20 # Reduced from 30 to 20 for faster noise adaptation\n",
        "  current_noise_scale, noise_scale_min, noise_scale_max = 0.03, 0.005, 0.25 # Slightly higher initial noise (0.02-\u003e0.03), higher max (0.20-\u003e0.25)\n",
        "  noise_scale_factor_increase, noise_scale_factor_decrease = 1.4, 0.7 # More aggressive scaling (1.3-\u003e1.4, 0.8-\u003e0.7)\n",
        "\n",
        "  # Probabilities for ILS perturbation strategies in DCT-space.\n",
        "  p_memory = 0.10  # Jump to a solution from memory\n",
        "  p_full_random_restart = 0.05 # Complete random restart\n",
        "  p_crossover_dct = 0.05 # Crossover with a random or memory solution in DCT space\n",
        "  # The remaining 80% of perturbations will be frequency-dependent Gaussian noise on the best solution.\n",
        "\n",
        "  # ILS loop. Check remaining_time_for_ils.\n",
        "  # The `start_time` is the overall start time of the function.\n",
        "  while (time.time() - start_time) \u003c total_runtime_budget_seconds:\n",
        "    # 1. Perturbation Strategy: Perturb in DCT-space (c-space)\n",
        "    c_start = c_best.copy()\n",
        "    roll = np.random.rand()\n",
        "\n",
        "    if roll \u003c p_memory and memory_buffer: # Jump to a past good solution\n",
        "        c_start = np.array(random.choice(memory_buffer))\n",
        "    elif roll \u003c p_memory + p_full_random_restart: # Full random restart in c-space\n",
        "        # Create a random, feasible u-vector and transform it to c-space.\n",
        "        u_rand = np.random.rand(m)\n",
        "        for i in range(m // 2 + 1):\n",
        "            s = u_rand[i] + u_rand[m - 1 - i]\n",
        "            if s \u003e 1.0:\n",
        "                u_rand[i] /= s\n",
        "                u_rand[m - 1 - i] /= s\n",
        "        c_start = dct(u_rand, type=2, norm='ortho')\n",
        "    elif roll \u003c p_memory + p_full_random_restart + p_crossover_dct: # Crossover in c-space\n",
        "        if memory_buffer and np.random.rand() \u003c 0.5: # Crossover with a solution from memory\n",
        "            c_partner = np.array(random.choice(memory_buffer))\n",
        "        else: # Crossover with a newly generated random solution\n",
        "            u_rand_partner = np.random.rand(m)\n",
        "            for i in range(m // 2 + 1):\n",
        "                s = u_rand_partner[i] + u_rand_partner[m - 1 - i]\n",
        "                if s \u003e 1.0:\n",
        "                    u_rand_partner[i] /= s\n",
        "                    u_rand_partner[m - 1 - i] /= s\n",
        "            c_partner = dct(u_rand_partner, type=2, norm='ortho')\n",
        "\n",
        "        # Perform crossover: mix coefficients from c_best and c_partner\n",
        "        # Choose a random split point or blend coefficients. Blending is usually better.\n",
        "        alpha_blend = np.random.uniform(0.2, 0.8) # Blend ratio\n",
        "        c_start = alpha_blend * c_best + (1 - alpha_blend) * c_partner\n",
        "    else:\n",
        "        # The main perturbation is frequency-dependent Gaussian noise.\n",
        "        # The std dev of the noise decays exponentially with frequency, making\n",
        "        # large, smooth changes more likely than small, noisy ones.\n",
        "        decay_rate = m / 4.0 if m \u003e 0 else 1.0\n",
        "        freq_weights = 0.5 ** (np.arange(m) / decay_rate)\n",
        "        noise_std_devs = current_noise_scale * freq_weights\n",
        "        c_start += np.random.normal(0, noise_std_devs)\n",
        "\n",
        "        # Add a small chance of swapping two coefficients to explore different structures.\n",
        "        # Add a small chance of swapping two coefficients to explore different structures.\n",
        "        if m \u003e 1 and np.random.rand() \u003c 0.05: # Reduced probability\n",
        "            idx1, idx2 = np.random.choice(m, 2, replace=False)\n",
        "            c_start[idx1], c_start[idx2] = c_start[idx2], c_start[idx1]\n",
        "\n",
        "        # Add a small chance of sparsifying higher frequency DCT coefficients.\n",
        "        if m \u003e 2 and np.random.rand() \u003c 0.05: # 5% chance\n",
        "            num_to_zero = np.random.randint(1, max(2, m // 4)) # Zero out 1 to m/4 coefficients\n",
        "            # Select higher frequency coefficients to zero out.\n",
        "            # DCT coefficients are ordered by frequency, so higher indices are higher frequencies.\n",
        "            high_freq_indices = np.random.choice(np.arange(m // 2, m), num_to_zero, replace=False)\n",
        "            c_start[high_freq_indices] = 0.0\n",
        "\n",
        "    # 2. Local Search (only if enough time remains)\n",
        "    if (time.time() - start_time) \u003e= total_runtime_budget_seconds:\n",
        "        break # Exit loop if time runs out before starting local search\n",
        "\n",
        "    # The optimizer works on `c`, which is unconstrained.\n",
        "    bounds = [(None, None)] * m\n",
        "    res = optimize.minimize(objective_dct, c_start, args=(m,), method='SLSQP', bounds=bounds,\n",
        "                            constraints=constraints, options={'maxiter': 500, 'ftol': 1e-10, 'disp': False})\n",
        "\n",
        "    # 3. Selection\n",
        "    current_score = -res.fun\n",
        "    if res.success and current_score \u003e best_score:\n",
        "      best_score, c_best = current_score, res.x\n",
        "      memory_buffer.append(c_best.tolist())\n",
        "      if len(memory_buffer) \u003e memory_size:\n",
        "          memory_buffer.pop(0)\n",
        "      print(f'New best score: {best_score:.6f} (Noise: {current_noise_scale:.3f})')\n",
        "      unimproved_iterations_counter = 0\n",
        "      current_noise_scale = max(noise_scale_min, current_noise_scale * noise_scale_factor_decrease)\n",
        "    else:\n",
        "        unimproved_iterations_counter += 1\n",
        "        if unimproved_iterations_counter \u003e= max_unimproved_iterations:\n",
        "            current_noise_scale = min(noise_scale_max, current_noise_scale * noise_scale_factor_increase)\n",
        "            unimproved_iterations_counter = 0\n",
        "\n",
        "  # Convert the final best c-vector back to a u-vector.\n",
        "  u_best = idct(c_best, type=2, norm='ortho')\n",
        "  # Project one last time to ensure feasibility due to potential floating point inaccuracies.\n",
        "  u_best = np.clip(u_best, 0.0, 1.0)\n",
        "  for i in range(m // 2 + 1):\n",
        "      s = u_best[i] + u_best[m-1-i]\n",
        "      if s \u003e 1.0:\n",
        "          u_best[i] /= s\n",
        "          u_best[m-1-i] /= s\n",
        "\n",
        "  # Construct the final parameters from the best u vector found.\n",
        "  v_best = u_best[::-1]\n",
        "  best_params = list(zip(u_best, v_best))\n",
        "  print(f'Final score after ILS: {best_score:.4f}')\n",
        "  return best_params\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JhVHeslorfIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Verification code\n",
        "\n",
        "\n",
        "\n",
        "def validate_input(u: list[float], v: list[float]):\n",
        "  \"\"\"Validates the input vectors u and v.\"\"\"\n",
        "  if len(u) != len(v):\n",
        "    raise ValueError('Input vectors u and v must have the same length.')\n",
        "  if not all(isinstance(x, (float, int)) for x in u) or not all(\n",
        "      isinstance(x, (float, int)) for x in v\n",
        "  ):\n",
        "    raise ValueError('Input vectors must contain only floats or integers.')\n",
        "  if not all(x \u003e= 0 for x in u) or not all(x \u003e= 0 for x in v):\n",
        "    raise ValueError('Input vectors must be non-negative.')\n",
        "  # Use a small tolerance for floating point comparisons\n",
        "  if not all(ui + vi \u003c= 1.000001 for ui, vi in zip(u, v)):\n",
        "    raise ValueError('Condition u_i + v_i \u003c= 1 must be met for all i.')\n",
        "  if any(np.isnan(x) for x in u) or any(np.isnan(x) for x in v):\n",
        "    raise ValueError('Input vectors cannot contain NaN values.')\n",
        "\n",
        "\n",
        "def compute_alpha_exact(u: list[float], v: list[float]) -\u003e tuple[float, float]:\n",
        "  \"\"\"Computes the smallest possible alpha (the min) for the given input vectors as well as alpha's smooth version.\"\"\"\n",
        "  validate_input(u, v)\n",
        "  m = len(u)\n",
        "  if m == 0:\n",
        "    return 0.0, 0.0\n",
        "\n",
        "  best_alpha = float('inf')\n",
        "\n",
        "  z_choices = [(vi, -ui) for ui, vi in zip(u, v)]\n",
        "  for z in itertools.product(*z_choices):\n",
        "    max_alpha_for_z = 0\n",
        "    if m \u003e 1:\n",
        "      max_alpha_for_z = max(abs(sum(z[:k]) - sum(z[k:])) for k in range(1, m))\n",
        "    best_alpha = min(best_alpha, max_alpha_for_z)\n",
        "\n",
        "  return best_alpha\n",
        "\n",
        "\n",
        "def get_score(params: list[tuple[float, float]], m: int) -\u003e float:\n",
        "  \"\"\"Calculates the score for a given set of (u, v) vector parameters.\"\"\"\n",
        "  if not isinstance(params, list) or len(params) != m:\n",
        "    return -1.0\n",
        "\n",
        "  # Cap m to avoid excessive computation time from the O(2^m) algorithm.\n",
        "  if len(params) != m:\n",
        "    return -1.0\n",
        "  if m \u003e 18:\n",
        "    return -1.0\n",
        "\n",
        "  u, v = [], []\n",
        "  for item in params:\n",
        "    if not isinstance(item, (tuple, list)) or len(item) != 2:\n",
        "      return -1.0\n",
        "    if not isinstance(item[0], (float, int)) or not isinstance(\n",
        "        item[1], (float, int)\n",
        "    ):\n",
        "      return -1.0\n",
        "    if np.isnan(item[0]) or np.isnan(item[1]):\n",
        "      return -1.0\n",
        "\n",
        "    ui, vi = abs(item[0]), abs(item[1])\n",
        "    s = ui + vi\n",
        "    if s \u003e 1.0:\n",
        "      ui /= s\n",
        "      vi /= s\n",
        "    if s \u003e 1e9:\n",
        "      return -1.0\n",
        "    u.append(ui)\n",
        "    v.append(vi)\n",
        "\n",
        "  # negative score if variance of the u-v is small\n",
        "  diff_variance = np.var(np.array(u) - np.array(v))\n",
        "  if diff_variance \u003c 0.1:\n",
        "    return -1.0\n",
        "\n",
        "  # I noticed that local optima have a small value somewhere\n",
        "  if min(u) \u003c 0.05 or min(v) \u003c 0.05:\n",
        "    return -1.0\n",
        "\n",
        "  # if all u[i]+v[i] sums are \u003e 0.99, that's a boring local optima\n",
        "  if all(ui + vi \u003e 0.95 for ui, vi in zip(u, v)):\n",
        "    return -1.0\n",
        "\n",
        "  # I also noticed that if the first two or last two entries are equal, that's a boring local optima, so let's push away from that\n",
        "  if (\n",
        "      np.abs(u[0] - u[1]) \u003c 0.05\n",
        "      or np.abs(v[0] - v[1]) \u003c 0.05\n",
        "      or np.abs(u[-2] - u[-1]) \u003c 0.05\n",
        "      or np.abs(v[-2] - v[-1]) \u003c 0.05\n",
        "  ):\n",
        "    return -1.0\n",
        "\n",
        "  try:\n",
        "    exact_alpha = compute_alpha_exact(u, v)\n",
        "    return exact_alpha\n",
        "  except (ValueError, OverflowError):\n",
        "    return -1.0\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-QRKv2eXrh7L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "8D8QmJtaBces"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
