{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sphere packing and uncertainty principles"
      ],
      "metadata": {
        "id": "djJE20OSZICD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sphere packing - upper bounds based on linear programming methods"
      ],
      "metadata": {
        "id": "RLCfM-4MC4A0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt for the search setup**\n",
        "\n",
        "Act as an expert software developer and optimization specialist specializing in\n",
        "creating linear combinations of Laguerre polynomials with certain properties.\n",
        "\n",
        "For a given pair of natural numbers (m, n) we consider the following\n",
        "construction.\n",
        "\n",
        "Let $g_k(x) = L_k^\\alpha(x)$ where $L_k^\\alpha(x)$ denotes the standard\n",
        "generalized Laguerre polynomial of degree k and order $\\alpha = (n / 2) - 1$.\n",
        "\n",
        "First, select a collection of m positive real numbers z_1, z_2, \\dots, z_m.\n",
        "\n",
        "Then let g(x) be a linear combination of odd degree g_k's up to order $4m + 3$\n",
        "i.e. a linear sum of g_1, g_3, \\dots, g_{4m + 3}. The coefficients of this\n",
        "linear combination are chosen such that z_1, \\dots, z_m are double roots and\n",
        "g(0) = 0 and g'(0) = 1 (Counting degrees of freedom implies that there is a\n",
        "unique such linear combination g(x)).\n",
        "\n",
        "Finally, define $r$ to be the largest positive sign change of the polynomial\n",
        "g(x).\n",
        "\n",
        "GOAL:\n",
        "Your optimization task is, for a given natural numbers m and n, to find a\n",
        "collection of m positive real numbers z_1, z_2, \\dots, z_m such that the\n",
        "polynomial g(x) has the largest possible value of r.\n",
        "\n",
        "Specifically, the Python function you have to provide has the following\n",
        "signature:\n",
        "\n",
        "def get_roots(m: int = 10, n: int = 8) -\u003e list[float] | np.ndarray:\n",
        "\n",
        "The function get_roots returns the one-dimensional array z consisting of\n",
        "the positive real numbers $z_i$ for $i = 1, \\dots, m$.\n",
        "NOTE:\n",
        "Try to find constructions of roots that are not too spread apart or too large.\n",
        "The absolute values of the roots z_i should be not larger than 200.\n",
        "Please keep in mind that a promising starting configuration for m = 11, n = 8 is\n",
        "given by z = [37.705, 50.285, 62.893, 75.578, 88.454, 101.737, 115.776, 131.035,\n",
        "148.162, 168.215, 193.766]. Consider using this as a start and inspiration for\n",
        "further optimization for other m and n.\n",
        "\n",
        "The score of z is given by the corresponding value of r. To compute this we use\n",
        "precise fractional arithmetic in sympy.\n",
        "\n",
        "The exact score function your construction will be evaluated on is given below:\n",
        "\n",
        "def get_score(m: int, n: int, zs: np.ndarray | list[float]) -\u003e float:\n",
        "  \"\"\"Returns the score of the given Laguerre combination.\"\"\"\n",
        "  if len(zs) != m:\n",
        "    return WRONG_Z_SHAPE\n",
        "\n",
        "  g_fn = find_laguerre_combination(m, n, zs)\n",
        "  x = sympy.symbols('x')\n",
        "  dg_fn = sympy.diff(g_fn, x)\n",
        "\n",
        "  div = sympy.prod([(x - sympy.Rational(z)) ** 2 for z in zs]) * x\n",
        "  gq_fn = sympy.exquo(g_fn, div)\n",
        "\n",
        "  g_fn.subs(x, sympy.Rational(0))\n",
        "  dg_fn.subs(x, sympy.Rational(1))\n",
        "\n",
        "  for z in zs:\n",
        "    if g_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return ROOTS_NOT_ENFORCED\n",
        "    if dg_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return DERIVATIVES_NOT_ENFORCED\n",
        "\n",
        "  real_roots = sympy.real_roots(gq_fn, x)\n",
        "  if not real_roots:\n",
        "    return NO_SIGN_CHANGES\n",
        "\n",
        "  approx_roots = list()\n",
        "  largest_sign_change = 0\n",
        "\n",
        "  for root in real_roots:\n",
        "    approx_root = root.eval_rational(n=200)\n",
        "    approx_root_p = approx_root + sympy.Rational(1e-198)\n",
        "    approx_root_m = approx_root - sympy.Rational(1e-198)\n",
        "    approx_roots.append(approx_root)\n",
        "    is_sign_change = (\n",
        "        gq_fn.subs(x, approx_root_p) \u003e 0 and gq_fn.subs(x, approx_root_m) \u003c 0\n",
        "    ) or (gq_fn.subs(x, approx_root_p) \u003c 0 and gq_fn.subs(x, approx_root_m) \u003e 0)\n",
        "    if is_sign_change:\n",
        "      largest_sign_change = max(largest_sign_change, approx_root)\n",
        "\n",
        "  return float(largest_sign_change)\n",
        "\n",
        "Note that the score function uses the find_laguerre_combination(m, n, zs) method\n",
        "to obtain the polynomial g(x) given z via exact fractional arithmetic in sympy.\n",
        "\n",
        "You may code up any search method you want, and you are allowed to call the\n",
        "get_score() function as many times as you want. You have access to it, you don't\n",
        "need to code up the get_score() function.\n",
        "You want the score it gives you to be as high as possible!\n",
        "\n",
        "Your task is to write a search function that searches for the best list.\n",
        "Your function will have 1000 seconds to run, and after that it has to have\n",
        "returned the best construction it found. If after 1000 seconds it has not\n",
        "returned anything, it will be terminated with negative infinity points. You can\n",
        "use your time best if you have an outer loop of the form\n",
        "\"while time.time() - start_time \u003c 1000:\" or similar, just don't forget to define\n",
        "the \"start_time\" variable early in your program."
      ],
      "metadata": {
        "id": "kdH7jVgFD-rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Utils\n",
        "\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "from typing import Any, Callable, Mapping\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.special\n",
        "import sympy\n",
        "\n",
        "sys.set_int_max_str_digits(40000)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "s7YE2vlLHrkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EjYjqBVhCOb2"
      },
      "outputs": [],
      "source": [
        "# @title Evaluation\n",
        "\n",
        "\n",
        "def find_laguerre_combination(m, n, z):\n",
        "\n",
        "  alpha = sympy.Rational(n, 2) - 1\n",
        "  degrees = np.arange(1, 4 * m + 4, 2)\n",
        "  x = sympy.symbols(\"x\")\n",
        "  lps = [\n",
        "      sympy.polys.orthopolys.laguerre_poly(n=i, x=x, alpha=alpha, polys=False)\n",
        "      for i in degrees\n",
        "  ]\n",
        "\n",
        "  num_lps = len(lps)\n",
        "  num_conditions = 2 * m + 2  # Root at 0, double roots at z_i\n",
        "\n",
        "  if num_lps \u003c num_conditions:\n",
        "    raise ValueError(\n",
        "        \"Not enough Laguerre polynomials to satisfy all conditions.\"\n",
        "    )\n",
        "\n",
        "  # Create a system of linear equations to solve for alpha_i\n",
        "  A = sympy.Matrix(num_conditions, num_lps, lambda i, j: 0)\n",
        "  b = sympy.Matrix(num_conditions, 1, lambda i, j: 0)\n",
        "\n",
        "  b[1] = 1  # Set g'(0) = const\n",
        "\n",
        "  # Condition 1: Root at 0 (g(0) = 0)\n",
        "  for j in range(num_lps):\n",
        "    A[0, j] = lps[j].subs(x, 0)\n",
        "    A[1, j] = lps[j].diff(x).subs(x, 0)\n",
        "\n",
        "  # Conditions 2 to 2m+2: Double roots at z_i (g(z_i) = 0 and g'(z_i) = 0)\n",
        "  for i in range(0, m):\n",
        "    zi = sympy.Rational(z[i])  # Ensure z_i is rational\n",
        "\n",
        "    # g(z_i) = 0\n",
        "    for j in range(num_lps):\n",
        "      A[2 * i + 2, j] = lps[j].subs(x, zi)\n",
        "\n",
        "    # g'(z_i) = 0 (derivative with respect to x)\n",
        "    for j in range(num_lps):\n",
        "      deriv_lp_j = lps[j].diff(x)  # Symbolic differentiation\n",
        "      A[2 * i + 3, j] = deriv_lp_j.subs(x, zi)\n",
        "\n",
        "  # Solve the linear system Ax = b for x (coefficients alpha_i)\n",
        "  x = A.LUsolve(b)  # Use LU decomposition for efficient solving\n",
        "  alpha_coeffs = [x[i] for i in range(num_lps)]\n",
        "  g_fn = sum(alpha_coeffs[i] * lps[i] for i in range(len(alpha_coeffs)))\n",
        "  return g_fn\n",
        "\n",
        "\n",
        "ROOTS_NOT_ENFORCED = 10000\n",
        "WRONG_Z_SHAPE = 10001\n",
        "DERIVATIVES_NOT_ENFORCED = 10002\n",
        "NO_SIGN_CHANGES = 10003\n",
        "SUGGESTED_ROOTS_TOO_LARGE = 10004\n",
        "\n",
        "\n",
        "def get_score(m: int, n: int, zs: np.ndarray | list[float]) -\u003e float:\n",
        "  \"\"\"Returns the score of the given Laguerre combination.\"\"\"\n",
        "  if len(zs) != m:\n",
        "    return WRONG_Z_SHAPE\n",
        "\n",
        "  g_fn = find_laguerre_combination(m, n, zs)\n",
        "  x = sympy.symbols('x')\n",
        "  dg_fn = sympy.diff(g_fn, x)\n",
        "\n",
        "  div = sympy.prod([(x - sympy.Rational(z)) ** 2 for z in zs]) * x\n",
        "  gq_fn = sympy.exquo(g_fn, div)\n",
        "\n",
        "  g_fn.subs(x, sympy.Rational(0))\n",
        "  dg_fn.subs(x, sympy.Rational(1))\n",
        "\n",
        "  for z in zs:\n",
        "    if g_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return ROOTS_NOT_ENFORCED\n",
        "    if dg_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return DERIVATIVES_NOT_ENFORCED\n",
        "\n",
        "  real_roots = sympy.real_roots(gq_fn, x)\n",
        "  if not real_roots:\n",
        "    return NO_SIGN_CHANGES\n",
        "\n",
        "  approx_roots = list()\n",
        "  largest_sign_change = 0\n",
        "\n",
        "  for root in real_roots:\n",
        "    approx_root = root.eval_rational(n=200)\n",
        "    approx_root_p = approx_root + sympy.Rational(1e-198)\n",
        "    approx_root_m = approx_root - sympy.Rational(1e-198)\n",
        "    approx_roots.append(approx_root)\n",
        "    is_sign_change = (\n",
        "        gq_fn.subs(x, approx_root_p) \u003e 0 and gq_fn.subs(x, approx_root_m) \u003c 0\n",
        "    ) or (gq_fn.subs(x, approx_root_p) \u003c 0 and gq_fn.subs(x, approx_root_m) \u003e 0)\n",
        "    if is_sign_change:\n",
        "      largest_sign_change = max(largest_sign_change, approx_root)\n",
        "\n",
        "  return float(largest_sign_change)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initial program\n",
        "\n",
        "suggested_roots = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
        "\n",
        "\n",
        "def get_roots(m: int, n: int) -\u003e list[float] | np.ndarray:\n",
        "  \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "  variable_name = f'suggested_roots_{m}'\n",
        "  best_roots = list(np.arange(1, m + 1) + n)\n",
        "\n",
        "  if np.random.rand() \u003c 0.5 and variable_name in globals():\n",
        "    best_roots = globals()[variable_name]\n",
        "\n",
        "  curr_positions = best_roots.copy()\n",
        "  best_score = get_score(m, n, best_roots)\n",
        "\n",
        "  start_time = time.time()\n",
        "  while time.time() - start_time \u003c 100:  # Search for 100 seconds\n",
        "    random_index = np.random.randint(0, len(curr_positions))\n",
        "    curr_positions[random_index:] += 1e-1 * np.random.randint(-10, 10)\n",
        "    curr_score = get_score(n, curr_positions)\n",
        "    if curr_score \u003e best_score:\n",
        "      best_score = curr_score\n",
        "      best_roots = curr_positions.copy()\n",
        "      print(f\"Best score: {curr_score}\")\n",
        "\n",
        "  return best_roots"
      ],
      "metadata": {
        "cellView": "form",
        "id": "n3VcvqG9G3oN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configurations obtained by AlphaEvolve\n",
        "\n",
        "# 6 roots in 25 dim\n",
        "suggested_roots_6_25 = [38.59990403042335, 51.492514056486456, 64.61752892431971, 80.83626553375464, 99.10082276235605, 119.82181796581477]\n",
        "# 8 roots in 25 dim\n",
        "suggested_roots_8_25 = [38.52953040091796, 51.26018187250741, 63.71261940889087, 78.09254403415129, 93.6713541797075, 110.16959212745668, 132.72837654008953, 151.87758151262366]\n",
        "# 10 roots in 25 dim\n",
        "suggested_roots_10_25 = [38.446349008804845, 50.94894525741638, 64.42826066299327, 77.8810376282672, 91.22936339942667, 105.95375302939827, 117.75701066036017, 135.99677682063452, 154.36310605878, 179.31645167349984]\n",
        "# 6 roots in 30 dim\n",
        "suggested_roots_6_30 = [42.754060091336754, 55.93712498537983, 69.6672739058253, 85.74802171838502, 103.80696192096791, 122.6267287889253]\n",
        "# 8 roots in 30 dim\n",
        "suggested_roots_8_30 = [42.843076071461326, 53.59448994991431, 65.03632808656212, 79.0354644879144, 93.32647614615303, 108.29065789473482, 126.04751333162189, 137.2109969193287]\n",
        "# 10 roots in 30 dim\n",
        "suggested_roots_10_30 = [40.70608913194654, 54.367044004983676, 67.07359341470105, 83.95998264550133, 96.72724938921412, 107.46383275000353, 129.7690253337481, 142.0989363215454, 162.00144210663203, 177.46601777960245]\n",
        "# 6 roots in 35 dim\n",
        "suggested_roots_6_35 = [47.008355187949455, 60.459254120329135, 74.36584602868015, 91.6127685240848, 109.06949521970334, 129.01863659501757]\n",
        "# 8 roots in 35 dim\n",
        "suggested_roots_8_35 = [46.50466498749102, 60.715302405700946, 75.56008072687219, 88.35291756954845, 103.53056264712156, 125.59614192990736, 143.5176152969259, 160.14549435186555]\n",
        "# 10 roots in 35 dim\n",
        "suggested_roots_10_35 = [46.34839194715566, 59.086464707143136, 71.69493811810037, 85.28766727724832, 100.53582876782653, 114.11784957031244, 129.08209602859588, 150.99036977340384, 171.46491738755452, 200.0]\n",
        "\n",
        "# Example scores\n",
        "# get_score(10, 25, suggested_roots_10_25)\n",
        "# get_score(10, 35, suggested_roots_10_35)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "i7d0AKjLIK-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Examples of programs evolved by AlphaEvolve\n",
        "\n",
        "def get_roots(m: int, n: int) -\u003e list[float] | np.ndarray:\n",
        "    \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "    rng = np.random.default_rng(seed=m * 100 + n)\n",
        "    variable_name = f'suggested_roots_{m}'\n",
        "    bounds = [(1, 200)] * m\n",
        "\n",
        "    def root_fusion(roots, n, rng):\n",
        "      \"\"\"Combines current roots with random roots from a different range.\"\"\"\n",
        "      n_fusion = rng.integers(5, 5+ n//2)        #Scale it.\n",
        "\n",
        "      # Scale for a better distribution in terms of range\n",
        "      fused_roots = rng.uniform(1, n_fusion, size=len(roots))\n",
        "      fusion_mask = rng.choice([True, False], size=len(roots), p=[0.21, 0.79]) #Mask\n",
        "\n",
        "      roots[fusion_mask] = fused_roots[fusion_mask] #Mix now\n",
        "      return roots\n",
        "\n",
        "    def repulsive_init(num_points, lower_bound, upper_bound, n, m):\n",
        "        \"\"\"Generates a repulsive initialization within bounds.\"\"\"\n",
        "        points = np.linspace(lower_bound, upper_bound, num_points * 3) # more points.\n",
        "\n",
        "        points = rng.choice(points, size=num_points, replace=False) # sample.\n",
        "\n",
        "        points = np.sort(points)\n",
        "\n",
        "\n",
        "        def force_repulsion(points, strength, iterations, n, m):\n",
        "            points_arr = np.array(points)\n",
        "            for _ in range(iterations): # iterate for better spread.\n",
        "                for i in range(len(points_arr)):\n",
        "                    force = 0.0\n",
        "                    for j in range(len(points_arr)):\n",
        "                        if i != j:\n",
        "                            distance = points_arr[j] - points_arr[i]\n",
        "                            # Cap the force to avoid extreme values\n",
        "                            force += strength / max(abs(distance), 1e-6) * np.sign(distance)\n",
        "\n",
        "                    points_arr[i] += 0.1*  force # Adaptive step\n",
        "                points_arr = np.clip(points_arr, lower_bound, upper_bound)\n",
        "                points_arr.sort() # Keep sorted\n",
        "            return points_arr.tolist()\n",
        "\n",
        "        strength = 0.5 * n + 0.1 * m  # Strength based on parameters\n",
        "        return force_repulsion(points, strength, 50, n, m)   # A few iterations.\n",
        "\n",
        "    def interpolate_roots(target_m: int, target_n: int, rng: np.random.Generator):\n",
        "        \"\"\"Interpolates roots from known solutions, with adaptive weighting.\"\"\"\n",
        "        known_solutions = {\n",
        "            (11, 8): [37.705, 50.285, 62.893, 75.578, 88.454, 101.737, 115.776, 131.035, 148.162, 168.215, 193.766],\n",
        "            # Add more known solutions if available\n",
        "        }\n",
        "\n",
        "        # Find the closest known (m, n)\n",
        "        closest_mn = None\n",
        "        min_distance = float('inf')\n",
        "        for (km, kn), _ in known_solutions.items():\n",
        "            distance = (km - target_m)**2 + (kn - target_n)**2\n",
        "            if distance \u003c min_distance:\n",
        "                min_distance = distance\n",
        "                closest_mn = (km, kn)\n",
        "\n",
        "        #Dynamic Selection Of solutions and blend.\n",
        "        num_sols_blend = min(3, len(known_solutions))\n",
        "        dists = []\n",
        "        sols = []\n",
        "        for (km, kn), sol in known_solutions.items():   #Compute distance and sort\n",
        "            dist = (km - target_m)**2 + (kn - target_n)**2\n",
        "            dists.append(dist)\n",
        "            sols.append(((km,kn),sol))\n",
        "\n",
        "        closest_sols = sorted(zip(dists, sols), key = lambda x: x[0])[:num_sols_blend] #Take k closest\n",
        "\n",
        "        if not closest_sols:\n",
        "            return repulsive_init(target_m, 1, 200, target_n, target_m)\n",
        "\n",
        "\n",
        "        #Blend by weightings.\n",
        "        interpolated_roots = np.zeros(target_m) #Base values\n",
        "        total_weight = 0.0\n",
        "        for dist, sol_data in closest_sols:\n",
        "            (known_m, known_n), known_roots = sol_data\n",
        "            weight = np.exp(-dist / (target_m + target_n))\n",
        "            total_weight+=weight\n",
        "\n",
        "            interp_roots = np.interp(\n",
        "                np.linspace(0, 1, target_m),  # Normalized indices for target_m\n",
        "                np.linspace(0, 1, known_m),  # Normalized indices for known_m\n",
        "                known_roots\n",
        "            )\n",
        "            interpolated_roots+= weight * interp_roots\n",
        "\n",
        "        interpolated_roots /= total_weight\n",
        "        known_m, known_n = closest_sols[0][1][0] #Get basic\n",
        "\n",
        "        # Adaptive interpolation/extrapolation\n",
        "        interpolated_roots = np.interp(\n",
        "            np.linspace(0, 1, target_m),  # Normalized indices for target_m\n",
        "            np.linspace(0, 1, known_m),  # Normalized indices for known_m\n",
        "            known_roots\n",
        "        ).tolist()\n",
        "\n",
        "        # Adjust based on target n, with scaling\n",
        "        for i in range(target_m):\n",
        "            interpolated_roots[i] += (target_n - known_n) * (0.1 + 0.01 * target_m)  # dynamic scaling\n",
        "            interpolated_roots[i] = np.clip(interpolated_roots[i] + rng.normal(0, (1 + target_n * 0.05) / (1 + target_m * 0.1)), 1, 200)\n",
        "\n",
        "        return interpolated_roots\n",
        "\n",
        "    # --- Initialization and Prior Knowledge ---\n",
        "    use_prior = 0.5 + 0.4 * np.exp(-0.005 * m * n)\n",
        "    jump_chance = 0.25 #MORE CHAOS. MORE RANDOM INIT.\n",
        "\n",
        "    if rng.random() \u003c jump_chance: # Rare Jump!\n",
        "        #Less jumping!\n",
        "        init_type = rng.choice(['repulsive',]) #No uniform (too much explosion)\n",
        "\n",
        "        if init_type == 'repulsive':\n",
        "            best_roots = repulsive_init(m, bounds[0][0], bounds[0][1], n, m) #Repulsive intit\n",
        "        elif init_type == \"root_fusion\":\n",
        "            best_roots = root_fusion(best_roots, n, rng)  # Call `initialize_roots` directly\n",
        "        elif init_type == 'interpolated':\n",
        "            best_roots = interpolate_roots(m, n, rng)\n",
        "        elif init_type == 'cauchy':\n",
        "            best_roots = rng.standard_cauchy(size=m) * (0.2 * n) + (n/2)  #Cauchy! Removing to reduce search space.\n",
        "\n",
        "        else: # uniform\n",
        "           best_roots = rng.uniform(bounds[0][0], bounds[0][1], size = m)\n",
        "    else: # Regular prior or other inits\n",
        "        if variable_name in globals() and rng.random() \u003c use_prior:\n",
        "            best_roots = np.array(globals()[variable_name]).copy()\n",
        "            shrinkage = 0.9 + 0.01 * n\n",
        "            best_roots = (shrinkage * best_roots) + rng.normal(0, (n ** 0.5) * 0.1, size=m)  # Smaller, scaled noise.\n",
        "        else:\n",
        "            if rng.random() \u003c 0.7: # reduce chance it is interpolate\n",
        "                best_roots = interpolate_roots(m, n, rng)  # Increased interpolation probability.\n",
        "            else:\n",
        "                # Fallback initialization.\n",
        "                base_spacing = n / (1.5 + 0.05 * m)\n",
        "                best_roots = np.array([i * (base_spacing + 0.017 * i * base_spacing) + n * (0.8 + 0.1 * rng.random()) for i in range(1, m + 1)])  # Adjusted.  Slightly more exponential to force local exploitation.\n",
        "\n",
        "    best_roots = np.clip(best_roots, 1, 200)\n",
        "\n",
        "    # --- Neighbor-Based Adjustments (Early Stage)---\n",
        "    for _ in range(min(m // 2,3 )): # Reduced Neighbor adjust\n",
        "        i = rng.integers(0, m)\n",
        "        neighbors = []\n",
        "        if i \u003e 0:\n",
        "            neighbors.append(best_roots[i - 1])\n",
        "        if i \u003c m - 1:\n",
        "            neighbors.append(best_roots[i + 1])\n",
        "        if neighbors:\n",
        "             avg_neighbor = np.mean(neighbors)\n",
        "             influence = 0.2 * (1 - m * 0.01)  # Reduce influence as m grows.\n",
        "             best_roots[i] = (1 - influence) * best_roots[i] + influence * avg_neighbor\n",
        "             best_roots[i] = np.clip(best_roots[i], 1, 200)\n",
        "\n",
        "    # --- Gradient-Informed Perturbation (Core Optimization) ---\n",
        "    if 'momentum' not in globals():\n",
        "        globals()['momentum'] = np.zeros(m) # Init momentum\n",
        "\n",
        "    # --- Hyper jump condition ---\n",
        "    # Less often, MORE Hyperjumping/coordinate exploration\n",
        "    num_gradient_steps = int(m * 0.7)  # Simplified num_gradient_steps\n",
        "\n",
        "    #Reduced hyperspace jumps to 1 and 3, then add prime force.\n",
        "    for _ in range(num_gradient_steps):\n",
        "        i = rng.integers(0, m)\n",
        "\n",
        "        local_best = best_roots.copy() # local back up\n",
        "        if rng.random() \u003c 0.01:  # Increased probability, try more often MORE DISTURBANCE, more jumping. More local back up\n",
        "\n",
        "            #Prime fact\n",
        "            prime_factor =  prime_factor_influence(best_roots, n)\n",
        "\n",
        "            #Add small-scaling for exploration and perturbation strength control\n",
        "            scale_rand= rng.uniform(-0.042 , 0.042) #Scale by a random number scaled, REMOVING, NO HYPER JUMP\n",
        "\n",
        "            #Scale normalization: Adaptively scale based on n, with prime_influence\n",
        "            scale = (np.mean(best_roots) + n * 1.51) / (np.linalg.norm(hyper_coords) + 1e-8) #Normalize hyperspace coordinates\n",
        "\n",
        "            best_roots += np.array([scale * hyper_coords[k % HYPERDIM] for k in range(m)]) #Mix back to original values\n",
        "\n",
        "            #Keep local, revert back\n",
        "            delta_c = np.sum(best_roots - local_best)/m;\n",
        "            if abs(delta_c) \u003e .2 + rng.normal(0,.1111 ):\n",
        "                best_roots = local_best # revere\n",
        "\n",
        "        delta = 0.025 * n  # Smaller delta. Reduce it further from .2-\u003e.1 since removing HYPERSpace JUMP already jumps so far.\n",
        "\n",
        "        # Central Difference Gradient Estimation\n",
        "        original_root = best_roots[i]\n",
        "        best_roots[i] = np.clip(original_root + delta, 1, 200)\n",
        "        score_plus = get_score(m, n, best_roots)\n",
        "\n",
        "        best_roots[i] = np.clip(original_root - delta, 1, 200)\n",
        "\n",
        "        score_minus = get_score(m, n, best_roots)\n",
        "\n",
        "        best_roots[i] = original_root  # Restore\n",
        "\n",
        "        if score_plus == -float('inf') and score_minus == -float('inf'):         #Both bad.\n",
        "            gradient = 0\n",
        "        elif score_plus == -float('inf'):\n",
        "            gradient = -1.0\n",
        "        elif score_minus == -float('inf'):\n",
        "            gradient = 1.0\n",
        "        else:\n",
        "            gradient = (score_plus - score_minus) / (2 * delta)\n",
        "\n",
        "        #---- Newton Step\n",
        "        # --- Random Gradient Scaling (Structured Exploration)---\n",
        "        rand_scale = 1.0 + rng.normal(0, 0.325) # Small random scaling more aggressively scale down\n",
        "        gradient *= rand_scale\n",
        "\n",
        "        mu = 0.2 * n* rng.uniform(0.1, 0.9)   #Regularization parameter (randomness added here, and prime_influence)\n",
        "        damping = 1 + mu\n",
        "        descent_direction = gradient  / damping # Direction vector\n",
        "\n",
        "        #----Momentum addition, helps navigate flat regions with randomness\n",
        "        momentum_factor = 0.5 + rng.normal(0,0.05) #Randomized and bounded\n",
        "        # --- Momentum Vector Perturbation ---\n",
        "        momentum_noise = rng.normal(0, 0.02 * n)  #Small perturbation but bounded to small size\n",
        "        globals()['momentum'][i] = momentum_factor * globals()['momentum'][i] + (1 - momentum_factor) * descent_direction + momentum_noise\n",
        "        descent_direction = globals()['momentum'][i]\n",
        "\n",
        "\n",
        "        max_step = 0.015 * n #limit each individual step.\n",
        "        step_size = min(max_step/ abs(descent_direction)  + 1e-8, 0.05*n)  #Limit step taken\n",
        "        # --- Step Size Randomization ---\n",
        "        step_rand = 1.0 + rng.normal(0, 0.05)  # Randomize step AND ALSO factor number here. Reduced number factor since jumping causes problems\n",
        "        best_roots[i] = np.clip(best_roots[i] - step_size * descent_direction * step_rand, 1, 200)\n",
        "\n",
        "\n",
        "    #---Chaotic Burst Modification---\n",
        "    if rng.random() \u003c 0.038: # Probability of chaotic jump - Increased Chance to explore\n",
        "        chaos = rng.normal(0, .25, m)  #Random values\n",
        "        for j in range(m):\n",
        "            best_roots[j] += n * 0.175 * chaos[j % m] #Apply series pertub.  Scale is also ramped.\n",
        "            best_roots[j] = np.clip(best_roots[j], 1, 200) #Clip now.\n",
        "\n",
        "    #-----LONG term global migration!-----\n",
        "    #  High level re injection\n",
        "    if 'long_contenders' not in globals():\n",
        "        #Init set of long contender\n",
        "        globals()['long_contenders'] = set()\n",
        "\n",
        "    global_pull =.001/10 #What is global pool size?\n",
        "    def _global():\n",
        "        inject=[]\n",
        "        if len(globals()['long_contenders']) \u003e 3:\n",
        "            cont_ = list(globals()['long_contenders'])\n",
        "            c   = rng.choice(cont_)\n",
        "            return c\n",
        "        else:\n",
        "             return \"\"\n",
        "\n",
        "    global_item = _global()\n",
        "    final_noise_scale = 0.009 * n + 0.009 * np.sqrt(np.arange(m)) #Reduced\n",
        "\n",
        "    # global scale inject\n",
        "    if global_item != \"\":\n",
        "         print(\"Apply new random noise: global inject\")\n",
        "         new_noise     = rng.normal(0, final_noise_scale, size         = m)\n",
        "         new_roots     = [min(200,max(1, new_noise[ind] +float(v))) for ind, v in enumerate(global_item)]\n",
        "         return new_roots\n",
        "\n",
        "\n",
        "    best_roots += rng.normal(0, final_noise_scale, size         = m)\n",
        "    best_roots = np.clip(best_roots, 1, 200).tolist()\n",
        "\n",
        "\n",
        "    return best_roots\n",
        "\n",
        "\n",
        "def get_roots(m: int, n: int) -\u003e list[float] | np.ndarray:\n",
        "    \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "    rng = np.random.default_rng(seed=m * 100 + n)\n",
        "    variable_name = f'suggested_roots_{m}'\n",
        "    bounds = [(1, 200)] * m\n",
        "\n",
        "    # --- Simulated Annealing Parameters ---\n",
        "    # --- Simulated Annealing Parameters ---\n",
        "    initial_temperature = 0.5 * (m + n)\n",
        "    cooling_rate = 0.995\n",
        "    pomodoro_interval = 20  # Define Pomodoro interval (cycles). To consider a good starting point for balancing exploration/exploitation\n",
        "    cognitive_load = 0.08  # Define cognitive load (probability of distraction)\n",
        "    random_perturbation_prob = 0.04 # Probability of strong random perturbation\n",
        "\n",
        "    # --- State Management ---\n",
        "    state = globals().get('state', { #Gets or reset\n",
        "        'temperature': initial_temperature, #Reset to new initial vals\n",
        "        'jump_scale': 0.1 * n,\n",
        "        'pomodoro_counter': 0,  # Track Pomodoro intervals\n",
        "        'best_score': float('-inf'),\n",
        "        'solution_memory': deque(maxlen=5),\n",
        "        'no_improvement_counter': 0,\n",
        "        'best_roots': None,\n",
        "    })\n",
        "    temperature = state['temperature']\n",
        "    jump_scale = state['jump_scale']\n",
        "    best_score = state['best_score']\n",
        "    solution_memory = state['solution_memory']\n",
        "    no_improvement_counter = state['no_improvement_counter']\n",
        "    pomodoro_counter = state['pomodoro_counter']\n",
        "\n",
        "    if state['best_roots'] is None:  # First run, none provided.\n",
        "        best_roots = np.array([rng.uniform(1, 200) for _ in range(m)])  #Initialize as well; we want to add historical ones.\n",
        "        was_random_start = True    #Keep track.\n",
        "    else:\n",
        "        best_roots = state['best_roots'].copy()\n",
        "        was_random_start = False #We didn't random start,\n",
        "\n",
        "\n",
        "\n",
        "    # Initialization with Prior Knowledge\n",
        "    use_prior = 0.3 + 0.3 * np.exp(-0.004 * m * n)\n",
        "    if variable_name in globals() and rng.random() \u003c use_prior:\n",
        "        best_roots = np.array(globals()[variable_name]).copy()\n",
        "        best_roots += rng.normal(0, temperature * 0.05 * n**0.3, size=m)   # Temperature dependent perturbation\n",
        "\n",
        "    else:\n",
        "        prime_nums = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97,\n",
        "                      101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193,\n",
        "                      197, 199]\n",
        "\n",
        "        # Introduce a \"Prime Resonance\" factor + more dynamic factor to promote escape behavior during convergence\n",
        "        prime_resonance = (prime_nums[m % len(prime_nums)] / prime_nums[-1]) * 0.02 + 0.005 * np.cos(time.time()*np.pi + m + n)  # small factor based on primes\n",
        "\n",
        "        base_spacing = n / (2.0 + 0.04 * m) + 1.1 + jump_scale * np.sin(\n",
        "            m * n / 5) + prime_resonance  # Jump scale and prime influence\n",
        "\n",
        "        # Fibonacci-based perturbation\n",
        "        fibonacci = [1, 1]\n",
        "        for k in range(2, m):\n",
        "            fibonacci.append((fibonacci[k-1] + fibonacci[k-2]) % 100) # Modulo to keep values small\n",
        "\n",
        "        best_roots = np.array([\n",
        "            i * base_spacing * (1 + 0.15 * (i / m)**1.5)  # Enhanced non-linear scaling (power law)\n",
        "            * (1 + 0.01 * prime_nums[i % len(prime_nums)] / prime_nums[-1])  # Prime-based MODULATION of spacing\n",
        "            * (1 + 0.005 * np.sin(i + prime_nums[i % len(prime_nums)]))  # Add Prime Resonance with sin\n",
        "            + 0.95 * n + jump_scale * 0.1 * i * np.cos(i * m)  # Reduced jump scale influence\n",
        "            + temperature * 0.01 * (fibonacci[i % m] / 100.0) * n  # Fibo.\n",
        "            + (i \u0026 prime_nums[i % len(prime_nums)]) * 0.00009 * n #BitWise with Prime number\n",
        "            * (1 + 0.001 * np.cos(np.sqrt(i+time.time()))) # More Modulation\n",
        "            + 0.002 * n * np.sin(prime_nums[(i + int(time.time())) % len(prime_nums)]*i/(m+1))\n",
        "\n",
        "            for i in range(1, m + 1)\n",
        "        ])\n",
        "\n",
        "    # --- Staccato Search (Pomodoro Technique) ---\n",
        "    current_score = get_score(m, n, best_roots)  # Current score.\n",
        "    best_score = globals().get('best_score', float('-inf'))\n",
        "\n",
        "    # === Global State Management Reset ===\n",
        "    reset_prob = (0.01 + pomodoro_counter*0.000025) #Adaptive\n",
        "    memory_replay_prob = 0.45    # Try to replay past configs- can help recover from bad decisions,\n",
        "\n",
        "    primes_used_for_reset = [3, 5, 7, 11, 13, 17]  # Primes to influence restarts\n",
        "    prime_to_use = primes_used_for_reset[m % len(primes_used_for_reset)]\n",
        "\n",
        "    # Check that best_roots is initialized\n",
        "    is_initialized = variable_name in globals() or best_roots is not None # check.\n",
        "\n",
        "    if is_initialized and pomodoro_counter \u003e 0 and pomodoro_counter %prime_to_use == 0 and rng.random() \u003c reset_prob:\n",
        "        if len(state['solution_memory']) \u003e 2 and rng.random() \u003c memory_replay_prob:\n",
        "\n",
        "            # Replay state history from the memory, make us eof other solutions.\n",
        "            selected_solution_index = rng.choice(len(solution_memory))\n",
        "            best_roots = solution_memory[selected_solution_index][0].copy() #Grab this old config.\n",
        "\n",
        "            print(\"\u003e\u003e\u003e REPLAY global best from state DICTIONARY \u003c\u003c\u003c\")\n",
        "        else:\n",
        "            # \"Forget\" the state by clearing the global dictionary.\n",
        "            del globals()['state'] #DELETE THE STATE!\n",
        "            state = {}\n",
        "            temperature = initial_temperature\n",
        "            jump_scale = 0.1 * n\n",
        "\n",
        "            print(\"\u003e\u003e\u003e STATE DICTIONARY RESET \u003c\u003c\u003c\")\n",
        "\n",
        "    #Reduced mutation\n",
        "    num_gradient_steps = int(m * 0.3)  # Further reduced gradient steps to let distractions work\n",
        "    for _ in range(num_gradient_steps):\n",
        "        i = rng.integers(0, m)\n",
        "        delta = 0.02 * n  # Smaller delta for gradient estimation\n",
        "        delta_2 = 0.008 * n  # Smaller delta for gradient estimation\n",
        "\n",
        "\n",
        "        # Apply cognitive load/distraction. For robustness\n",
        "        if rng.random() \u003c cognitive_load * (1 + np.sin(time.time())):  # Temporal load variation (external/Zeitgeist stimulus).\n",
        "             best_roots[i] += rng.normal(0, 0.08 * n)  # Small stochastic \"annoyance.\"\n",
        "             best_roots[i] = np.clip(best_roots[i], 1, 200)\n",
        "\n",
        "        # Adaptive Step Size (and direction finding)\n",
        "\n",
        "        original_root = best_roots[i]\n",
        "\n",
        "        # Random Perturbation\n",
        "        if rng.random() \u003c random_perturbation_prob:\n",
        "            best_roots[i] += rng.normal(0, n * 0.15) # Larger Perturbation\n",
        "            best_roots[i] = np.clip(best_roots[i], 1, 200) # Clip and then evaluate.\n",
        "\n",
        "        best_roots[i] = np.clip(original_root + delta, 1, 200)\n",
        "        score_plus = get_score(m, n, best_roots)\n",
        "        best_roots[i] = np.clip(original_root - delta, 1, 200)\n",
        "        score_minus = get_score(m, n, best_roots)\n",
        "        best_roots[i] = original_root  # Restore original root\n",
        "\n",
        "        if score_plus == -float('inf') and score_minus == -float('inf'):\n",
        "            gradient = 0.0\n",
        "        elif score_plus == -float('inf'):\n",
        "            gradient = -1.0\n",
        "        elif score_minus == -float('inf'):\n",
        "            gradient = 1.0\n",
        "        else:\n",
        "            gradient = (score_plus - score_minus) / (2 * delta)\n",
        "\n",
        "\n",
        "        # Adaptive Step Size and Momentum (Smoother updates)\n",
        "        # Higher learning rate if no recent improvements. Also inject number theoretic properties\n",
        "        aggression_factor = 1.0 + 0.4 * np.tanh(no_improvement_counter / 20.0) * np.sin(prime_nums[i%len(prime_nums)])\n",
        "        step_size = 0.03 * n * aggression_factor / (1 + np.abs(gradient))  # Adjust scaling here!\n",
        "\n",
        "        momentum = 0.5  # Add momentum for smoother gradient descent\n",
        "\n",
        "        # Ensure that momentum is initialized in the scope or increase!\n",
        "        if 'momentum_values' not in locals():\n",
        "            momentum_values = np.zeros(m)\n",
        "\n",
        "        momentum_values[i] = momentum * momentum_values[i] + (1 - momentum) * step_size * gradient  # Momentum\n",
        "\n",
        "        \"\"\"\n",
        "        A combinatorics augmented number theory-based perturbation is applied as part of the update, involving the injection of finely-tuned stochastic noise to enhance exploration within the solution space.\n",
        "        \"\"\"\n",
        "\n",
        "        best_roots[i] = np.clip(best_roots[i] + momentum_values[i], 1, 200) # momentum step\n",
        "\n",
        "\n",
        "    # --- Final Touches, reduced noise --- --Increase level - for final kick!\n",
        "    noise = rng.normal(0, (n * 0.015 + np.sqrt(np.arange(m)) *0.05) * temperature * 0.08, size=m)  # Reduced final noise.\n",
        "\n",
        "    best_roots = np.clip(best_roots + noise, 1, 200)  # reduced final noise.\n",
        "    final_score = get_score(m, n, best_roots)\n",
        "\n",
        "    # -- Stochastic Restart Mechanism --\n",
        "    restart_prob = 0.001 + 0.005 * np.exp(no_improvement_counter / 40)  # Adaptive restart probability\n",
        "    num_number_jump = len(prime_nums) # number list\n",
        "    if rng.random() \u003c restart_prob:        # More Restarts, bigger range and power laws.\n",
        "\n",
        "        num_to_restart = rng.integers(1,min(m // 2 + 1, num_number_jump))  # Restart a portion of roots\n",
        "        indices_to_restart = rng.choice(m, size=num_to_restart, replace=False)\n",
        "        for j in indices_to_restart:    #Inject from primes now\n",
        "            best_roots[j] = prime_nums[j % num_number_jump] + rng.normal(0,0.5 * n) # from prime number as seeding pt\n",
        "\n",
        "        final_score = get_score(m, n, best_roots) #Update the scores\n",
        "\n",
        "    current_shuffle_prob = 0.07 # Base probability\n",
        "    current_shuffle_prob += (1 - np.exp(-0.001 * m * n)) * 0.5  # Adaptive, less if m*n large\n",
        "    # --- \"Aggressive Remix\"- to force it out!---\n",
        "    # This aggressively remixes the population.\n",
        "    if rng.random() \u003c current_shuffle_prob and best_roots is not None:  # If score gets bad.\n",
        "\n",
        "        # Create radically different children.\n",
        "        noise = rng.normal(0, 0.15 *n, size=m)\n",
        "        prime_scaling = ( primes[m % len(primes)] * 0.01 / sum(primes[:min(m, len(primes))])) if m\u003e0 else 0 # Small Prime Factors.\n",
        "\n",
        "        recombined_roots = np.clip(best_roots *  np.sin(time.time()) + noise + prime_scaling, 1, 200) # Prime Mod\n",
        "        best_roots =  recombined_roots\n",
        "\n",
        "        final_score = get_score(m, n, best_roots)\n",
        "\n",
        "    # -- Cache Update  --\n",
        "    \"\"\"\n",
        "    \"Breaks\" are introduced periodically as cognitive interrupts. This method disrupts\n",
        "    local search patterns to enhance long-term exploration, analogous to stepping away from a problem to gain fresh perspective.\n",
        "    \"\"\"\n",
        "\n",
        "    # === \"Break\" Phase (Staccato Search) === # The interrupt part.\n",
        "\n",
        "    break_probability = 0.11 #Aggressive breaks - highter chances\n",
        "    break_type = rng.choice( ['root_reset', 'noise_injection'], p = [0.60, 0.40])  # Bias the selection towards root_reset:\n",
        "\n",
        "\n",
        "    # Pomodoro is all or nothing\n",
        "    if pomodoro_counter \u003e 0 and pomodoro_counter %pomodoro_interval == 0 and rng.random() \u003c break_probability:\n",
        "\n",
        "        if break_type == 'root_reset':\n",
        "            reset_indices = rng.choice(m, size=rng.integers(1, m // 3 + 1), replace=False)  # select random subset to be randomized.\n",
        "            best_roots[reset_indices] = rng.uniform(1, 200, size=len(reset_indices))  #  assign random samples\n",
        "\n",
        "        elif break_type == 'noise_injection':\n",
        "            noise = rng.normal(0,0.25 * n, size=m) #Aggressive disturbance!\n",
        "            best_roots = np.clip(best_roots + noise, 1, 200) # Add noise to the current best\n",
        "\n",
        "    final_score = get_score(m, n, best_roots)\n",
        "    # === End Break Phase -Pomodoro End! ===\n",
        "\n",
        "    # ----- Update the globals  -----\n",
        "\n",
        "    if final_score \u003e best_score: #Update highest scores.\n",
        "\n",
        "        best_score = final_score  #Store the final scores at the end\n",
        "\n",
        "        #Overwrite (the best).\n",
        "        state['best_score'] = best_score  # Store\n",
        "        state['best_roots'] = best_roots.copy()  # Store current\n",
        "\n",
        "        if variable_name in globals():\n",
        "            globals()[variable_name] = best_roots.copy()# update as well\n",
        "        else:\n",
        "            globals()[variable_name] = best_roots.copy()\n",
        "        no_improvement_counter = 0  # Reset on IMPROVEMENT\n",
        "\n",
        "        # Solution memory implementation - track only improved sols\n",
        "        is_present = any([(np.array_equal(best_roots, sol[0])) for sol in solution_memory])\n",
        "        if memory_replay_prob\u003e= 0.40 and not is_present: #Dont add duplicates (if larger )\n",
        "            solution_memory.append((best_roots.copy(), best_score))# Keep at max 5, and score.\n",
        "\n",
        "\n",
        "    jump_scale *= ( 1 + 0.013 * np.sin(pomodoro_counter + m + n))  #More dynamic\n",
        "    jump_scale =  min(jump_scale, 0.518 * n)  # clip the jump scale\n",
        "\n",
        "    # --Increase the no improve count--\n",
        "    no_improvement_counter += 1\n",
        "\n",
        "    #Add to Pomodoro counter- the more \"staccato\" this does, the larger it gets\n",
        "    pomodoro_counter += 1   #Move first, important.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    At conclusion of cycle, cache state is updated; the temperature parameter dictates annealing; jump scale enables variable disruption magnitude,\n",
        "    whilst tracking both no_improvement_counter and pomodoro_counter contributes signal to phase transition decisions,\n",
        "    that either exploit or abandon the incumbent best solution.\n",
        "    \"\"\"\n",
        "\n",
        "    # Simplified State Cache - Only Store Best Score \u0026 Roots\n",
        "    #Update State\n",
        "    state['temperature'] = temperature\n",
        "    state['jump_scale'] = jump_scale\n",
        "    state['no_improvement_counter'] = no_improvement_counter  # State cache only stores the \"count\"!\n",
        "    state['pomodoro_counter'] = pomodoro_counter  # Pomodoro counts.\n",
        "    ##\n",
        "\n",
        "    #If state resetted (we need to manually store) update\n",
        "    if 'state' in locals():\n",
        "        state['best_score'] = best_score\n",
        "        state['solution_memory'] = solution_memory # solution memory\n",
        "\n",
        "        state['best_roots'] = best_roots.copy() # Store back - this makes more sense now\n",
        "\n",
        "\n",
        "        ##Finally, store the state, if its present.\n",
        "        globals()['state'] = state #Global storage!\n",
        "\n",
        "    return best_roots.tolist()\n",
        "\n",
        "\n",
        "def get_roots(m: int, n: int) -\u003e list[float] | np.ndarray:\n",
        "    \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "    rng = np.random.default_rng(seed=m * 100 + n)\n",
        "    variable_name = f'suggested_roots_{m}'\n",
        "    bounds = [(1, 200)] * m\n",
        "\n",
        "    # --- Simulated Annealing Parameters ---\n",
        "    # --- Simulated Annealing Parameters ---\n",
        "    initial_temperature = 0.5 * (m + n)\n",
        "    cooling_rate = 0.995\n",
        "    pomodoro_interval = 20  # Define Pomodoro interval (cycles). To consider a good starting point for balancing exploration/exploitation\n",
        "    cognitive_load = 0.08  # Define cognitive load (probability of distraction)\n",
        "    random_perturbation_prob = 0.04 # Probability of strong random perturbation\n",
        "\n",
        "    # --- State Management ---\n",
        "    state = globals().get('state', { #Gets or reset\n",
        "        'temperature': initial_temperature, #Reset to new initial vals\n",
        "        'jump_scale': 0.1 * n,\n",
        "        'pomodoro_counter': 0,  # Track Pomodoro intervals\n",
        "        'best_score': float('-inf'),\n",
        "        'solution_memory': deque(maxlen=5),\n",
        "        'no_improvement_counter': 0,\n",
        "        'best_roots': None,\n",
        "    })\n",
        "    temperature = state['temperature']\n",
        "    jump_scale = state['jump_scale']\n",
        "    best_score = state['best_score']\n",
        "    solution_memory = state['solution_memory']\n",
        "    no_improvement_counter = state['no_improvement_counter']\n",
        "    pomodoro_counter = state['pomodoro_counter']\n",
        "\n",
        "    if state['best_roots'] is None:  # First run, none provided.\n",
        "        best_roots = np.array([rng.uniform(1, 200) for _ in range(m)])  #Initialize as well; we want to add historical ones.\n",
        "        was_random_start = True    #Keep track.\n",
        "    else:\n",
        "        best_roots = state['best_roots'].copy()\n",
        "        was_random_start = False #We didn't random start,\n",
        "\n",
        "\n",
        "\n",
        "    # Initialization with Prior Knowledge\n",
        "    use_prior = 0.3 + 0.3 * np.exp(-0.004 * m * n)\n",
        "    if variable_name in globals() and rng.random() \u003c use_prior:\n",
        "        best_roots = np.array(globals()[variable_name]).copy()\n",
        "        best_roots += rng.normal(0, temperature * 0.05 * n**0.3, size=m)   # Temperature dependent perturbation\n",
        "\n",
        "    else:\n",
        "        prime_nums = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97,\n",
        "                      101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193,\n",
        "                      197, 199]\n",
        "\n",
        "        # Introduce a \"Prime Resonance\" factor + more dynamic factor to promote escape behavior during convergence\n",
        "        prime_resonance = (prime_nums[m % len(prime_nums)] / prime_nums[-1]) * 0.02 + 0.005 * np.cos(time.time()*np.pi + m + n)  # small factor based on primes\n",
        "\n",
        "        base_spacing = n / (2.0 + 0.04 * m) + 1.1 + jump_scale * np.sin(\n",
        "            m * n / 5) + prime_resonance  # Jump scale and prime influence\n",
        "\n",
        "        # Fibonacci-based perturbation\n",
        "        fibonacci = [1, 1]\n",
        "        for k in range(2, m):\n",
        "            fibonacci.append((fibonacci[k-1] + fibonacci[k-2]) % 100) # Modulo to keep values small\n",
        "\n",
        "        best_roots = np.array([\n",
        "            i * base_spacing * (1 + 0.15 * (i / m)**1.5)  # Enhanced non-linear scaling (power law)\n",
        "            * (1 + 0.01 * prime_nums[i % len(prime_nums)] / prime_nums[-1])  # Prime-based MODULATION of spacing\n",
        "            * (1 + 0.005 * np.sin(i + prime_nums[i % len(prime_nums)]))  # Add Prime Resonance with sin\n",
        "            + 0.95 * n + jump_scale * 0.1 * i * np.cos(i * m)  # Reduced jump scale influence\n",
        "            + temperature * 0.01 * (fibonacci[i % m] / 100.0) * n  # Fibo.\n",
        "            + (i \u0026 prime_nums[i % len(prime_nums)]) * 0.00009 * n #BitWise with Prime number\n",
        "            * (1 + 0.001 * np.cos(np.sqrt(i+time.time()))) # More Modulation\n",
        "            + 0.002 * n * np.sin(prime_nums[(i + int(time.time())) % len(prime_nums)]*i/(m+1))\n",
        "\n",
        "            for i in range(1, m + 1)\n",
        "        ])\n",
        "\n",
        "    # --- Staccato Search (Pomodoro Technique) ---\n",
        "    current_score = get_score(m, n, best_roots)  # Current score.\n",
        "    best_score = globals().get('best_score', float('-inf'))\n",
        "\n",
        "    # === Global State Management Reset ===\n",
        "    reset_prob = (0.01 + pomodoro_counter*0.000025) #Adaptive\n",
        "    memory_replay_prob = 0.45    # Try to replay past configs- can help recover from bad decisions,\n",
        "\n",
        "    primes_used_for_reset = [3, 5, 7, 11, 13, 17]  # Primes to influence restarts\n",
        "    prime_to_use = primes_used_for_reset[m % len(primes_used_for_reset)]\n",
        "\n",
        "    # Check that best_roots is initialized\n",
        "    is_initialized = variable_name in globals() or best_roots is not None # check.\n",
        "\n",
        "    if is_initialized and pomodoro_counter \u003e 0 and pomodoro_counter %prime_to_use == 0 and rng.random() \u003c reset_prob:\n",
        "        if len(state['solution_memory']) \u003e 2 and rng.random() \u003c memory_replay_prob:\n",
        "\n",
        "            # Replay state history from the memory, make us eof other solutions.\n",
        "            selected_solution_index = rng.choice(len(solution_memory))\n",
        "            best_roots = solution_memory[selected_solution_index][0].copy() #Grab this old config.\n",
        "\n",
        "            print(\"\u003e\u003e\u003e REPLAY global best from state DICTIONARY \u003c\u003c\u003c\")\n",
        "        else:\n",
        "            # \"Forget\" the state by clearing the global dictionary.\n",
        "            del globals()['state'] #DELETE THE STATE!\n",
        "            state = {}\n",
        "            temperature = initial_temperature\n",
        "            jump_scale = 0.1 * n\n",
        "\n",
        "            print(\"\u003e\u003e\u003e STATE DICTIONARY RESET \u003c\u003c\u003c\")\n",
        "\n",
        "    #Reduced mutation\n",
        "    num_gradient_steps = int(m * 0.3)  # Further reduced gradient steps to let distractions work\n",
        "    for _ in range(num_gradient_steps):\n",
        "        i = rng.integers(0, m)\n",
        "        delta = 0.02 * n  # Smaller delta for gradient estimation\n",
        "        delta_2 = 0.008 * n  # Smaller delta for gradient estimation\n",
        "\n",
        "\n",
        "        # Apply cognitive load/distraction. For robustness\n",
        "        if rng.random() \u003c cognitive_load * (1 + np.sin(time.time())):  # Temporal load variation (external/Zeitgeist stimulus).\n",
        "             best_roots[i] += rng.normal(0, 0.08 * n)  # Small stochastic \"annoyance.\"\n",
        "             best_roots[i] = np.clip(best_roots[i], 1, 200)\n",
        "\n",
        "        # Adaptive Step Size (and direction finding)\n",
        "\n",
        "        original_root = best_roots[i]\n",
        "\n",
        "        # Random Perturbation\n",
        "        if rng.random() \u003c random_perturbation_prob:\n",
        "            best_roots[i] += rng.normal(0, n * 0.15) # Larger Perturbation\n",
        "            best_roots[i] = np.clip(best_roots[i], 1, 200) # Clip and then evaluate.\n",
        "\n",
        "        best_roots[i] = np.clip(original_root + delta, 1, 200)\n",
        "        score_plus = get_score(m, n, best_roots)\n",
        "        best_roots[i] = np.clip(original_root - delta, 1, 200)\n",
        "        score_minus = get_score(m, n, best_roots)\n",
        "        best_roots[i] = original_root  # Restore original root\n",
        "\n",
        "        if score_plus == -float('inf') and score_minus == -float('inf'):\n",
        "            gradient = 0.0\n",
        "        elif score_plus == -float('inf'):\n",
        "            gradient = -1.0\n",
        "        elif score_minus == -float('inf'):\n",
        "            gradient = 1.0\n",
        "        else:\n",
        "            gradient = (score_plus - score_minus) / (2 * delta)\n",
        "\n",
        "\n",
        "        # Adaptive Step Size and Momentum (Smoother updates)\n",
        "        # Higher learning rate if no recent improvements. Also inject number theoretic properties\n",
        "        aggression_factor = 1.0 + 0.4 * np.tanh(no_improvement_counter / 20.0) * np.sin(prime_nums[i%len(prime_nums)])\n",
        "        step_size = 0.03 * n * aggression_factor / (1 + np.abs(gradient))  # Adjust scaling here!\n",
        "\n",
        "        momentum = 0.5  # Add momentum for smoother gradient descent\n",
        "\n",
        "        # Ensure that momentum is initialized in the scope or increase!\n",
        "        if 'momentum_values' not in locals():\n",
        "            momentum_values = np.zeros(m)\n",
        "\n",
        "        momentum_values[i] = momentum * momentum_values[i] + (1 - momentum) * step_size * gradient  # Momentum\n",
        "\n",
        "        \"\"\"\n",
        "        A combinatorics augmented number theory-based perturbation is applied as part of the update, involving the injection of finely-tuned stochastic noise to enhance exploration within the solution space.\n",
        "        \"\"\"\n",
        "\n",
        "        best_roots[i] = np.clip(best_roots[i] + momentum_values[i], 1, 200) # momentum step\n",
        "\n",
        "\n",
        "    # --- Final Touches, reduced noise --- --Increase level - for final kick!\n",
        "    noise = rng.normal(0, (n * 0.015 + np.sqrt(np.arange(m)) *0.05) * temperature * 0.08, size=m)  # Reduced final noise.\n",
        "\n",
        "    best_roots = np.clip(best_roots + noise, 1, 200)  # reduced final noise.\n",
        "    final_score = get_score(m, n, best_roots)\n",
        "\n",
        "    # -- Stochastic Restart Mechanism --\n",
        "    restart_prob = 0.001 + 0.005 * np.exp(no_improvement_counter / 40)  # Adaptive restart probability\n",
        "    num_number_jump = len(prime_nums) # number list\n",
        "    if rng.random() \u003c restart_prob:        # More Restarts, bigger range and power laws.\n",
        "\n",
        "        num_to_restart = rng.integers(1,min(m // 2 + 1, num_number_jump))  # Restart a portion of roots\n",
        "        indices_to_restart = rng.choice(m, size=num_to_restart, replace=False)\n",
        "        for j in indices_to_restart:    #Inject from primes now\n",
        "            best_roots[j] = prime_nums[j % num_number_jump] + rng.normal(0,0.5 * n) # from prime number as seeding pt\n",
        "\n",
        "        final_score = get_score(m, n, best_roots) #Update the scores\n",
        "\n",
        "    current_shuffle_prob = 0.07 # Base probability\n",
        "    current_shuffle_prob += (1 - np.exp(-0.001 * m * n)) * 0.5  # Adaptive, less if m*n large\n",
        "    # --- \"Aggressive Remix\"- to force it out!---\n",
        "    # This aggressively remixes the population.\n",
        "    if rng.random() \u003c current_shuffle_prob and best_roots is not None:  # If score gets bad.\n",
        "\n",
        "        # Create radically different children.\n",
        "        noise = rng.normal(0, 0.15 *n, size=m)\n",
        "        prime_scaling = ( primes[m % len(primes)] * 0.01 / sum(primes[:min(m, len(primes))])) if m\u003e0 else 0 # Small Prime Factors.\n",
        "\n",
        "        recombined_roots = np.clip(best_roots *  np.sin(time.time()) + noise + prime_scaling, 1, 200) # Prime Mod\n",
        "        best_roots =  recombined_roots\n",
        "\n",
        "        final_score = get_score(m, n, best_roots)\n",
        "\n",
        "    # -- Cache Update  --\n",
        "    \"\"\"\n",
        "    \"Breaks\" are introduced periodically as cognitive interrupts. This method disrupts\n",
        "    local search patterns to enhance long-term exploration, analogous to stepping away from a problem to gain fresh perspective.\n",
        "    \"\"\"\n",
        "\n",
        "    # === \"Break\" Phase (Staccato Search) === # The interrupt part.\n",
        "\n",
        "    break_probability = 0.11 #Aggressive breaks - highter chances\n",
        "    break_type = rng.choice( ['root_reset', 'noise_injection'], p = [0.60, 0.40])  # Bias the selection towards root_reset:\n",
        "\n",
        "\n",
        "    # Pomodoro is all or nothing\n",
        "    if pomodoro_counter \u003e 0 and pomodoro_counter %pomodoro_interval == 0 and rng.random() \u003c break_probability:\n",
        "\n",
        "        if break_type == 'root_reset':\n",
        "            reset_indices = rng.choice(m, size=rng.integers(1, m // 3 + 1), replace=False)  # select random subset to be randomized.\n",
        "            best_roots[reset_indices] = rng.uniform(1, 200, size=len(reset_indices))  #  assign random samples\n",
        "\n",
        "        elif break_type == 'noise_injection':\n",
        "            noise = rng.normal(0,0.25 * n, size=m) #Aggressive disturbance!\n",
        "            best_roots = np.clip(best_roots + noise, 1, 200) # Add noise to the current best\n",
        "\n",
        "    final_score = get_score(m, n, best_roots)\n",
        "    # === End Break Phase -Pomodoro End! ===\n",
        "\n",
        "    # ----- Update the globals  -----\n",
        "\n",
        "    if final_score \u003e best_score: #Update highest scores.\n",
        "\n",
        "        best_score = final_score  #Store the final scores at the end\n",
        "\n",
        "        #Overwrite (the best).\n",
        "        state['best_score'] = best_score  # Store\n",
        "        state['best_roots'] = best_roots.copy()  # Store current\n",
        "\n",
        "        if variable_name in globals():\n",
        "            globals()[variable_name] = best_roots.copy()# update as well\n",
        "        else:\n",
        "            globals()[variable_name] = best_roots.copy()\n",
        "        no_improvement_counter = 0  # Reset on IMPROVEMENT\n",
        "\n",
        "        # Solution memory implementation - track only improved sols\n",
        "        is_present = any([(np.array_equal(best_roots, sol[0])) for sol in solution_memory])\n",
        "        if memory_replay_prob\u003e= 0.40 and not is_present: #Dont add duplicates (if larger )\n",
        "            solution_memory.append((best_roots.copy(), best_score))# Keep at max 5, and score.\n",
        "\n",
        "\n",
        "    jump_scale *= ( 1 + 0.013 * np.sin(pomodoro_counter + m + n))  #More dynamic\n",
        "    jump_scale =  min(jump_scale, 0.518 * n)  # clip the jump scale\n",
        "\n",
        "    # --Increase the no improve count--\n",
        "    no_improvement_counter += 1\n",
        "\n",
        "    #Add to Pomodoro counter- the more \"staccato\" this does, the larger it gets\n",
        "    pomodoro_counter += 1   #Move first, important.\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    At conclusion of cycle, cache state is updated; the temperature parameter dictates annealing; jump scale enables variable disruption magnitude,\n",
        "    whilst tracking both no_improvement_counter and pomodoro_counter contributes signal to phase transition decisions,\n",
        "    that either exploit or abandon the incumbent best solution.\n",
        "    \"\"\"\n",
        "\n",
        "    # Simplified State Cache - Only Store Best Score \u0026 Roots\n",
        "    #Update State\n",
        "    state['temperature'] = temperature\n",
        "    state['jump_scale'] = jump_scale\n",
        "    state['no_improvement_counter'] = no_improvement_counter  # State cache only stores the \"count\"!\n",
        "    state['pomodoro_counter'] = pomodoro_counter  # Pomodoro counts.\n",
        "    ##\n",
        "\n",
        "    #If state resetted (we need to manually store) update\n",
        "    if 'state' in locals():\n",
        "        state['best_score'] = best_score\n",
        "        state['solution_memory'] = solution_memory # solution memory\n",
        "\n",
        "        state['best_roots'] = best_roots.copy() # Store back - this makes more sense now\n",
        "\n",
        "\n",
        "        ##Finally, store the state, if its present.\n",
        "        globals()['state'] = state #Global storage!\n",
        "\n",
        "    return best_roots.tolist()\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AtCMHEZrJFDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uncertainty principles"
      ],
      "metadata": {
        "id": "XVyDJXqZOhJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt for the search setup**\n",
        "\n",
        "You are a research mathematician and an expert software developer.\n",
        "Your task is to optimize linear combinations of Laguerre polynomials with\n",
        "certain properties.\n",
        "\n",
        "For a given pair of natural number m we consider the following\n",
        "construction.\n",
        "\n",
        "Let $g_k(x) = L_k^\\alpha(x)$ where $L_k^\\alpha(x)$ denotes the standard\n",
        "generalized Laguerre polynomial of degree k and order $\\alpha = (1 / 2) - 1$.\n",
        "\n",
        "First, select a collection of m positive real numbers z_1, z_2, \\dots, z_m.\n",
        "\n",
        "Then let g(x) be a linear combination of even degree g_k's up to order $4m + 3$\n",
        "i.e. a linear sum of g_0, g_2, \\dots, g_(4m + 2). The coefficients of this\n",
        "linear combination are chosen such that z_1, \\dots, z_m are double roots and\n",
        "g(0) = 0 and g'(0) = 1 (Counting degrees of freedom implies that there is a\n",
        "unique such linear combination g(x)).\n",
        "\n",
        "Finally, define $r$ to be the largest positive sign change of the polynomial\n",
        "g(x).\n",
        "\n",
        "GOAL:\n",
        "Your optimization task is, for a given natural number m, to find a\n",
        "collection of m positive real numbers z_1, z_2, \\dots, z_m such that the\n",
        "polynomial g(x) has the smallest possible value of r.\n",
        "\n",
        "Specifically, the Python function you have to provide has the following\n",
        "signature:\n",
        "\n",
        "def get_roots(m: int) -\u003e list[float] | np.ndarray:\n",
        "\n",
        "The function get_roots returns the one-dimensional array z of size m consisting\n",
        "of the positive real numbers $z_i$ for $i = 1, \\dots, m$.\n",
        "\n",
        "HINTS:\n",
        "1. For m = 5, the following list is a good initial guess:\n",
        "[3.6331003, 5.6714292, 33.09981679, 41.1543366, 50.98385922]\n",
        "\n",
        "2. Try to find constructions of roots that are not too spread apart or too\n",
        "large. The absolute values of the roots z_i should be not larger than 300.\n",
        "\n",
        "The score of z is given by the corresponding value of r. To compute this use\n",
        "precise fractional arithmetic in sympy.\n",
        "\n",
        "The exact score function your construction will be evaluated on is given below:\n",
        "\n",
        "def get_score(zs: np.ndarray | list[float]) -\u003e float:\n",
        "  \"\"\"Returns the score of the given Laguerre combination.\"\"\"\n",
        "\n",
        "  g_fn = find_laguerre_combination(zs)\n",
        "  x = sympy.symbols('x')\n",
        "  dg_fn = sympy.diff(g_fn, x)\n",
        "\n",
        "  div = sympy.prod([(x - sympy.Rational(z)) ** 2 for z in zs]) * x\n",
        "  gq_fn = sympy.exquo(g_fn, div)\n",
        "\n",
        "  g_fn.subs(x, sympy.Rational(0))\n",
        "  dg_fn.subs(x, sympy.Rational(1))\n",
        "\n",
        "  for z in zs:\n",
        "    if g_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return ROOTS_NOT_ENFORCED\n",
        "    if dg_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return DERIVATIVES_NOT_ENFORCED\n",
        "\n",
        "  real_roots = sympy.real_roots(gq_fn, x)\n",
        "  if not real_roots:\n",
        "    return NO_SIGN_CHANGES\n",
        "\n",
        "  approx_roots = list()\n",
        "  largest_sign_change = 0\n",
        "\n",
        "  for root in real_roots:\n",
        "    approx_root = root.eval_rational(n=200)\n",
        "    approx_root_p = approx_root + sympy.Rational(1e-198)\n",
        "    approx_root_m = approx_root - sympy.Rational(1e-198)\n",
        "    approx_roots.append(approx_root)\n",
        "    is_sign_change = (\n",
        "        gq_fn.subs(x, approx_root_p) \u003e 0 and gq_fn.subs(x, approx_root_m) \u003c 0\n",
        "    ) or (gq_fn.subs(x, approx_root_p) \u003c 0 and gq_fn.subs(x, approx_root_m) \u003e 0)\n",
        "    if is_sign_change:\n",
        "      largest_sign_change = max(largest_sign_change, approx_root)\n",
        "\n",
        "  return np.sqrt(float(largest_sign_change) / 2 / np.pi)\n",
        "\n",
        "Note that the score function uses the find_laguerre_combination(zs) method\n",
        "to obtain the polynomial g(x) given z via exact fractional arithmetic in sympy.\n",
        "\n",
        "You may code up any search method you want, and you are allowed to call the\n",
        "get_score() function as many times as you want. You have access to it, you don't\n",
        "need to code up the get_score() function.\n",
        "You want the score it gives you to be as high as possible!\n",
        "\n",
        "Your task is to write a search function that searches for the best list.\n",
        "Your function will have 1000 seconds to run, and after that it has to have\n",
        "returned the best construction it found. If after 1000 seconds it has not\n",
        "returned anything, it will be terminated with negative infinity points. You can\n",
        "use your time best if you have an outer loop of the form\n",
        "\"while time.time() - start_time \u003c 1000:\" or similar, just don't forget to define\n",
        "the \"start_time\" variable early in your program. You may choose n, the length of\n",
        "the list, to be anything in this experiment. Larger values of n have more\n",
        "potential for bigger scores, but the search space is larger so they are harder\n",
        "to find. You'll have to balance it accordingly!"
      ],
      "metadata": {
        "id": "IYIFr3KvX1yF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompts for search setup with starting hints for 5 roots**\n",
        "\n",
        "You are a research mathematician and an expert software developer.\n",
        "Your task is to optimize linear combinations of Laguerre polynomials with\n",
        "certain properties.\n",
        "\n",
        "For a given pair of natural number m we consider the following\n",
        "construction.\n",
        "\n",
        "Let $g_k(x) = L_k^\\alpha(x)$ where $L_k^\\alpha(x)$ denotes the standard\n",
        "generalized Laguerre polynomial of degree k and order $\\alpha = (1 / 2) - 1$.\n",
        "\n",
        "First, select a collection of m positive real numbers z_1, z_2, \\dots, z_m.\n",
        "\n",
        "Then let g(x) be a linear combination of even degree g_k's up to order $4m + 3$\n",
        "i.e. a linear sum of g_0, g_2, \\dots, g_(4m + 2). The coefficients of this\n",
        "linear combination are chosen such that z_1, \\dots, z_m are double roots and\n",
        "g(0) = 0 and g'(0) = 1 (Counting degrees of freedom implies that there is a\n",
        "unique such linear combination g(x)).\n",
        "\n",
        "Finally, define $r$ to be the largest positive sign change of the polynomial\n",
        "g(x).\n",
        "\n",
        "GOAL:\n",
        "Your optimization task is, for a given natural number m, to find a\n",
        "collection of m positive real numbers z_1, z_2, \\dots, z_m such that the\n",
        "polynomial g(x) has the smallest possible value of r.\n",
        "\n",
        "Specifically, the Python function you have to provide has the following\n",
        "signature:\n",
        "\n",
        "def get_roots(m: int) -\u003e list[float] | np.ndarray:\n",
        "\n",
        "The function get_roots returns the one-dimensional array z of size m consisting\n",
        "of the positive real numbers $z_i$ for $i = 1, \\dots, m$.\n",
        "\n",
        "HINTS:\n",
        "1. For m = 5, the following list is a good initial guess:\n",
        "[3.6331003, 5.6714292, 33.09981679, 41.1543366, 50.98385922]\n",
        "Similarly, for m = 2 a good initial guess is:\n",
        "[5.00115031, 42.3186769]\n",
        "For m = 6, the following list is a good initial guess:\n",
        "[41.65007642, 40.31923115, 40.14619073, 5.54073594, 45.31997179, 3.60084242]\n",
        "2. For m = 6 try using the above construction for m = 5 and adding a new root\n",
        "e.g. around 60. Then try optimizing the roots further starting from there.\n",
        "3. Try to find constructions of roots that are not too spread apart or too\n",
        "large. The absolute values of the roots z_i should be not larger than 300.\n",
        "\n",
        "The score of z is given by the corresponding value of r. To compute this use\n",
        "precise fractional arithmetic in sympy.\n",
        "\n",
        "SCORING:\n",
        "The exact score function your construction will be evaluated on is given below:\n",
        "\n",
        "def get_score(zs: np.ndarray | list[float]) -\u003e float:\n",
        "  \"\"\"Returns the score of the given Laguerre combination.\"\"\"\n",
        "\n",
        "  g_fn = find_laguerre_combination(zs)\n",
        "  x = sympy.symbols('x')\n",
        "  dg_fn = sympy.diff(g_fn, x)\n",
        "\n",
        "  div = sympy.prod([(x - sympy.Rational(z)) ** 2 for z in zs]) * x\n",
        "  gq_fn = sympy.exquo(g_fn, div)\n",
        "\n",
        "  g_fn.subs(x, sympy.Rational(0))\n",
        "  dg_fn.subs(x, sympy.Rational(1))\n",
        "\n",
        "  for z in zs:\n",
        "    if g_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return -ROOTS_NOT_ENFORCED\n",
        "    if dg_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return -DERIVATIVES_NOT_ENFORCED\n",
        "\n",
        "  real_roots = sympy.real_roots(gq_fn, x)\n",
        "  if not real_roots:\n",
        "    return -NO_SIGN_CHANGES\n",
        "\n",
        "  approx_roots = list()\n",
        "  largest_sign_change = 0\n",
        "\n",
        "  for root in real_roots:\n",
        "    approx_root = root.eval_rational(n=200)\n",
        "    approx_root_p = approx_root + sympy.Rational(1e-198)\n",
        "    approx_root_m = approx_root - sympy.Rational(1e-198)\n",
        "    approx_roots.append(approx_root)\n",
        "    is_sign_change = (\n",
        "        gq_fn.subs(x, approx_root_p) \u003e 0 and gq_fn.subs(x, approx_root_m) \u003c 0\n",
        "    ) or (gq_fn.subs(x, approx_root_p) \u003c 0 and gq_fn.subs(x, approx_root_m) \u003e 0)\n",
        "    if is_sign_change:\n",
        "      largest_sign_change = max(largest_sign_change, approx_root)\n",
        "\n",
        "  return -np.sqrt(float(largest_sign_change) / 2 / np.pi)\n",
        "\n",
        "Note that the score function uses the find_laguerre_combination(zs) method\n",
        "to obtain the polynomial g(x) given z via exact fractional arithmetic in sympy.\n",
        "\n",
        "You may code up any search method you want, and you are allowed to call the\n",
        "get_score() function as many times as you want. You have access to it, you don't\n",
        "need to code up the get_score() function.\n",
        "You want the score it gives you to be as high as possible!\n",
        "\n",
        "Your task is to write a search function that searches for the best list.\n",
        "Your function will have 1000 seconds to run, and after that it has to have\n",
        "returned the best construction it found. If after 1000 seconds it has not\n",
        "returned anything, it will be terminated with negative infinity points. You can\n",
        "use your time best if you have an outer loop of the form\n",
        "\"while time.time() - start_time \u003c 1000:\" or similar, just don't forget to define\n",
        "the \"start_time\" variable early in your program. You may choose m, the length of\n",
        "the list, to be anything in this experiment. Larger values of m have more\n",
        "potential for bigger scores, but the search space is larger so they are harder\n",
        "to find. You'll have to balance it accordingly!"
      ],
      "metadata": {
        "id": "yTuAEH4JO7JR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluation\n",
        "\n",
        "ROOTS_NOT_ENFORCED = 10000\n",
        "WRONG_Z_SHAPE = 10001\n",
        "DERIVATIVES_NOT_ENFORCED = 10002\n",
        "NO_SIGN_CHANGES = 10003\n",
        "SUGGESTED_ROOTS_TOO_LARGE = 10004\n",
        "\n",
        "\n",
        "def find_laguerre_combination(z) -\u003e sympy.Expr:\n",
        "  \"\"\"Computing Laguerre combinations for given roots.\"\"\"\n",
        "  n = 1\n",
        "  m = len(z)\n",
        "  alpha = sympy.Rational(n, 2) - 1\n",
        "  degrees = np.arange(0, 4 * m + 4, 2)\n",
        "  x = sympy.symbols('x')\n",
        "  lps = [\n",
        "      sympy.polys.orthopolys.laguerre_poly(n=i, x=x, alpha=alpha, polys=False)\n",
        "      for i in degrees\n",
        "  ]\n",
        "\n",
        "  num_lps = len(lps)\n",
        "  num_conditions = 2 * m + 2  # Root at 0, double roots at z_i\n",
        "\n",
        "  if num_lps \u003c num_conditions:\n",
        "    raise ValueError(\n",
        "        'Not enough Laguerre polynomials to satisfy all conditions.'\n",
        "    )\n",
        "\n",
        "  # Create a system of linear equations to solve for alpha_i\n",
        "  mat = sympy.Matrix(num_conditions, num_lps, lambda i, j: 0)\n",
        "  b = sympy.Matrix(num_conditions, 1, lambda i, j: 0)\n",
        "\n",
        "  b[1] = 1  # Set g'(0) = const\n",
        "\n",
        "  # Condition 1: Root at 0 (g(0) = 0)\n",
        "  for j in range(num_lps):\n",
        "    mat[0, j] = lps[j].subs(x, 0)\n",
        "    mat[1, j] = lps[j].diff(x).subs(x, 0)\n",
        "\n",
        "  # Conditions 2 to 2m+2: Double roots at z_i (g(z_i) = 0 and g'(z_i) = 0)\n",
        "  for i in range(0, m):\n",
        "    zi = sympy.Rational(z[i])\n",
        "\n",
        "    # g(z_i) = 0\n",
        "    for j in range(num_lps):\n",
        "      mat[2 * i + 2, j] = lps[j].subs(x, zi)\n",
        "\n",
        "    # g'(z_i) = 0 (derivative with respect to x)\n",
        "    for j in range(num_lps):\n",
        "      deriv_lp_j = lps[j].diff(x)\n",
        "      mat[2 * i + 3, j] = deriv_lp_j.subs(x, zi)\n",
        "\n",
        "  # Solve the linear system Ax = b for x (coefficients alpha_i)\n",
        "  x = mat.LUsolve(b)\n",
        "  alpha_coeffs = [x[i] for i in range(num_lps)]\n",
        "  g_fn = sum(alpha_coeffs[i] * lps[i] for i in range(len(alpha_coeffs)))\n",
        "  return g_fn\n",
        "\n",
        "\n",
        "def get_score(zs: np.ndarray | list[float]) -\u003e float:\n",
        "  \"\"\"Returns the score of the given Laguerre combination.\"\"\"\n",
        "\n",
        "  g_fn = find_laguerre_combination(zs)\n",
        "  x = sympy.symbols('x')\n",
        "  dg_fn = sympy.diff(g_fn, x)\n",
        "\n",
        "  div = sympy.prod([(x - sympy.Rational(z)) ** 2 for z in zs]) * x\n",
        "  gq_fn = sympy.exquo(g_fn, div)\n",
        "\n",
        "  g_fn.subs(x, sympy.Rational(0))\n",
        "  dg_fn.subs(x, sympy.Rational(1))\n",
        "\n",
        "  for z in zs:\n",
        "    if g_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return -ROOTS_NOT_ENFORCED\n",
        "    if dg_fn.subs(x, sympy.Rational(z)) != 0:\n",
        "      return -DERIVATIVES_NOT_ENFORCED\n",
        "\n",
        "  real_roots = sympy.real_roots(gq_fn, x)\n",
        "  if not real_roots:\n",
        "    return -NO_SIGN_CHANGES\n",
        "\n",
        "  approx_roots = list()\n",
        "  largest_sign_change = 0\n",
        "\n",
        "  for root in real_roots:\n",
        "    approx_root = root.eval_rational(n=200)\n",
        "    approx_root_p = approx_root + sympy.Rational(1e-198)\n",
        "    approx_root_m = approx_root - sympy.Rational(1e-198)\n",
        "    approx_roots.append(approx_root)\n",
        "    is_sign_change = (\n",
        "        gq_fn.subs(x, approx_root_p) \u003e 0 and gq_fn.subs(x, approx_root_m) \u003c 0\n",
        "    ) or (gq_fn.subs(x, approx_root_p) \u003c 0 and gq_fn.subs(x, approx_root_m) \u003e 0)\n",
        "    if is_sign_change:\n",
        "      largest_sign_change = max(largest_sign_change, approx_root)\n",
        "\n",
        "  return -np.sqrt(float(largest_sign_change) / 2 / np.pi)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LM2iD5WSPG9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initial programs\n",
        "\n",
        "\n",
        "def get_roots(m: int) -\u003e list[float] | np.ndarray:\n",
        "  \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "  variable_name = f'suggested_roots_{m}'\n",
        "\n",
        "  best_roots = np.arange(1, m + 1)\n",
        "\n",
        "  if m == 2:\n",
        "    best_roots = [5.00115031, 42.3186769]\n",
        "\n",
        "  if np.random.rand() \u003c 0.5 and variable_name in globals():\n",
        "    best_roots = globals()[variable_name]\n",
        "\n",
        "  curr_positions = best_roots.copy()\n",
        "  best_score = get_score(best_roots)\n",
        "\n",
        "  start_time = time.time()\n",
        "  while time.time() - start_time \u003c 100:  # Search for 100 seconds\n",
        "    random_index = np.random.randint(0, len(curr_positions))\n",
        "    curr_positions[random_index:] += 1e-1 * np.random.randint(-10, 10)\n",
        "    curr_score = get_score(curr_positions)\n",
        "    if curr_score \u003e best_score:\n",
        "      best_score = curr_score\n",
        "      best_roots = curr_positions.copy()\n",
        "      print(f\"Best score: {best_score}\")\n",
        "\n",
        "  return best_roots"
      ],
      "metadata": {
        "cellView": "form",
        "id": "i4uJhywuPZv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Constructions obtained by AlphaEvolve\n",
        "\n",
        "# 6 roots\n",
        "z_6 = [3.64273649, 5.68246114, 33.00463486, 40.97185579, 50.1028231, 53.76768016]\n",
        "# 7 roots\n",
        "z_7 = [3.64913287, 5.67235784, 38.79096469, 32.62677356, 45.48028355, 52.97276933, 106.77886152]\n",
        "# 8 roots\n",
        "z_8 = [3.64386938, 5.69329786, 32.38322129, 38.90891377, 45.14892756, 53.11575866, 99.06784500, 122.102121266]\n",
        "# 9 roots\n",
        "z_9 = [3.65229523, 5.69674475, 32.13629449, 38.30580848, 44.53027128, 52.78630070, 98.67722817, 118.22167413, 133.59986194]\n",
        "# 10 roots\n",
        "z_10 = [3.6331003, 5.6714292, 33.09981679, 38.35917516, 41.1543366, 50.98385922, 59.75317169, 94.27439607, 119.86075361, 136.35793559]\n",
        "\n",
        "\n",
        "# Upper bounds on the uncertainty constant e.g.:\n",
        "# get_score(z_7)**2\n",
        "# get_score(z_8)**2"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Q4W2boRnQ5sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Programs obtained by AlphaEvolve\n",
        "\n",
        "\n",
        "\n",
        "def get_roots(m: int) -\u003e list[float] | np.ndarray:\n",
        "  \"\"\"Generate roots to for optimal Laguerre combination.\"\"\"\n",
        "\n",
        "  # Set a seed for reproducibility (Optional, removed for more varied runs)\n",
        "  # np.random.seed(42)\n",
        "\n",
        "  # Start optimization time\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Flag to indicate if Nelder-Mead has made recent progress.  Reset every iteration.\n",
        "  nelder_mead_progress = False\n",
        "\n",
        "  best_score = -float('inf')\n",
        "  best_roots = None\n",
        "  bounds = [(1e-9, 300.0)] * m\n",
        "\n",
        "  # Initialize global best roots list\n",
        "  global_best_roots_list = []\n",
        "\n",
        "  # Start optimization time\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Pre-defined good initial guesses\n",
        "  known_good_roots = {\n",
        "      1: np.array([40.0]),\n",
        "      2: np.array([5.00115031, 42.3186769]),\n",
        "      3: np.array([4.0, 5.0, 42.0]), # Example: simple structured guess\n",
        "      4: np.array([4.0, 5.0, 40.0, 45.0]), # Example: simple structured guess\n",
        "      5: np.array([3.6331003, 5.6714292, 33.09981679, 41.1543366, 50.98385922]),\n",
        "      6: np.array([3.60084242, 5.54073594, 40.14619073, 40.31923115, 41.65007642, 45.31997179]), # Sorted version of the hint\n",
        "      7: np.array([3.5, 5.5, 30.0, 35.0, 40.0, 45.0, 50.0]), # Structured guess for m=7\n",
        "      8: np.array([3.5, 5.5, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0]), # Structured guess for m=8\n",
        "      12: np.array([3.5, 5.5, 30.0, 35.0, 40.0, 45.0, 50.0, 55.0, 60.0, 65.0, 70.0, 75.0]) # Structured guess for m=12\n",
        "  }\n",
        "\n",
        "  initial_guesses_list = []\n",
        "\n",
        "  # Strategy 1: Use known good guesses\n",
        "  if m in known_good_roots:\n",
        "      initial_guesses_list.append(np.sort(known_good_roots[m]))\n",
        "\n",
        "  # Strategy 2: Structured guesses for other m\n",
        "  if m \u003e 6:\n",
        "      # Approach 2a: Two small roots, rest spaced out (refined)\n",
        "      num_small = 2\n",
        "      if m - num_small \u003e= 0:\n",
        "         small_roots = [4.0, 5.0]\n",
        "         if m \u003e num_small:\n",
        "             start_val_a = 30.0 + (m-num_small) * 2.5\n",
        "             end_val_a = 70.0 + (m-num_small) * 3 + m\n",
        "             large_roots_a = list(np.linspace(start_val_a, end_val_a, m - num_small))\n",
        "             initial_guesses_list.append(np.sort(np.array(small_roots + large_roots_a)))\n",
        "         elif m == num_small:\n",
        "              initial_guesses_list.append(np.sort(np.array(small_roots)))\n",
        "\n",
        "      # Add another structured guess: spaced out with increasing gaps (exponential)\n",
        "      if m \u003e 1:\n",
        "          structured_start_exp = 5.0\n",
        "          structured_end_exp = 150.0 + m * 8 # Increased end range\n",
        "          # Use log space for a more exponential-like spacing\n",
        "          structured_roots_exp = np.exp(np.linspace(np.log(structured_start_exp), np.log(structured_end_exp), m))\n",
        "          initial_guesses_list.append(np.sort(np.clip(np.array(structured_roots_exp), bounds[0][0], bounds[0][1])))\n",
        "\n",
        "      # Add a structured guess with roots clustered at the lower end and then spaced out\n",
        "      if m \u003e 2:\n",
        "          num_clustered = max(2, int(m * 0.2)) # Cluster a percentage of roots\n",
        "          clustered_roots = np.linspace(4.0, 10.0 + m*0.5, num_clustered)\n",
        "          if m \u003e num_clustered:\n",
        "              remaining_roots_start = clustered_roots[-1] + 10.0\n",
        "              remaining_roots_end = 200.0 + m * 10\n",
        "              remaining_roots = np.linspace(remaining_roots_start, remaining_roots_end, m - num_clustered)\n",
        "              initial_guesses_list.append(np.sort(np.clip(np.concatenate([clustered_roots, remaining_roots]), bounds[0][0], bounds[0][1])))\n",
        "\n",
        "\n",
        "  # Strategy 3: Add some random guesses\n",
        "  num_random_guesses = 4 if m \u003c= 10 else 2 # Keep a few random for diversity\n",
        "  for _ in range(num_random_guesses):\n",
        "       random_guess = np.random.uniform(1.0, 200.0 + m*10, m) # Range scaled with m\n",
        "       initial_guesses_list.append(np.sort(np.array(random_guess)))\n",
        "\n",
        "  # Add perturbations of known good roots for smaller m (sorted)\n",
        "  if m \u003e 2:\n",
        "      for prev_m in range(2, min(m, 13)): # Extended check for known small m values\n",
        "          if prev_m in known_good_roots:\n",
        "              prev_roots = known_good_roots[prev_m]\n",
        "              if m - prev_m \u003e 0:\n",
        "                  for _ in range(3): # Add more permutations with new roots\n",
        "                      # Add new roots in a reasonable range\n",
        "                      new_roots_added = np.random.uniform(30.0, 150.0 + m*5, m - prev_m)\n",
        "                      combined_roots = np.concatenate([prev_roots, new_roots_added])\n",
        "                      if len(combined_roots) == m:\n",
        "                           initial_guesses_list.append(np.sort(np.clip(combined_roots, bounds[0][0], bounds[0][1])))\n",
        "\n",
        "\n",
        "  # Clean and unique initial guesses, ensure sorted\n",
        "  initial_guesses_list = [np.array(sorted(g)) for g in initial_guesses_list if len(g) == m]\n",
        "  # Use set to remove duplicates (convert to tuple for hashability)\n",
        "  unique_guesses_tuples = set(tuple(g.tolist()) for g in initial_guesses_list)\n",
        "  initial_guesses_queue = [np.array(g) for g in unique_guesses_tuples]\n",
        "\n",
        "  # Prioritize known good roots if they are in the initial guesses\n",
        "  if m in known_good_roots:\n",
        "      known_good = np.sort(known_good_roots[m])\n",
        "      if any(np.array_equal(guess, known_good) for guess in initial_guesses_queue):\n",
        "          # Move the known good guess to the front of the queue\n",
        "          initial_guesses_queue.insert(0, initial_guesses_queue.pop([i for i, guess in enumerate(initial_guesses_queue) if np.array_equal(guess, known_good)][0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  while time.time() - start_time \u003c 985 and len(initial_guesses_queue) \u003e 0:\n",
        "\n",
        "      initial_guess = initial_guesses_queue.pop(0)\n",
        "      initial_guess = np.clip(initial_guess, bounds[0][0], bounds[0][1])\n",
        "\n",
        "      # Check remaining time before starting a new optimization run\n",
        "      if time.time() - start_time \u003e= 985:\n",
        "          break\n",
        "\n",
        "      try:\n",
        "          # Slightly increase max iterations per attempt\n",
        "          max_iter_per_attempt = max(400, 60 * m)\n",
        "          if m \u003e 15: max_iter_per_attempt = max(300, 40 * m)\n",
        "          if m \u003e 20: max_iter_per_attempt = max(200, 30 * m)\n",
        "\n",
        "          # Add an absolute function evaluation limit as well, capped globally\n",
        "          max_fevals_per_attempt_nm = min(max_iter_per_attempt * 1.5, 80000 + m * 2000) # Increased cap with m\n",
        "\n",
        "          # Run Nelder-Mead first\n",
        "          nm_result = scipy.optimize.minimize(\n",
        "              objective_function,\n",
        "              initial_guess,\n",
        "              method='Nelder-Mead',\n",
        "              bounds=bounds,\n",
        "              options={\n",
        "                  'maxiter': max_iter_per_attempt,\n",
        "                  'maxfev': max_fevals_per_attempt_nm,\n",
        "                  'disp': False\n",
        "                  }\n",
        "          )\n",
        "\n",
        "          nm_current_roots = nm_result.x\n",
        "          nm_current_roots = np.clip(nm_current_roots, bounds[0][0], bounds[0][1])\n",
        "          nm_current_score = get_score(nm_current_roots)\n",
        "\n",
        "          current_best_roots = nm_current_roots\n",
        "          current_best_score = nm_current_score\n",
        "\n",
        "          if current_best_score is not None and current_best_score \u003e -1e9:\n",
        "               if current_best_score \u003e best_score:\n",
        "                  # Found a new best score with NM or DE\n",
        "                  best_score = current_best_score\n",
        "                  best_roots = current_best_roots.tolist()\n",
        "                  # Add to global best roots list (keeping it relatively small and diverse)\n",
        "                  global_best_roots_list.append(best_roots)\n",
        "                  # Keep the global_best_roots_list sorted by score and limit its size\n",
        "                  global_best_roots_list = sorted(global_best_roots_list, key=lambda x: get_score(x) if get_score(x) is not None else -float('inf'), reverse=True)\n",
        "                  global_best_roots_list = global_best_roots_list[:max(5, m)] # Limit size\n",
        "\n",
        "                  # print(f\"Found new best score (NM): {best_score:.4f} for m={m}\")\n",
        "\n",
        "               # Warm-starting for Nelder-Mead perturbations (slightly reduced to make room for global best exploration)\n",
        "               if current_best_score is not None and current_best_score \u003e -5.0 and time.time() - start_time \u003c 980 and len(initial_guesses_queue) \u003c max(15, m * 1.5):\n",
        "                   perturb_scale = 0.8 + 2.5 * (m/20.0)\n",
        "                   num_perturbations = 2 # Increased perturbations slightly\n",
        "\n",
        "                   for _ in range(num_perturbations):\n",
        "                       # Normal perturbation\n",
        "                       perturbed_guess_normal = np.array(current_best_roots) + np.random.normal(0, perturb_scale, m)\n",
        "                       initial_guesses_queue.append(np.clip(perturbed_guess_normal, bounds[0][0], bounds[0][1]))\n",
        "\n",
        "                       if m \u003e 1:\n",
        "                            # Swap perturbation\n",
        "                            perturbed_guess_swap = np.array(current_best_roots)\n",
        "                            idx1, idx2 = np.random.choice(m, 2, replace=False)\n",
        "                            perturbed_guess_swap[[idx1, idx2]] = perturbed_guess_swap[[idx2, idx1]]\n",
        "                            initial_guesses_queue.append(np.clip(perturbed_guess_swap, bounds[0][0], bounds[0][1]))\n",
        "\n",
        "                            # Perturb close roots\n",
        "                            sorted_roots = np.sort(current_best_roots)\n",
        "                            diffs = np.diff(sorted_roots)\n",
        "                            close_pairs_indices = np.where(diffs \u003c np.mean(diffs) / 2.0)[0] # Threshold for closeness\n",
        "                            if len(close_pairs_indices) \u003e 0:\n",
        "                                chosen_pair_index = np.random.choice(close_pairs_indices)\n",
        "                                root1_idx = chosen_pair_index\n",
        "                                root2_idx = chosen_pair_index + 1\n",
        "                                perturbed_guess_close = np.copy(current_best_roots)\n",
        "                                # Find the indices of the roots in the original (unsorted) array\n",
        "                                root1_val = sorted_roots[root1_idx]\n",
        "                                root2_val = sorted_roots[root2_idx]\n",
        "                                original_indices_1 = np.where(np.isclose(current_best_roots, root1_val))[0]\n",
        "                                original_indices_2 = np.where(np.isclose(current_best_roots, root2_val))[0]\n",
        "\n",
        "                                if original_indices_1.size \u003e 0 and original_indices_2.size \u003e 0:\n",
        "                                    idx1 = np.random.choice(original_indices_1)\n",
        "                                    idx2 = np.random.choice(original_indices_2)\n",
        "                                    # Apply a small, opposite perturbation to the close roots\n",
        "                                    perturb_amount = np.random.uniform(0.1, 0.5) * diffs[chosen_pair_index]\n",
        "                                    perturbed_guess_close[idx1] += perturb_amount\n",
        "                                    perturbed_guess_close[idx2] -= perturb_amount\n",
        "                                    initial_guesses_queue.append(np.clip(perturbed_guess_close, bounds[0][0], bounds[0][1]))\n",
        "          #Differential evolution is already handled inside\n",
        "          if remaining_time \u003e 15 and current_best_score is not None and current_best_score \u003e -1e9: # Only run DE if NM was somewhat successful\n",
        "              # Allocate a portion of remaining time to DE, cap it to prevent excessively long runs\n",
        "              # Make DE time limit more dynamic based on remaining time\n",
        "              de_time_limit = min(remaining_time * 0.8, 400 + m * 8 + remaining_time * 0.1) # Increased cap and added dependency on remaining time\n",
        "\n",
        "              # If NM found a better point than the initial guess, start DE from there, or use a mix of best roots\n",
        "              de_initial_population = []\n",
        "              if current_best_score is not None and current_best_score \u003e -1e8 and (objective_function(current_best_roots) \u003c objective_function(initial_guess) or current_best_score \u003e get_score(initial_guess)):\n",
        "                  de_initial_population.append(current_best_roots)\n",
        "              # Add some of the global best roots to the initial DE population (ensure diversity)\n",
        "              for roots in global_best_roots_list[:min(5, len(global_best_roots_list))]:\n",
        "                  de_initial_population.append(np.array(roots))\n",
        "\n",
        "\n",
        "              try:\n",
        "                 # Adjust DE parameters based on remaining time\n",
        "                 dynamic_maxiter = min(1500, 60 * m + int(remaining_time * 0.5)) # More iterations if time permits\n",
        "                 dynamic_popsize = max(20, m * 2.5 + int(remaining_time * 0.1)) # Larger population if time permits\n",
        "\n",
        "                 de_result = scipy.optimize.differential_evolution( # Explicitly call from scipy.optimize\n",
        "                     objective_function,\n",
        "                     bounds=bounds,\n",
        "                     popsize=dynamic_popsize,\n",
        "                     maxiter=dynamic_maxiter,\n",
        "                     tol=0.005, # Increased tolerance for potentially better convergence\n",
        "                     disp=False,\n",
        "                     # seed=42 # Optional: for reproducibility\n",
        "                     # Use initial population if available, otherwise let DE generate random\n",
        "                     init=de_initial_population if de_initial_population else \"random\"\n",
        "                 )\n",
        "\n",
        "                 de_current_roots = de_result.x\n",
        "                 de_current_roots = np.clip(de_current_roots, bounds[0][0], bounds[0][1])\n",
        "                 de_current_score = get_score(de_current_roots)\n",
        "\n",
        "                 if de_current_score is not None and de_current_score \u003e -1e9:\n",
        "                     if de_current_score \u003e best_score:\n",
        "                         best_score = de_current_score\n",
        "                         best_roots = de_current_roots.tolist()\n",
        "                         # Add to global best roots list\n",
        "                         global_best_roots_list.append((best_roots, current_best_score))\n",
        "                         global_best_roots_list = sorted(global_best_roots_list, key=lambda x: x[1], reverse=True)\n",
        "                         global_best_roots_list = global_best_roots_list[:max(5, m)] # Limit size\n",
        "\n",
        "                         # print(f\"Found new best score (DE): {best_score:.4f} for m={m}\")\n",
        "\n",
        "              except Exception as e:\n",
        "                   # print(f\"Differential Evolution failed with error {e}\")\n",
        "                   pass\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "          # print(f\"Optimization attempt failed for guess {initial_guess[:5]}... with error {e}\")\n",
        "          pass\n",
        "\n",
        "  # If no valid roots were found during optimization, try the initial guesses\n",
        "  if best_roots is None or best_score \u003c -1e8:\n",
        "      fallback_score = -float('inf')\n",
        "      fallback_roots = None\n",
        "      for guess in initial_guesses_list:\n",
        "          try:\n",
        "              score = get_score(guess)\n",
        "              if score is not None and score \u003e -1e9:\n",
        "                  if score \u003e fallback_score:\n",
        "                      fallback_score = score\n",
        "                      fallback_roots = guess.tolist()\n",
        "          except Exception:\n",
        "              pass\n",
        "\n",
        "      if fallback_roots is not None:\n",
        "          return fallback_roots\n",
        "      else:\n",
        "          # Return a default guess if all else fails\n",
        "          if m in known_good_roots:\n",
        "              return known_good_roots[m].tolist()\n",
        "          else:\n",
        "              # Fallback to a simple structured guess or random\n",
        "              if m \u003e= 2:\n",
        "                  start_val = 35.0\n",
        "                  end_val = 50.0 + (m-6)*2\n",
        "                  if m-2 \u003e= 1:\n",
        "                       roots = [4.0, 5.0] + list(np.linspace(start_val, end_val, m - 2))\n",
        "                  else: # m=2\n",
        "                       roots = [4.0, 5.0]\n",
        "              elif m == 1:\n",
        "                   roots = [40.0]\n",
        "              else:\n",
        "                   roots = np.random.uniform(1.0, 100.0, m).tolist() # Safeguard\n",
        "\n",
        "              return np.clip(np.array(roots), bounds[0][0], bounds[0][1]).tolist()\n",
        "\n",
        "\n",
        "  return best_roots\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aY6NyilyRNi9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "djJE20OSZICD"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
