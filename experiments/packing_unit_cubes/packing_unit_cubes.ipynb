{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Packing unit cubes"
      ],
      "metadata": {
        "id": "46-U096rrlU-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o6RQ78grxeu"
      },
      "outputs": [],
      "source": [
        "#@title Data and verification\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# --- Core Geometric Functions ---\n",
        "\n",
        "def rotation_matrix_3d(rx_deg, ry_deg, rz_deg):\n",
        "    \"\"\"\n",
        "    Generates a 3D rotation matrix from Euler angles in degrees.\n",
        "    The order of rotation is Z, then Y, then X.\n",
        "    \"\"\"\n",
        "    # Convert degrees to radians for numpy's trigonometric functions\n",
        "    rx, ry, rz = np.deg2rad([rx_deg, ry_deg, rz_deg])\n",
        "\n",
        "    # Pre-calculate cosines and sines\n",
        "    cos_x, sin_x = np.cos(rx), np.sin(rx)\n",
        "    cos_y, sin_y = np.cos(ry), np.sin(ry)\n",
        "    cos_z, sin_z = np.cos(rz), np.sin(rz)\n",
        "\n",
        "    # Define rotation matrices for each axis\n",
        "    rot_x = np.array([[1, 0, 0], [0, cos_x, -sin_x], [0, sin_x, cos_x]])\n",
        "    rot_y = np.array([[cos_y, 0, sin_y], [0, 1, 0], [-sin_y, 0, cos_y]])\n",
        "    rot_z = np.array([[cos_z, -sin_z, 0], [sin_z, cos_z, 0], [0, 0, 1]])\n",
        "\n",
        "    # Combine rotations: R = Rz * Ry * Rx\n",
        "    return rot_z @ rot_y @ rot_x\n",
        "\n",
        "class Cube:\n",
        "    \"\"\"A class to represent a single cube in 3D space.\"\"\"\n",
        "    def __init__(self, center, rotation_angles, side_length=1.0):\n",
        "        \"\"\"\n",
        "        Initializes a Cube object.\n",
        "        Args:\n",
        "            center (list or np.array): The [x, y, z] coordinates of the cube's center.\n",
        "            rotation_angles (list or np.array): The [rx, ry, rz] rotation angles in degrees.\n",
        "            side_length (float): The side length of the cube.\n",
        "        \"\"\"\n",
        "        self.center = np.array(center)\n",
        "        self.rot_mat = rotation_matrix_3d(*rotation_angles)\n",
        "\n",
        "        # The local axes of the cube (its face normals) are the columns of the rotation matrix.\n",
        "        self.axes = [self.rot_mat[:, i] for i in range(3)]\n",
        "\n",
        "        # Calculate the world coordinates of the 8 vertices\n",
        "        half_side = side_length / 2.0\n",
        "        local_verts = np.array([\n",
        "            [-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
        "            [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]\n",
        "        ]) * half_side\n",
        "        # Rotate and translate the vertices to their world positions\n",
        "        self.vertices = (local_verts @ self.rot_mat.T) + self.center\n",
        "\n",
        "# --- Separating Axis Theorem (SAT) Implementation ---\n",
        "\n",
        "def _project_on_axis(cube, axis):\n",
        "    \"\"\"Projects a cube's vertices onto an axis to find the min/max interval.\"\"\"\n",
        "    # Ensure axis is a unit vector for consistent projection values\n",
        "    axis_norm = np.linalg.norm(axis)\n",
        "    if axis_norm \u003c 1e-9: # Avoid division by zero for zero-length cross products\n",
        "        return 0, 0\n",
        "    axis = axis / axis_norm\n",
        "\n",
        "    # Project each vertex onto the axis\n",
        "    projections = [np.dot(vertex, axis) for vertex in cube.vertices]\n",
        "    return min(projections), max(projections)\n",
        "\n",
        "def check_intersection(cube1, cube2):\n",
        "    \"\"\"\n",
        "    Checks for intersection between two cubes using the Separating Axis Theorem (SAT).\n",
        "\n",
        "    The SAT states that two convex objects do not intersect if there exists an axis\n",
        "    (a \"separating axis\") onto which their projections do not overlap. For two cubes,\n",
        "    we only need to test 15 potential separating axes.\n",
        "\n",
        "    Returns:\n",
        "        True if the cubes intersect, False otherwise.\n",
        "    \"\"\"\n",
        "    # The 15 axes to test are:\n",
        "    # 1. The 3 face normals of Cube 1\n",
        "    # 2. The 3 face normals of Cube 2\n",
        "    # 3. The 9 cross products of each edge from Cube 1 with each edge from Cube 2\n",
        "    #    (Since cube edges are parallel to its axes, we use the axes).\n",
        "    potential_axes = cube1.axes + cube2.axes\n",
        "    for axis1 in cube1.axes:\n",
        "        for axis2 in cube2.axes:\n",
        "            potential_axes.append(np.cross(axis1, axis2))\n",
        "\n",
        "    for axis in potential_axes:\n",
        "        # Project both cubes onto the current axis\n",
        "        min1, max1 = _project_on_axis(cube1, axis)\n",
        "        min2, max2 = _project_on_axis(cube2, axis)\n",
        "\n",
        "        # Check if the projections (intervals) overlap.\n",
        "        # If they DON'T overlap, we have found a separating axis.\n",
        "        if max1 \u003c min2 or max2 \u003c min1:\n",
        "            return False # The cubes are separated, no intersection.\n",
        "\n",
        "    # If we tested all 15 axes and found an overlap on every single one,\n",
        "    # the cubes must be intersecting.\n",
        "    return True\n",
        "\n",
        "# --- Bounding Box Calculation ---\n",
        "\n",
        "def calculate_bounding_box_side(cubes):\n",
        "    \"\"\"\n",
        "    Calculates the side length of the smallest axis-aligned bounding cube\n",
        "    that contains all the given cubes.\n",
        "    \"\"\"\n",
        "    if not cubes:\n",
        "        return 0\n",
        "\n",
        "    # Collect all vertices from all cubes into a single array\n",
        "    all_vertices = np.vstack([cube.vertices for cube in cubes])\n",
        "\n",
        "    # Find the minimum and maximum coordinates across all vertices\n",
        "    min_coords = np.min(all_vertices, axis=0) # [min_x, min_y, min_z]\n",
        "    max_coords = np.max(all_vertices, axis=0) # [max_x, max_y, max_z]\n",
        "\n",
        "    # Calculate the side lengths of the bounding box along each axis\n",
        "    span = max_coords - min_coords # [span_x, span_y, span_z]\n",
        "\n",
        "    # The side of the smallest *cube* that bounds this box is the largest of the spans\n",
        "    return np.max(span)\n",
        "\n",
        "# --- Main Analysis Function ---\n",
        "\n",
        "def analyze_cube_packing(placements):\n",
        "    \"\"\"\n",
        "    Main function to perform the analysis. It checks for intersections and, if none\n",
        "    are found, calculates the bounding box side length.\n",
        "\n",
        "    Args:\n",
        "        placements (np.array): An Nx6 numpy array where each row is\n",
        "                               [cx, cy, cz, rx, ry, rz] for a cube.\n",
        "    \"\"\"\n",
        "    print(\"--- Starting Cube Packing Analysis ---\")\n",
        "    num_cubes = len(placements)\n",
        "    if num_cubes \u003c 2:\n",
        "        print(\"Analysis requires at least two cubes.\")\n",
        "        return\n",
        "\n",
        "    # Create Cube objects from the raw placement data\n",
        "    cubes = [Cube(p[:3], p[3:]) for p in placements]\n",
        "    print(f\"Successfully created {len(cubes)} cube objects.\")\n",
        "\n",
        "    # 1. Check for intersections by comparing every unique pair of cubes\n",
        "    print(\"\\n1. Checking for intersections...\")\n",
        "    intersection_found = False\n",
        "    for i in range(num_cubes):\n",
        "        for j in range(i + 1, num_cubes):\n",
        "            if check_intersection(cubes[i], cubes[j]):\n",
        "                print(f\"   -\u003e ‚ùå INTERSECTION DETECTED between Cube {i+1} and Cube {j+1}.\")\n",
        "                intersection_found = True\n",
        "\n",
        "    # 2. If no intersections were found, proceed to calculate the bounding box\n",
        "    print(\"\\n2. Final Result:\")\n",
        "    if not intersection_found:\n",
        "        print(\"   ‚úÖ No intersections were found.\")\n",
        "        side_length = calculate_bounding_box_side(cubes)\n",
        "        print(f\"   üì¶ Side length of the smallest bounding cube: {side_length:.6f}\")\n",
        "    else:\n",
        "        print(\"   ‚ö†Ô∏è Analysis stopped. Cannot calculate bounding box due to intersections.\")\n",
        "    print(\"--- Analysis Complete ---\")\n",
        "\n",
        "\n",
        "\n",
        "placements_no_intersection = np.array([[-8.77779155e-01, -8.77126384e-01, -1.01671182e+00,0,0,0], [-8.77779155e-01, -8.77126384e-01, 8.77819332e-01, 0,0,0], [-8.77779155e-01, 1.01740471e+00,-1.01671182e+00,0,0,0], [-8.77779155e-01, 1.01740471e+00,8.77819332e-01, 0,0,0], [ 1.01675167e+00,-8.77126384e-01, -1.01671182e+00,0,0,0], [ 1.01675167e+00,-8.77126384e-01, 8.77819332e-01, 0,0,0], [ 1.01675167e+00,1.01740471e+00,-1.01671182e+00,0,0,0], [ 1.01675167e+00,1.01740471e+00,8.77819332e-01, 0,0,0], [ 2.01013926e-01, 1.15252160e-01, 8.77806873e-01, 6.76458206e+00,8.99998576e+01, 1.60681931e+02], [ 1.13368230e-01, -8.77124005e-01, -2.08800374e-01, 2.07520455e+02, 3.59999904e+02, 9.00002316e+01], [-8.77752030e-01, 2.04448607e-01, -1.14126641e-01, 1.80000883e+02, 2.65856303e+01, 2.70001203e+02]])\n",
        "\n",
        "\n",
        "analyze_cube_packing(placements_no_intersection)\n",
        "\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "import random\n",
        "\n",
        "# --- Helper Functions (required for the visualization to run) ---\n",
        "def rotation_matrix_3d(x_angle_deg, y_angle_deg, z_angle_deg):\n",
        "    \"\"\"Generates a 3D rotation matrix from Euler angles.\"\"\"\n",
        "    x_rad, y_rad, z_rad = np.deg2rad([x_angle_deg, y_angle_deg, z_angle_deg])\n",
        "    cos_x, sin_x = np.cos(x_rad), np.sin(x_rad)\n",
        "    cos_y, sin_y = np.cos(y_rad), np.sin(y_rad)\n",
        "    cos_z, sin_z = np.cos(z_rad), np.sin(z_rad)\n",
        "    rot_x = np.array([[1, 0, 0], [0, cos_x, -sin_x], [0, sin_x, cos_x]])\n",
        "    rot_y = np.array([[cos_y, 0, sin_y], [0, 1, 0], [-sin_y, 0, cos_y]])\n",
        "    rot_z = np.array([[cos_z, -sin_z, 0], [sin_z, cos_z, 0], [0, 0, 1]])\n",
        "    return rot_z @ rot_y @ rot_x\n",
        "\n",
        "def get_cube_vertices(center, rotation_matrix, side_length=1.0):\n",
        "    \"\"\"Calculates the world coordinates of a cube's 8 vertices.\"\"\"\n",
        "    half_side = side_length / 2.0\n",
        "    local_verts = np.array([\n",
        "        [-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
        "        [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]\n",
        "    ]) * half_side\n",
        "    return (local_verts @ rotation_matrix.T) + center\n",
        "\n",
        "\n",
        "def get_random_color():\n",
        "    \"\"\"Generates a random hexadecimal color string.\"\"\"\n",
        "    r = random.randint(0, 255)\n",
        "    g = random.randint(0, 255)\n",
        "    b = random.randint(0, 255)\n",
        "    return f'#{r:02x}{g:02x}{b:02x}'\n",
        "\n",
        "# --- Visualization Function using Plotly ---\n",
        "def visualize_packing_3d(placements):\n",
        "    \"\"\"Visualizes a 3D cube packing as an interactive Plotly plot.\"\"\"\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Define the 12 triangles that make up the faces of a cube\n",
        "    # (2 triangles per face)\n",
        "    # Indices correspond to the 8 vertices from get_cube_vertices\n",
        "    face_triangles = np.array([\n",
        "        [0, 1, 2], [1, 3, 2], # Back face\n",
        "        [4, 6, 5], [5, 6, 7], # Front face\n",
        "        [0, 4, 1], [1, 4, 5], # Bottom face\n",
        "        [2, 3, 6], [3, 7, 6], # Top face\n",
        "        [0, 2, 4], [2, 6, 4], # Left face\n",
        "        [1, 5, 3], [3, 5, 7]  # Right face\n",
        "    ])\n",
        "\n",
        "    for i, placement in enumerate(placements):\n",
        "        center = np.array(placement[:3])\n",
        "        rotation_mat = rotation_matrix_3d(*placement[3:])\n",
        "        vertices = get_cube_vertices(center, rotation_mat)\n",
        "\n",
        "        fig.add_trace(go.Mesh3d(\n",
        "            x=vertices[:, 0],\n",
        "            y=vertices[:, 1],\n",
        "            z=vertices[:, 2],\n",
        "            i=face_triangles[:, 0],\n",
        "            j=face_triangles[:, 1],\n",
        "            k=face_triangles[:, 2],\n",
        "            opacity=0.6,\n",
        "            color=get_random_color(),\n",
        "            name=f'Cube {i+1}'\n",
        "        ))\n",
        "\n",
        "    # Configure the plot layout\n",
        "    fig.update_layout(\n",
        "        title='3D Cube Packing (Interactive)',\n",
        "        scene=dict(\n",
        "            xaxis_title='X Axis',\n",
        "            yaxis_title='Y Axis',\n",
        "            zaxis_title='Z Axis',\n",
        "            aspectmode='data'  # Ensures correct aspect ratio\n",
        "        ),\n",
        "        margin=dict(l=0, r=0, b=0, t=40)\n",
        "    )\n",
        "\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "\n",
        "visualize_packing_3d(placements_no_intersection)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt used**\n",
        "\n",
        "Act as an expert in optimization and geometry, to solve the following question:\n",
        "what is the smallest cube that can fit 'num_cubes' unit cubes in it without them\n",
        "overlapping?\n",
        "\n",
        "Your task is to produce a search function that searches for the best placements\n",
        "of the num_cubes unit cubes. The side length of the big cube containing all num_cubes of\n",
        "your unit cubes will be calculated automatically, and that will be your\n",
        "score. More precisely, you will have to produce a list of placements, which is\n",
        "num_cubes tuples of size 6 of the form (x, y, z, x_angle, y_angle, z_angle), and you will be evaluated with the\n",
        "calculate_packing_score_cubes_3d(placements: List[Tuple], num_cubes: int) function which computes the smallest bounding box, and heavily penalizes overlapping unit cubes.\n",
        "This function returns two things: the current score that we want to maximise, and also a \"fixed\" version of the input placements, which just fixes some obvious inaccuracies that may be present in the input.\n",
        "\n",
        "You could call this as follows:\n",
        "score, fixed_placements = calculate_packing_score_cubes_3d(placements, num_cubes)\n",
        "\n",
        "You will also have access to a squeezing function that tries to greedily compress the existing configuration. You may call it for example like this:\n",
        "\n",
        "squeezed_placements = squeeze_placements_3d([tuple(item) for item in placements], num_passes=5, binary_search_iterations=10)\n",
        "\n",
        "This squeezing function usually improves things, but it can occasionally produce worse results than the input, its codebase is a bit unreliable.\n",
        "\n",
        "You may code up any search method you want, and you are allowed to call the\n",
        "calculate_packing_score_cubes_3d() function as many times as you want. You have\n",
        "access to it, you don't need to code up the calculate_packing_score_cubes_3d() or the squeeze_placements_3d() functions. You want the score to be as high as possible!\n",
        "\n",
        "Your task is to write a search function that searches for the best placements. Your\n",
        "function will have 1000 seconds to run, and after that it has to have returned\n",
        "the best construction it found. If after 1000 seconds it has not returned anything, the program will be terminated with a huge negative score.\n",
        "\n",
        "Good luck!"
      ],
      "metadata": {
        "id": "YlVNwG2jc6bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Initial program\n",
        "\n",
        "\"\"\"Finds the smallest cube into which n unit cubes can be packed.\"\"\"\n",
        "import itertools\n",
        "import logging\n",
        "import time\n",
        "from scipy import integrate\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "import warnings\n",
        "import random\n",
        "import re\n",
        "from collections.abc import Callable, Mapping\n",
        "from typing import Any, List, Tuple, Dict\n",
        "import scipy.linalg as la\n",
        "import numpy.polynomial.polynomial as poly\n",
        "import collections\n",
        "import copy\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def scaling(input_arr, factor=1.001):\n",
        "  new_arr = [list(item) for item in input_arr]\n",
        "  for i in range(len(new_arr)):\n",
        "    new_arr[i][0] *= factor\n",
        "    new_arr[i][1] *= factor\n",
        "    new_arr[i][2] *= factor\n",
        "  return np.array(new_arr)\n",
        "\n",
        "\n",
        "def search_for_best_packings_3d(num_cubes: int) -\u003e List[Tuple]:\n",
        "  \"\"\"Searches for the best packing of unit cubes into a container cube.\"\"\"\n",
        "  variable_name = f'best_placements_3d_{num_cubes}'\n",
        "  if np.random.rand() \u003c 0.99 and variable_name in globals():\n",
        "    placements = list(globals()[variable_name])\n",
        "    # To avoid float point errors, we scale the placements by a small factor.\n",
        "    placements = list(scaling(placements, factor=1.00001))\n",
        "  else:\n",
        "    side = math.ceil(num_cubes ** (1 / 3.0))\n",
        "    placements = [\n",
        "        (\n",
        "            (np.random.rand() - 0.5) * side,\n",
        "            (np.random.rand() - 0.5) * side,\n",
        "            (np.random.rand() - 0.5) * side,\n",
        "            np.random.uniform(0, 360),\n",
        "            np.random.uniform(0, 360),\n",
        "            np.random.uniform(0, 360),\n",
        "        )\n",
        "        for _ in range(num_cubes)\n",
        "    ]\n",
        "\n",
        "  best_placements = copy.deepcopy(placements)\n",
        "  best_score, fixed_temp_placements = calculate_packing_score_cubes_3d(\n",
        "      best_placements, num_cubes\n",
        "  )\n",
        "  temp_placements = [tuple(p) for p in fixed_temp_placements]\n",
        "  print(\n",
        "      f'Initial score: {best_score}, side:'\n",
        "      f' {-best_score if best_score \u003e -1000 else \"N/A\"}'\n",
        "  )\n",
        "\n",
        "  start_time = time.time()\n",
        "  eval_count = 0\n",
        "  running_time = np.random.randint(100, 1000)\n",
        "  while time.time() - start_time \u003c running_time:\n",
        "    temp_placements = [list(p) for p in temp_placements]\n",
        "    if np.random.rand() \u003c 0.01:\n",
        "      temp_placements = [list(p) for p in best_placements]\n",
        "    idx_to_mutate = np.random.randint(0, num_cubes)\n",
        "\n",
        "    temp_placements[idx_to_mutate][0] += np.random.normal(0, 0.01)\n",
        "    temp_placements[idx_to_mutate][1] += np.random.normal(0, 0.01)\n",
        "    temp_placements[idx_to_mutate][2] += np.random.normal(0, 0.01)\n",
        "    for i in range(3, 6):\n",
        "      temp_placements[idx_to_mutate][i] = (\n",
        "          temp_placements[idx_to_mutate][i] + np.random.normal(0, 2)\n",
        "      ) % 360\n",
        "    candidate_placements = [tuple(p) for p in temp_placements]\n",
        "\n",
        "    if eval_count % 100 == 0 and eval_count \u003e 0 and best_score \u003e -100:\n",
        "      squeezed_candidate = squeeze_placements_3d(\n",
        "          [tuple(item) for item in candidate_placements],\n",
        "          num_passes=3,\n",
        "          binary_search_iterations=10,\n",
        "      )\n",
        "      if len(squeezed_candidate) == num_cubes:\n",
        "        candidate_placements = squeezed_candidate\n",
        "\n",
        "    score, fixed_candidate_placements = calculate_packing_score_cubes_3d(\n",
        "        candidate_placements, num_cubes\n",
        "    )\n",
        "    candidate_placements = [tuple(p) for p in fixed_candidate_placements]\n",
        "    eval_count += 1\n",
        "\n",
        "    if score \u003e best_score:\n",
        "      best_score = score\n",
        "      best_placements = copy.deepcopy(candidate_placements)\n",
        "      temp_placements = copy.deepcopy(candidate_placements)\n",
        "      logging.info(\n",
        "          f'New best score: {best_score}, side: {-score}, evals: {eval_count}'\n",
        "      )\n",
        "      squeezed_candidate = squeeze_placements_3d(\n",
        "          [tuple(item) for item in best_placements],\n",
        "          num_passes=10,\n",
        "          binary_search_iterations=20,\n",
        "      )\n",
        "      score_after, fixed_squeezed_candidates = calculate_packing_score_cubes_3d(\n",
        "          squeezed_candidate, num_cubes\n",
        "      )\n",
        "      logging.info(f'Score after squeeze: {score_after}')\n",
        "      if score_after \u003e best_score:\n",
        "        best_score = score_after\n",
        "        best_placements = copy.deepcopy(fixed_squeezed_candidates)\n",
        "        temp_placements = copy.deepcopy(fixed_squeezed_candidates)\n",
        "    if np.random.rand() \u003c 0.01:\n",
        "      temp_placements = [list(p) for p in best_placements]\n",
        "\n",
        "  logging.info(f'Final score: {best_score}, side: {-best_score}')\n",
        "  logging.info(f'Total Evaluations: {eval_count}')\n",
        "  return best_placements\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Lm7E0lFwdX1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluation function used\n",
        "\n",
        "NUM_CUBES_IN_CORNERS = 8\n",
        "\n",
        "\n",
        "# --- 3D GEOMETRY HELPER FUNCTIONS ---\n",
        "\n",
        "\n",
        "def rotation_matrix_3d(x_angle_deg, y_angle_deg, z_angle_deg):\n",
        "  \"\"\"Generates a 3D rotation matrix from Euler angles (XYZ convention).\"\"\"\n",
        "  x_angle_rad = np.deg2rad(x_angle_deg)\n",
        "  y_angle_rad = np.deg2rad(y_angle_deg)\n",
        "  z_angle_rad = np.deg2rad(z_angle_deg)\n",
        "  cos_x, sin_x = np.cos(x_angle_rad), np.sin(x_angle_rad)\n",
        "  cos_y, sin_y = np.cos(y_angle_rad), np.sin(y_angle_rad)\n",
        "  cos_z, sin_z = np.cos(z_angle_rad), np.sin(z_angle_rad)\n",
        "\n",
        "  rotation_x = np.array([[1, 0, 0], [0, cos_x, -sin_x], [0, sin_x, cos_x]])\n",
        "  rotation_y = np.array([[cos_y, 0, sin_y], [0, 1, 0], [-sin_y, 0, cos_y]])\n",
        "  rotation_z = np.array([[cos_z, -sin_z, 0], [sin_z, cos_z, 0], [0, 0, 1]])\n",
        "\n",
        "  return rotation_z @ rotation_y @ rotation_x\n",
        "\n",
        "\n",
        "def get_cube_vertices(center, rotation_matrix, side_length=1.0):\n",
        "  \"\"\"Calculates the world coordinates of a cube's vertices.\"\"\"\n",
        "  half_side = side_length / 2.0\n",
        "  local_vertices = np.array([\n",
        "      [-half_side, -half_side, -half_side],\n",
        "      [-half_side, -half_side, half_side],\n",
        "      [-half_side, half_side, -half_side],\n",
        "      [-half_side, half_side, half_side],\n",
        "      [half_side, -half_side, -half_side],\n",
        "      [half_side, -half_side, half_side],\n",
        "      [half_side, half_side, -half_side],\n",
        "      [half_side, half_side, half_side],\n",
        "  ])\n",
        "  return (local_vertices @ rotation_matrix.T) + center\n",
        "\n",
        "\n",
        "def get_cube_axes(rotation_matrix):\n",
        "  \"\"\"Calculates the axes to test for SAT, which are the face normals.\"\"\"\n",
        "  local_axes = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
        "  return local_axes @ rotation_matrix.T\n",
        "\n",
        "\n",
        "def project_cube_onto_axis(vertices, axis):\n",
        "  \"\"\"Projects a cube's vertices onto an axis.\"\"\"\n",
        "  projections = vertices @ axis\n",
        "  return np.min(projections), np.max(projections)\n",
        "\n",
        "\n",
        "def do_cubes_intersect(vertices1, vertices2, axes1, axes2):\n",
        "  \"\"\"Checks for intersection between two cubes using the full Separating Axis Theorem.\"\"\"\n",
        "  # Combine the 6 face-normal axes from both cubes\n",
        "  axes_to_test = list(axes1) + list(axes2)\n",
        "\n",
        "  # **CORRECTION**: Add the 9 axes from the cross products of the cubes' axes.\n",
        "  # This is the part that was missing from the original.\n",
        "  for i in range(3):\n",
        "    for j in range(3):\n",
        "      cross_product = np.cross(axes1[i], axes2[j])\n",
        "      # Add the axis only if it's not a zero vector (avoids parallel axes)\n",
        "      if np.linalg.norm(cross_product) \u003e 1e-6:\n",
        "        axes_to_test.append(cross_product)\n",
        "\n",
        "  # Test for separation along all 15 (or fewer) axes\n",
        "  for axis in axes_to_test:\n",
        "    min1, max1 = project_cube_onto_axis(vertices1, axis)\n",
        "    min2, max2 = project_cube_onto_axis(vertices2, axis)\n",
        "\n",
        "    # If there is no overlap on any axis, the cubes do not intersect\n",
        "    if max1 \u003c min2 - 1e-9 or max2 \u003c min1 - 1e-9:\n",
        "      return False  # Found a separating axis\n",
        "\n",
        "  # If no separating axis was found after checking all potential axes,\n",
        "  # the cubes must be intersecting.\n",
        "  return True\n",
        "\n",
        "\n",
        "def min_bounding_cube_extent_3d(all_vertices):\n",
        "  \"\"\"Calculates the side length of the minimum axis-aligned bounding cube.\"\"\"\n",
        "  if not all_vertices:\n",
        "    return 0, np.array([0, 0, 0]), np.array([0, 0, 0])\n",
        "  all_vertices_np = np.vstack(all_vertices)\n",
        "  min_coords = np.min(all_vertices_np, axis=0)\n",
        "  max_coords = np.max(all_vertices_np, axis=0)\n",
        "  side_lengths = max_coords - min_coords\n",
        "  return np.max(side_lengths), min_coords, max_coords\n",
        "\n",
        "\n",
        "# --- SQUEEZING FUNCTION ---\n",
        "def squeeze_placements_3d(\n",
        "    placements: List[Tuple],\n",
        "    num_passes: int = 3,\n",
        "    binary_search_iterations: int = 10,\n",
        "):\n",
        "  \"\"\"Adjusts cube placements to pack them more tightly, with special handling\n",
        "\n",
        "  for corner and inner cubes.\n",
        "  \"\"\"\n",
        "  if not placements:\n",
        "    return []\n",
        "  # print(f'Squeezing {len(placements)} cubes...')\n",
        "  # print(placements)\n",
        "  num_cubes = len(placements)\n",
        "  if num_cubes \u003c= 1:\n",
        "    return placements\n",
        "\n",
        "  current_placements = np.array([list(p) for p in placements])\n",
        "\n",
        "  final_placements = [list(p) for p in current_placements]\n",
        "\n",
        "  # Determine the bounding box of the initial \"free\" cubes\n",
        "  _, min_b, max_b = min_bounding_cube_extent_3d([\n",
        "      get_cube_vertices(p[:3], rotation_matrix_3d(p[3], p[4], p[5]))\n",
        "      for p in final_placements\n",
        "  ])\n",
        "\n",
        "  # Set the positions for the corner cubes\n",
        "  num_corner_cubes = min(num_cubes, NUM_CUBES_IN_CORNERS)\n",
        "  if num_corner_cubes \u003e 0:\n",
        "    corner_centers = [\n",
        "        np.array([min_b[0] + 0.5, min_b[1] + 0.5, min_b[2] + 0.5]),\n",
        "        np.array([min_b[0] + 0.5, min_b[1] + 0.5, max_b[2] - 0.5]),\n",
        "        np.array([min_b[0] + 0.5, max_b[1] - 0.5, min_b[2] + 0.5]),\n",
        "        np.array([min_b[0] + 0.5, max_b[1] - 0.5, max_b[2] - 0.5]),\n",
        "        np.array([max_b[0] - 0.5, min_b[1] + 0.5, min_b[2] + 0.5]),\n",
        "        np.array([max_b[0] - 0.5, min_b[1] + 0.5, max_b[2] - 0.5]),\n",
        "        np.array([max_b[0] - 0.5, max_b[1] - 0.5, min_b[2] + 0.5]),\n",
        "        np.array([max_b[0] - 0.5, max_b[1] - 0.5, max_b[2] - 0.5]),\n",
        "    ]\n",
        "    for i in range(num_corner_cubes):\n",
        "      final_placements[i][:3] = corner_centers[i]\n",
        "      final_placements[i][3:] = [0, 0, 0]\n",
        "\n",
        "  current_placements = np.array(final_placements)\n",
        "\n",
        "  # Part 1: Squeeze the inner cubes (last num_cubes - NUM_CUBES_IN_CORNERS)\n",
        "  # This part pushes these cubes towards the center, one axis at a time.\n",
        "  made_change_in_global_pass = True\n",
        "  for pass_idx in range(num_passes):\n",
        "    if not made_change_in_global_pass:\n",
        "      break\n",
        "    made_change_in_global_pass = False\n",
        "\n",
        "    for axis_idx in range(3):\n",
        "      rotation_matrices = [\n",
        "          rotation_matrix_3d(p[3], p[4], p[5]) for p in current_placements\n",
        "      ]\n",
        "      all_vertices = [\n",
        "          get_cube_vertices(p[:3], rot)\n",
        "          for p, rot in zip(current_placements, rotation_matrices)\n",
        "      ]\n",
        "      all_axes = [get_cube_axes(rot) for rot in rotation_matrices]\n",
        "      avg_center = np.mean(current_placements[:, :3], axis=0)\n",
        "\n",
        "      # Only iterate over the inner cubes for this type of squeezing\n",
        "      inner_cube_indices = list(range(NUM_CUBES_IN_CORNERS, num_cubes))\n",
        "      random.shuffle(inner_cube_indices)\n",
        "\n",
        "      for i in inner_cube_indices:\n",
        "        original_center = current_placements[i, :3].copy()\n",
        "        vec_to_avg_center = avg_center - original_center\n",
        "\n",
        "        move_vec = np.zeros(3)\n",
        "        if abs(vec_to_avg_center[axis_idx]) \u003c 1e-7:\n",
        "          continue\n",
        "        move_vec[axis_idx] = vec_to_avg_center[axis_idx]\n",
        "\n",
        "        low_bound, high_bound = 0.0, 1.0\n",
        "        best_non_colliding_factor = 0.0\n",
        "        rot_i = rotation_matrices[i]\n",
        "        axes_i = all_axes[i]\n",
        "\n",
        "        for _ in range(binary_search_iterations):\n",
        "          test_factor = (low_bound + high_bound) / 2.0\n",
        "          test_center = original_center + test_factor * move_vec\n",
        "          moved_vertices_i = get_cube_vertices(test_center, rot_i)\n",
        "\n",
        "          collision = False\n",
        "          for j in range(num_cubes):\n",
        "            if i == j:\n",
        "              continue\n",
        "            if do_cubes_intersect(\n",
        "                moved_vertices_i, all_vertices[j], axes_i, all_axes[j]\n",
        "            ):\n",
        "              collision = True\n",
        "              break\n",
        "          if collision:\n",
        "            high_bound = test_factor\n",
        "          else:\n",
        "            best_non_colliding_factor = test_factor\n",
        "            low_bound = test_factor\n",
        "\n",
        "        if best_non_colliding_factor \u003e 1e-5:\n",
        "          displacement = best_non_colliding_factor * move_vec\n",
        "          current_placements[i, :3] += displacement\n",
        "          all_vertices[i] = get_cube_vertices(current_placements[i, :3], rot_i)\n",
        "          made_change_in_global_pass = True\n",
        "\n",
        "  # Part 2: Squeeze the corner cubes (first NUM_CUBES_IN_CORNERS)\n",
        "  # This part finds a single factor `alpha` to push all corner cubes\n",
        "  # simultaneously towards the center.\n",
        "  if num_cubes \u003e NUM_CUBES_IN_CORNERS \u003e 0:\n",
        "    rotation_matrices = [\n",
        "        rotation_matrix_3d(p[3], p[4], p[5]) for p in current_placements\n",
        "    ]\n",
        "    all_vertices = [\n",
        "        get_cube_vertices(p[:3], rot)\n",
        "        for p, rot in zip(current_placements, rotation_matrices)\n",
        "    ]\n",
        "    all_axes = [get_cube_axes(rot) for rot in rotation_matrices]\n",
        "    avg_center = np.mean(current_placements[:, :3], axis=0)\n",
        "\n",
        "    corner_vectors = [\n",
        "        avg_center - current_placements[i, :3]\n",
        "        for i in range(NUM_CUBES_IN_CORNERS)\n",
        "    ]\n",
        "\n",
        "    low_alpha, high_alpha = 0.0, 1.0\n",
        "    best_alpha = 0.0\n",
        "\n",
        "    for _ in range(binary_search_iterations):\n",
        "      test_alpha = (low_alpha + high_alpha) / 2.0\n",
        "      if test_alpha == 0.0:\n",
        "        continue\n",
        "\n",
        "      collision_found = False\n",
        "      for i in range(NUM_CUBES_IN_CORNERS):\n",
        "        test_center_i = (\n",
        "            current_placements[i, :3] + test_alpha * corner_vectors[i]\n",
        "        )\n",
        "        moved_vertices_i = get_cube_vertices(\n",
        "            test_center_i, rotation_matrices[i]\n",
        "        )\n",
        "\n",
        "        # Check for intersection only against the inner cubes\n",
        "        for j in range(NUM_CUBES_IN_CORNERS, num_cubes):\n",
        "          if do_cubes_intersect(\n",
        "              moved_vertices_i, all_vertices[j], all_axes[i], all_axes[j]\n",
        "          ):\n",
        "            collision_found = True\n",
        "            break\n",
        "        if collision_found:\n",
        "          break\n",
        "\n",
        "      if collision_found:\n",
        "        high_alpha = test_alpha\n",
        "      else:\n",
        "        best_alpha = test_alpha\n",
        "        low_alpha = test_alpha\n",
        "\n",
        "    # Apply the best simultaneous move to all corner cubes\n",
        "    if best_alpha \u003e 1e-5:\n",
        "      for i in range(NUM_CUBES_IN_CORNERS):\n",
        "        current_placements[i, :3] += (best_alpha - 1e-9) * corner_vectors[i]\n",
        "    # print(f\"Best alpha: {best_alpha}\")\n",
        "\n",
        "  return [tuple(p) for p in current_placements]\n",
        "\n",
        "\n",
        "def calculate_packing_score_cubes_3d(\n",
        "    placements: List[Tuple],\n",
        "    num_cubes: int,\n",
        "    intersection_penalty_factor=100.0,\n",
        "    return_adjusted_coordinates=True,\n",
        "    verbose=False,\n",
        "):\n",
        "  \"\"\"Calculates the score for a 3D cube packing configuration.\"\"\"\n",
        "  if not placements or len(placements) != num_cubes:\n",
        "    return -1_000_000.0\n",
        "\n",
        "  try:\n",
        "    # Create a working copy of placements to modify\n",
        "    final_placements = [list(p) for p in placements]\n",
        "\n",
        "    # Determine the bounding box of the initial \"free\" cubes\n",
        "    _, min_b, max_b = min_bounding_cube_extent_3d([\n",
        "        get_cube_vertices(p[:3], rotation_matrix_3d(p[3], p[4], p[5]))\n",
        "        for p in final_placements\n",
        "    ])\n",
        "\n",
        "    if verbose:\n",
        "      print(f'Initial bounding box: {min_b}, {max_b}')\n",
        "\n",
        "    # Set the positions for the corner cubes\n",
        "    num_corner_cubes = min(num_cubes, NUM_CUBES_IN_CORNERS)\n",
        "    if num_corner_cubes \u003e 0:\n",
        "      corner_centers = [\n",
        "          np.array([min_b[0] + 0.5, min_b[1] + 0.5, min_b[2] + 0.5]),\n",
        "          np.array([min_b[0] + 0.5, min_b[1] + 0.5, max_b[2] - 0.5]),\n",
        "          np.array([min_b[0] + 0.5, max_b[1] - 0.5, min_b[2] + 0.5]),\n",
        "          np.array([min_b[0] + 0.5, max_b[1] - 0.5, max_b[2] - 0.5]),\n",
        "          np.array([max_b[0] - 0.5, min_b[1] + 0.5, min_b[2] + 0.5]),\n",
        "          np.array([max_b[0] - 0.5, min_b[1] + 0.5, max_b[2] - 0.5]),\n",
        "          np.array([max_b[0] - 0.5, max_b[1] - 0.5, min_b[2] + 0.5]),\n",
        "          np.array([max_b[0] - 0.5, max_b[1] - 0.5, max_b[2] - 0.5]),\n",
        "      ]\n",
        "      for i in range(num_corner_cubes):\n",
        "        final_placements[i][:3] = corner_centers[i]\n",
        "        final_placements[i][3:] = [0, 0, 0]\n",
        "\n",
        "    # NOW, calculate the definitive geometry based on the final placements\n",
        "    rotation_matrices = [\n",
        "        rotation_matrix_3d(p[3], p[4], p[5]) for p in final_placements\n",
        "    ]\n",
        "    all_vertices = [\n",
        "        get_cube_vertices(p[:3], rot)\n",
        "        for p, rot in zip(final_placements, rotation_matrices)\n",
        "    ]\n",
        "    all_axes = [get_cube_axes(rot) for rot in rotation_matrices]\n",
        "\n",
        "    # The REAL side length is from the final, arranged configuration\n",
        "    final_side_length, _, _ = min_bounding_cube_extent_3d(all_vertices)\n",
        "\n",
        "    # Check for intersections\n",
        "    intersection_count = 0\n",
        "    for i in range(num_cubes):\n",
        "      for j in range(i + 1, num_cubes):\n",
        "        if do_cubes_intersect(\n",
        "            all_vertices[i], all_vertices[j], all_axes[i], all_axes[j]\n",
        "        ):\n",
        "          intersection_count += 1\n",
        "          if verbose:\n",
        "            print(f'Intersection between cubes {i} and {j}')\n",
        "            print(f'Vertices: {all_vertices[i]},\\n {all_vertices[j]}')\n",
        "            print(f'Axes: {all_axes[i]}, {all_axes[j]}')\n",
        "            print(f'Minimum bounding box: {final_side_length}')\n",
        "\n",
        "    score = (\n",
        "        -final_side_length - intersection_count * intersection_penalty_factor\n",
        "    )\n",
        "    if return_adjusted_coordinates:\n",
        "      return score, final_placements\n",
        "    return score\n",
        "\n",
        "  except (ValueError, IndexError) as e:\n",
        "    return -1_000_002.0"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vF2kUe7yepWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Final code evolved by AlphaEvolve\n",
        "\n",
        "\"\"\"Finds the smallest cube into which n unit cubes can be packed.\"\"\"\n",
        "import itertools\n",
        "import logging\n",
        "import time\n",
        "from scipy import integrate\n",
        "import numpy as np\n",
        "from scipy import optimize\n",
        "import warnings\n",
        "import random\n",
        "import re\n",
        "from collections.abc import Callable, Mapping\n",
        "from typing import Any, List, Tuple, Dict\n",
        "import scipy.linalg as la\n",
        "import numpy.polynomial.polynomial as poly\n",
        "import collections\n",
        "import copy\n",
        "import math\n",
        "from scipy.spatial.transform import Rotation as R # Import for rotations\n",
        "import scipy.linalg # For null_space if needed, or QR decomposition\n",
        "\n",
        "\n",
        "def normalize_angle(angle: float) -\u003e float:\n",
        "    \"\"\"Normalizes an angle to be within [0, 360).\"\"\"\n",
        "    angle = angle % 360.0\n",
        "    if angle \u003c 0:\n",
        "        angle += 360.0\n",
        "    return angle\n",
        "\n",
        "# Angles relevant for cube packing (axis-aligned, 45-degree, and body-diagonal alignments)\n",
        "THETA_BODY_DIAG = np.degrees(np.arctan(1/np.sqrt(2))) # approx 35.264 degrees\n",
        "\n",
        "# Generate all relevant angles systematically\n",
        "BASE_SNAP_ANGLES = np.array([\n",
        "    0.0, 45.0, THETA_BODY_DIAG, 90.0 - THETA_BODY_DIAG\n",
        "])\n",
        "\n",
        "# Add 90, 180, 270 degrees to each base angle for full coverage\n",
        "SNAP_ANGLES_CUBE = np.concatenate([\n",
        "    BASE_SNAP_ANGLES + i for i in [0.0, 90.0, 180.0, 270.0]\n",
        "])\n",
        "SNAP_ANGLES_CUBE = np.unique(np.sort(SNAP_ANGLES_CUBE % 360.0))\n",
        "\n",
        "\n",
        "# Helper to apply a global rotation and translation to a cube's (pos, angles)\n",
        "def apply_global_transformation_to_cube(x: float, y: float, z: float, ax: float, ay: float, az: float,\n",
        "                                        global_rot_matrix: R, translation_offset: np.ndarray) -\u003e Tuple[float, float, float, float, float, float]:\n",
        "    \"\"\"\n",
        "    Applies a global rotation and translation to a cube's position and orientation.\n",
        "    Args:\n",
        "        x, y, z: Current position of the cube's center.\n",
        "        ax, ay, az: Current Euler angles (degrees) of the cube.\n",
        "        global_rot_matrix: A scipy.spatial.transform.Rotation object representing the global rotation.\n",
        "        translation_offset: A numpy array [tx, ty, tz] for the global translation.\n",
        "    Returns:\n",
        "        Tuple[float, float, float, float, float, float]: New (x, y, z, ax, ay, az) for the cube.\n",
        "    \"\"\"\n",
        "    # Convert position to numpy array\n",
        "    pos_vec = np.array([x, y, z])\n",
        "\n",
        "    # Apply global rotation to position\n",
        "    rotated_pos_vec = global_rot_matrix.apply(pos_vec)\n",
        "\n",
        "    # Apply translation offset\n",
        "    final_pos_vec = rotated_pos_vec + translation_offset\n",
        "\n",
        "    # Original rotation of the cube\n",
        "    R_orig = R.from_euler('xyz', [ax, ay, az], degrees=True)\n",
        "\n",
        "    # Combine original rotation with global rotation.\n",
        "    # The order global_rot_matrix * R_orig means global_rot_matrix is applied first in the sequence,\n",
        "    # then R_orig relative to the newly rotated frame.\n",
        "    R_new = global_rot_matrix * R_orig\n",
        "\n",
        "    # Convert back to Euler angles\n",
        "    new_ax, new_ay, new_az = R_new.as_euler('xyz', degrees=True)\n",
        "\n",
        "    # Ensure angles are within [0, 360)\n",
        "    # Normalize angles\n",
        "    new_ax = normalize_angle(new_ax)\n",
        "    new_ay = normalize_angle(new_ay)\n",
        "    new_az = normalize_angle(new_az)\n",
        "\n",
        "    return final_pos_vec[0], final_pos_vec[1], final_pos_vec[2], new_ax, new_ay, new_az\n",
        "\n",
        "# Predefined canonical global rotations (Euler angles ZYX for consistency, but stored as XYZ for R.from_euler)\n",
        "# These are key orientations for a single cube (or a collection) that may lead to dense packings.\n",
        "CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ = [\n",
        "    (0.0, 0.0, 0.0), # Axis-aligned\n",
        "    (0.0, 0.0, 45.0), # Z-axis 45-degree rotation\n",
        "    (0.0, 45.0, 0.0), # Y-axis 45-degree rotation\n",
        "    (45.0, 0.0, 0.0), # X-axis 45-degree rotation\n",
        "    (90.0, 0.0, 0.0), # 90 degree X\n",
        "    (0.0, 90.0, 0.0), # 90 degree Y\n",
        "    (0.0, 0.0, 90.0), # 90 degree Z\n",
        "]\n",
        "# Ensure angles are within [0, 360) and keep only unique (though these are mostly unique)\n",
        "CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ_UNIQUE = []\n",
        "for rot_tuple in CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ:\n",
        "    normalized_rot = tuple(a % 360 for a in rot_tuple)\n",
        "    if not any(np.allclose(normalized_rot, existing_rot, atol=1e-3) for existing_rot in CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ_UNIQUE):\n",
        "        CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ_UNIQUE.append(normalized_rot)\n",
        "CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ = CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ_UNIQUE\n",
        "\n",
        "# Motifs for \"Crystalline Lattice Mutation\" and predefined initial placements.\n",
        "# Each motif is a list of (x, y, z, ax, ay, az) tuples, centered at origin.\n",
        "# These are known optimal or highly dense packings for small numbers of cubes.\n",
        "MOTIFS = {\n",
        "    1: [\n",
        "        (0.0, 0.0, 0.0, 0.0, 0.0, 0.0) # Single cube\n",
        "    ],\n",
        "    2: [ # Optimal for 2 cubes: two interlocked cubes (side length sqrt(2) approx 1.414)\n",
        "        (0.0, 0.0, 0.0, 45.0, 0.0, 45.0),\n",
        "        (0.0, 0.0, 0.0, 45.0, 90.0, 45.0)\n",
        "    ],\n",
        "    3: [ # Near-optimal for 3 cubes (can achieve side length ~1.83)\n",
        "        (-0.5, 0.0, 0.0, 0.0, 0.0, 0.0),\n",
        "        (0.5, 0.0, 0.0, 0.0, 0.0, 0.0),\n",
        "        (0.0, 0.0, 0.0, 45.0, 45.0, 45.0) # One central rotated cube, two axis-aligned.\n",
        "    ],\n",
        "    4: [ # Optimal for 4 cubes: 2x2x1 axis-aligned block (side length 2.0)\n",
        "        (-0.5, -0.5, 0.0, 0.0, 0.0, 0.0), (0.5, -0.5, 0.0, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, 0.0, 0.0, 0.0, 0.0), (0.5, 0.5, 0.0, 0.0, 0.0, 0.0)\n",
        "    ],\n",
        "    5: [ # This is a common optimal pattern for N=5, side length 2.0.\n",
        "        (-0.5, -0.5, -0.5, 0.0, 0.0, 0.0), (0.5, -0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, -0.5, 0.0, 0.0, 0.0), (0.5, 0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (0.0, 0.0, 0.5, 0.0, 0.0, 0.0)\n",
        "    ],\n",
        "    6: [ # 2x2x2 minus 2, side 2.0\n",
        "        (-0.5, -0.5, -0.5, 0.0, 0.0, 0.0), (0.5, -0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, -0.5, 0.0, 0.0, 0.0), (0.5, 0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, -0.5, 0.5, 0.0, 0.0, 0.0), (0.5, 0.5, 0.5, 0.0, 0.0, 0.0),\n",
        "    ],\n",
        "    7: [ # 2x2x2 minus 1, side 2.0\n",
        "        (-0.5, -0.5, -0.5, 0.0, 0.0, 0.0), (0.5, -0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, -0.5, 0.0, 0.0, 0.0), (0.5, 0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, -0.5, 0.5, 0.0, 0.0, 0.0), (0.5, -0.5, 0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, 0.5, 0.0, 0.0, 0.0)\n",
        "    ],\n",
        "    8: [ # Optimal for 8 cubes: 2x2x2 axis-aligned block (side length 2.0)\n",
        "        (-0.5, -0.5, -0.5, 0.0, 0.0, 0.0), (0.5, -0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, -0.5, 0.0, 0.0, 0.0), (0.5, 0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, -0.5, 0.5, 0.0, 0.0, 0.0), (0.5, -0.5, 0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, 0.5, 0.0, 0.0, 0.0), (0.5, 0.5, 0.5, 0.0, 0.0, 0.0)\n",
        "    ],\n",
        "    9: [ # Optimal for 9 cubes: 8 cubes forming a 2x2x2 block, 1 central rotated cube (side length 2.0)\n",
        "        (-0.5, -0.5, -0.5, 0.0, 0.0, 0.0), (0.5, -0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, -0.5, 0.0, 0.0, 0.0), (0.5, 0.5, -0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, -0.5, 0.5, 0.0, 0.0, 0.0), (0.5, -0.5, 0.5, 0.0, 0.0, 0.0),\n",
        "        (-0.5, 0.5, 0.5, 0.0, 0.0, 0.0), (0.5, 0.5, 0.5, 0.0, 0.0, 0.0),\n",
        "        (0.0, 0.0, 0.0, 45.0, 45.0, 45.0) # Central cube, rotated 45 degrees on all axes\n",
        "    ]\n",
        "}\n",
        "\n",
        "def get_predefined_placements_for_packing(num_cubes: int) -\u003e Optional[List[Tuple]]:\n",
        "    \"\"\"\n",
        "    Returns a predefined optimal or near-optimal placement for specific num_cubes,\n",
        "    or None if no such pattern is defined.\n",
        "    \"\"\"\n",
        "    if num_cubes in MOTIFS:\n",
        "        placements = list(MOTIFS[num_cubes]) # Make a copy to avoid modifying original motif\n",
        "        # Add a very small noise to positions and angles to help SA fine-tune from here.\n",
        "        pos_noise_std = 0.00001\n",
        "        angle_noise_std = 0.001\n",
        "        for i in range(len(placements)):\n",
        "            p = list(placements[i])\n",
        "            p[0] += np.random.normal(0, pos_noise_std)\n",
        "            p[1] += np.random.normal(0, pos_noise_std)\n",
        "            p[2] += np.random.normal(0, pos_noise_std)\n",
        "            p[3] = normalize_angle(p[3] + np.random.normal(0, angle_noise_std))\n",
        "            p[4] = normalize_angle(p[4] + np.random.normal(0, angle_noise_std))\n",
        "            p[5] = normalize_angle(p[5] + np.random.normal(0, angle_noise_std))\n",
        "            placements[i] = tuple(p)\n",
        "        return placements\n",
        "    return None\n",
        "\n",
        "\n",
        "def _get_compact_grid_dimensions(num_cubes: int) -\u003e Tuple[int, int, int]:\n",
        "    \"\"\"Calculates dimensions L, W, H for a compact rectangular grid for num_cubes.\"\"\"\n",
        "    if num_cubes \u003c= 0:\n",
        "        return 0, 0, 0\n",
        "\n",
        "    best_L, best_W, best_H = num_cubes, 1, 1 # Default for 1D case, ensures volume is at least num_cubes\n",
        "    min_max_dim = num_cubes # Minimize the maximum dimension\n",
        "    min_sum_dim = num_cubes + 2 # Minimize the sum of dimensions (as a tie-breaker for max_dim)\n",
        "\n",
        "    # A more restricted search space for L, W, H based on typical packing bounds\n",
        "    # Max dimension is usually \u003c= 2 * ceil(N^(1/3))\n",
        "    max_dim_search = int(math.ceil(num_cubes**(1/3.0)) * 2) + 1 # Add 1 for safety to include max\n",
        "    if num_cubes \u003c= 8: max_dim_search = 3 # For small num_cubes, keep search very tight\n",
        "\n",
        "    for L_candidate in range(1, min(num_cubes + 1, max_dim_search + 1)):\n",
        "        for W_candidate in range(1, min(L_candidate + 1, max_dim_search + 1)): # W \u003c= L for symmetry\n",
        "            # Calculate H such that L*W*H \u003e= num_cubes\n",
        "            H_candidate = int(math.ceil(num_cubes / (L_candidate * W_candidate)))\n",
        "            if H_candidate == 0: H_candidate = 1 # Ensure H is at least 1\n",
        "            if H_candidate \u003e max_dim_search: continue # Prune if H is already too large\n",
        "\n",
        "            if L_candidate * W_candidate * H_candidate \u003e= num_cubes:\n",
        "                current_max_dim = max(L_candidate, W_candidate, H_candidate)\n",
        "                current_sum_dim = L_candidate + W_candidate + H_candidate\n",
        "\n",
        "                # Prioritize minimizing the maximum dimension\n",
        "                if current_max_dim \u003c min_max_dim:\n",
        "                    min_max_dim = current_max_dim\n",
        "                    min_sum_dim = current_sum_dim\n",
        "                    best_L, best_W, best_H = L_candidate, W_candidate, H_candidate\n",
        "                # If max dimensions are equal, prefer smaller sum of dimensions (more \"cuboid\" shape)\n",
        "                elif current_max_dim == min_max_dim:\n",
        "                    if current_sum_dim \u003c min_sum_dim:\n",
        "                        min_sum_dim = current_sum_dim\n",
        "                        best_L, best_W, best_H = L_candidate, W_candidate, H_candidate\n",
        "\n",
        "    return max(1, best_L), max(1, best_W), max(1, best_H)\n",
        "\n",
        "\n",
        "def _apply_strategic_initial_angles(placements: List[List[float]]):\n",
        "  \"\"\"Applies strategic initial angles to placements, biasing towards common optimal orientations.\"\"\"\n",
        "  axis_aligned_prob = 0.4   # 40% chance for angles near 0, 90, 180, 270\n",
        "  forty_five_deg_prob = 0.2 # 20% chance for angles near 45, 135, 225, 315\n",
        "  body_diag_prob = 0.2 # 20% chance for angles near body diagonal angles\n",
        "  # Remaining 20% will be fully random (1.0 - 0.4 - 0.2 - 0.2 = 0.2)\n",
        "\n",
        "  angle_perturb_std = 5.0 # Small standard deviation for initial angle noise (in degrees)\n",
        "\n",
        "  for p in placements:\n",
        "    rand_initial_angle_strategy_selector = np.random.rand()\n",
        "\n",
        "    if rand_initial_angle_strategy_selector \u003c axis_aligned_prob:\n",
        "        # Bias towards axis-aligned orientations\n",
        "        base_angles_axial = [0.0, 90.0, 180.0, 270.0]\n",
        "        p[3] = normalize_angle(np.random.choice(base_angles_axial) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[4] = normalize_angle(np.random.choice(base_angles_axial) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[5] = normalize_angle(np.random.choice(base_angles_axial) + np.random.normal(0.0, angle_perturb_std))\n",
        "    elif rand_initial_angle_strategy_selector \u003c axis_aligned_prob + forty_five_deg_prob:\n",
        "        # Bias towards 45-degree rotations (important for some dense packings)\n",
        "        base_angles_45_deg = [45.0, 135.0, 225.0, 315.0]\n",
        "        p[3] = normalize_angle(np.random.choice(base_angles_45_deg) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[4] = normalize_angle(np.random.choice(base_angles_45_deg) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[5] = normalize_angle(np.random.choice(base_angles_45_deg) + np.random.normal(0.0, angle_perturb_std))\n",
        "    elif rand_initial_angle_strategy_selector \u003c axis_aligned_prob + forty_five_deg_prob + body_diag_prob:\n",
        "        # Bias towards body-diagonal rotations\n",
        "        # Use a subset of SNAP_ANGLES_CUBE that corresponds to body-diagonal angles\n",
        "        body_diag_angles = [a for a in SNAP_ANGLES_CUBE if not np.isclose(a % 45.0, 0.0)]\n",
        "        if not body_diag_angles: body_diag_angles = [35.26, 54.73] # Fallback if SNAP_ANGLES_CUBE is empty\n",
        "        p[3] = normalize_angle(np.random.choice(body_diag_angles) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[4] = normalize_angle(np.random.choice(body_diag_angles) + np.random.normal(0.0, angle_perturb_std))\n",
        "        p[5] = normalize_angle(np.random.choice(body_diag_angles) + np.random.normal(0.0, angle_perturb_std))\n",
        "    else:\n",
        "        # Fully random angles for broad exploration\n",
        "        p[3] = normalize_angle(np.random.uniform(0.0, 360.0))\n",
        "        p[4] = normalize_angle(np.random.uniform(0.0, 360.0))\n",
        "        p[5] = normalize_angle(np.random.uniform(0.0, 360.0))\n",
        "\n",
        "\n",
        "def get_centroid(placements: List[Tuple]) -\u003e Tuple[float, float, float]:\n",
        "  \"\"\"Calculates the centroid of a list of cube placements.\"\"\"\n",
        "  if not placements:\n",
        "    return (0.0, 0.0, 0.0)\n",
        "  x_coords = [p[0] for p in placements]\n",
        "  y_coords = [p[1] for p in placements]\n",
        "  z_coords = [p[2] for p in placements]\n",
        "  return (sum(x_coords) / len(placements),\n",
        "          sum(y_coords) / len(placements),\n",
        "          sum(z_coords) / len(placements))\n",
        "\n",
        "def recenter_placements(placements: List[Tuple]) -\u003e List[Tuple]:\n",
        "  \"\"\"Recalculates the centroid of current placements and shifts them to be centered at origin.\"\"\"\n",
        "  if not placements:\n",
        "    return []\n",
        "\n",
        "  # Calculate centroid\n",
        "  x_coords = [p[0] for p in placements]\n",
        "  y_coords = [p[1] for p in placements]\n",
        "  z_coords = [p[2] for p in placements]\n",
        "\n",
        "  centroid_x = sum(x_coords) / len(placements)\n",
        "  centroid_y = sum(y_coords) / len(placements)\n",
        "  centroid_z = sum(z_coords) / len(placements)\n",
        "\n",
        "  centered_placements = []\n",
        "  for p in placements:\n",
        "    centered_placements.append(\n",
        "        (p[0] - centroid_x, p[1] - centroid_y, p[2] - centroid_z, p[3], p[4], p[5])\n",
        "    )\n",
        "  return centered_placements\n",
        "\n",
        "def snap_angle_to_nearest_optimal(angle: float) -\u003e float:\n",
        "    \"\"\"Snaps an angle to the nearest optimal packing angle (0, 45, 90, ...).\"\"\"\n",
        "    angle = normalize_angle(angle) # Ensure angle is in [0, 360)\n",
        "\n",
        "    # SNAP_ANGLES_CUBE is a global numpy array\n",
        "    distances = np.abs(SNAP_ANGLES_CUBE - angle)\n",
        "    # Handle wrap-around for angles near 0/360 degrees\n",
        "    wrap_around_distances = np.abs(SNAP_ANGLES_CUBE - (angle - 360.0))\n",
        "    distances = np.minimum(distances, wrap_around_distances)\n",
        "\n",
        "    closest_idx = np.argmin(distances)\n",
        "    return SNAP_ANGLES_CUBE[closest_idx]\n",
        "\n",
        "def generate_centered_grid_placements(num_cubes: int) -\u003e List[Tuple]:\n",
        "  \"\"\"Generates a compact rectangular grid of axis-aligned unit cubes centered around the origin.\"\"\"\n",
        "  if num_cubes \u003c= 0:\n",
        "      return []\n",
        "\n",
        "  L, W, H = _get_compact_grid_dimensions(num_cubes)\n",
        "\n",
        "  # Calculate offset to center the cluster of cubes around the origin.\n",
        "  offset_x = (L - 1) / 2.0\n",
        "  offset_y = (W - 1) / 2.0\n",
        "  offset_z = (H - 1) / 2.0\n",
        "\n",
        "  placements = []\n",
        "  # Iterate through the calculated L, W, H dimensions to fill the rectangular prism\n",
        "  for z_idx in range(H):\n",
        "    for y_idx in range(W):\n",
        "      for x_idx in range(L):\n",
        "        if len(placements) \u003c num_cubes: # Only add up to num_cubes\n",
        "          # Apply centering offset and set rotations to 0.0 for axis-aligned cubes\n",
        "          placements.append(\n",
        "              (x_idx - offset_x, y_idx - offset_y, z_idx - offset_z, 0.0, 0.0, 0.0)\n",
        "          )\n",
        "        else:\n",
        "          return placements # Return early once num_cubes are placed\n",
        "  return placements\n",
        "\n",
        "def generate_density_gradient_placements(num_cubes: int) -\u003e List[Tuple]:\n",
        "    \"\"\"\n",
        "    Generates an initial placement of num_cubes unit cubes where rotation\n",
        "    angles are dependent on their distance from the center of the grid,\n",
        "    aiming for a denser, more complex core and more axis-aligned outer cubes.\n",
        "    \"\"\"\n",
        "    if num_cubes \u003c= 0:\n",
        "        return []\n",
        "\n",
        "    # Start with a basic centered grid to get initial positions\n",
        "    initial_grid_placements = generate_centered_grid_placements(num_cubes)\n",
        "    if not initial_grid_placements:\n",
        "        return []\n",
        "\n",
        "    placements = []\n",
        "\n",
        "    # Calculate distances and max_distance to normalize\n",
        "    distances = []\n",
        "    for p in initial_grid_placements:\n",
        "        dist = np.linalg.norm(np.array(p[:3]))\n",
        "        distances.append(dist)\n",
        "\n",
        "    max_distance_overall = max(distances) if distances else 1.0 # Avoid division by zero, min 1.0\n",
        "\n",
        "    pos_noise_std = 0.0001 # Keep position noise low\n",
        "    angle_noise_std = 0.1 # Small noise for angles\n",
        "\n",
        "    # Pre-calculate common rotation types\n",
        "    # Body-diagonal set: (THETA_BODY_DIAG, THETA_BODY_DIAG, THETA_BODY_DIAG) permutations and their complements/90-deg rotations.\n",
        "    # For simplicity, use the specific known optimal (45,45,45) and THETA_BODY_DIAG values.\n",
        "    body_diag_angles = [\n",
        "        (45.0, 45.0, 45.0),\n",
        "        (THETA_BODY_DIAG, THETA_BODY_DIAG, THETA_BODY_DIAG),\n",
        "        (90.0 - THETA_BODY_DIAG, 90.0 - THETA_BODY_DIAG, 90.0 - THETA_BODY_DIAG)\n",
        "    ]\n",
        "    # Face-diagonal set: one axis 45/90/etc, others 0/90.\n",
        "    face_diag_angles = [\n",
        "        (0.0, 0.0, 45.0), (0.0, 45.0, 0.0), (45.0, 0.0, 0.0),\n",
        "        (0.0, 0.0, 90.0), (0.0, 90.0, 0.0), (90.0, 0.0, 0.0),\n",
        "        (0.0, 0.0, 135.0), (0.0, 135.0, 0.0), (135.0, 0.0, 0.0)\n",
        "    ]\n",
        "    # Axis-aligned set: all 0 or 90 or 180 or 270.\n",
        "    axis_aligned_angles = [\n",
        "        (0.0, 0.0, 0.0), (90.0, 0.0, 0.0), (0.0, 90.0, 0.0), (0.0, 0.0, 90.0),\n",
        "        (90.0, 90.0, 0.0), (90.0, 0.0, 90.0), (0.0, 90.0, 90.0), (90.0, 90.0, 90.0)\n",
        "    ]\n",
        "\n",
        "    for i, p in enumerate(initial_grid_placements):\n",
        "        cx, cy, cz = p[:3]\n",
        "        distance = distances[i]\n",
        "        normalized_distance = distance / max_distance_overall # 0.0 at center, 1.0 at max_distance\n",
        "\n",
        "        ax, ay, az = 0.0, 0.0, 0.0 # Default fallback\n",
        "\n",
        "        # Define radial zones for angle assignments\n",
        "        if normalized_distance \u003c 0.25: # Innermost core (e.g., central 25% of cubes by distance)\n",
        "            # Prioritize body-diagonal type rotations\n",
        "            chosen_angles = random.choice(body_diag_angles)\n",
        "            ax, ay, az = chosen_angles\n",
        "            angle_perturb_factor = 0.5 # Larger noise for more exploration in the core\n",
        "\n",
        "        elif normalized_distance \u003c 0.65: # Mid-range (between 25% and 65%)\n",
        "            # Prioritize face-diagonal type rotations\n",
        "            chosen_angles = random.choice(face_diag_angles)\n",
        "            ax, ay, az = chosen_angles\n",
        "            angle_perturb_factor = 0.3 # Medium noise\n",
        "\n",
        "        else: # Outermost layer (beyond 65%)\n",
        "            # Prioritize axis-aligned rotations\n",
        "            chosen_angles = random.choice(axis_aligned_angles)\n",
        "            ax, ay, az = chosen_angles\n",
        "            angle_perturb_factor = 0.1 # Smallest noise for stability at outer boundaries\n",
        "\n",
        "        # Add a perturbation to the chosen angles for fine-tuning by SA\n",
        "        ax = normalize_angle(ax + np.random.normal(0, angle_noise_std * angle_perturb_factor))\n",
        "        ay = normalize_angle(ay + np.random.normal(0, angle_noise_std * angle_perturb_factor))\n",
        "        az = normalize_angle(az + np.random.normal(0, angle_noise_std * angle_perturb_factor))\n",
        "\n",
        "        # Keep positions from the initial grid, add very tiny noise\n",
        "        final_cx = cx + np.random.normal(0, pos_noise_std)\n",
        "        final_cy = cy + np.random.normal(0, pos_noise_std)\n",
        "        final_cz = cz + np.random.normal(0, pos_noise_std)\n",
        "\n",
        "        placements.append((final_cx, final_cy, final_cz, ax, ay, az))\n",
        "\n",
        "    return placements\n",
        "\n",
        "\n",
        "def generate_staggered_placements(num_cubes: int) -\u003e List[Tuple]:\n",
        "    \"\"\"Generates a compact rectangular grid of axis-aligned unit cubes,\n",
        "    with alternating layers offset, centered around the origin.\n",
        "    This aims to provide a denser initial packing than a simple grid.\"\"\"\n",
        "    if num_cubes \u003c= 0:\n",
        "        return []\n",
        "\n",
        "    L, W, H = _get_compact_grid_dimensions(num_cubes)\n",
        "\n",
        "    placements = []\n",
        "    # Staggering logic: offset alternate layers in X and Y by 0.5 units\n",
        "    for z_idx in range(H):\n",
        "      for y_idx in range(W):\n",
        "        for x_idx in range(L):\n",
        "          if len(placements) \u003c num_cubes:\n",
        "            x_offset = 0.0\n",
        "            y_offset = 0.0\n",
        "            # Apply offset to odd layers (z_idx is 0-indexed)\n",
        "            if (z_idx % 2) == 1:\n",
        "                x_offset = 0.5\n",
        "                y_offset = 0.5\n",
        "\n",
        "            placements.append(\n",
        "                (x_idx + x_offset, y_idx + y_offset, z_idx, 0.0, 0.0, 0.0)\n",
        "            )\n",
        "          else:\n",
        "            break # Stop adding cubes once num_cubes is reached\n",
        "        if len(placements) \u003e= num_cubes:\n",
        "            break\n",
        "      if len(placements) \u003e= num_cubes:\n",
        "          break\n",
        "\n",
        "    # Calculate overall centroid of the generated points to center them.\n",
        "    # This accounts for the actual bounds of the staggered arrangement.\n",
        "    max_x = max(p[0] for p in placements) if placements else 0.0\n",
        "    min_x = min(p[0] for p in placements) if placements else 0.0\n",
        "    max_y = max(p[1] for p in placements) if placements else 0.0\n",
        "    min_y = min(p[1] for p in placements) if placements else 0.0\n",
        "    max_z = max(p[2] for p in placements) if placements else 0.0\n",
        "    min_z = min(p[2] for p in placements) if placements else 0.0\n",
        "\n",
        "    actual_center_x = (max_x + min_x) / 2.0\n",
        "    actual_center_y = (max_y + min_y) / 2.0\n",
        "    actual_center_z = (max_z + min_z) / 2.0\n",
        "\n",
        "    centered_placements = []\n",
        "    for p in placements:\n",
        "        centered_placements.append(\n",
        "            (p[0] - actual_center_x, p[1] - actual_center_y, p[2] - actual_center_z, p[3], p[4], p[5])\n",
        "        )\n",
        "\n",
        "    return centered_placements\n",
        "\n",
        "def generate_crystalline_checkerboard_placements(num_cubes: int) -\u003e List[Tuple]:\n",
        "    \"\"\"\n",
        "    Generates an initial placement of num_cubes unit cubes in a compact grid,\n",
        "    with an alternating 'checkerboard' pattern of axis-aligned (0,0,0)\n",
        "    and diagonally rotated (45,45,45) cubes. This aims to create an interlocked,\n",
        "    dense initial structure.\n",
        "    \"\"\"\n",
        "    if num_cubes \u003c= 0:\n",
        "        return []\n",
        "\n",
        "    L, W, H = _get_compact_grid_dimensions(num_cubes)\n",
        "\n",
        "    placements = []\n",
        "\n",
        "    # Calculate offset to center the cluster of cubes around the origin.\n",
        "    offset_x = (L - 1) / 2.0\n",
        "    offset_y = (W - 1) / 2.0\n",
        "    offset_z = (H - 1) / 2.0\n",
        "\n",
        "    pos_noise_std = 0.0001\n",
        "    angle_noise_std = 0.01\n",
        "\n",
        "    for z_idx in range(H):\n",
        "        for y_idx in range(W):\n",
        "            for x_idx in range(L):\n",
        "                if len(placements) \u003c num_cubes:\n",
        "                    cx = (x_idx - offset_x) + np.random.normal(0, pos_noise_std)\n",
        "                    cy = (y_idx - offset_y) + np.random.normal(0, pos_noise_std)\n",
        "                    cz = (z_idx - offset_z) + np.random.normal(0, pos_noise_std)\n",
        "\n",
        "                    # Apply checkerboard rotation pattern\n",
        "                    if (x_idx + y_idx + z_idx) % 2 == 0: # Even sum of indices\n",
        "                        ax, ay, az = (0.0, 0.0, 0.0) # Axis-aligned\n",
        "                    else: # Odd sum of indices\n",
        "                        ax, ay, az = (45.0, 45.0, 45.0) # Diagonally rotated\n",
        "\n",
        "                    ax = normalize_angle(ax + np.random.normal(0, angle_noise_std))\n",
        "                    ay = normalize_angle(ay + np.random.normal(0, angle_noise_std))\n",
        "                    az = normalize_angle(az + np.random.normal(0, angle_noise_std))\n",
        "\n",
        "                    placements.append((cx, cy, cz, ax, ay, az))\n",
        "                else:\n",
        "                    return placements\n",
        "    return placements\n",
        "\n",
        "def search_for_best_packings_3d(num_cubes: int) -\u003e List[Tuple]:\n",
        "  \"\"\"Searches for the best packing of unit cubes into a container cube.\"\"\"\n",
        "  variable_name = f'best_placements_3d_{num_cubes}'\n",
        "\n",
        "  initial_placements_tuple = []\n",
        "  eval_count = 0\n",
        "\n",
        "  # Option 1: Try to load previous best from globals()\n",
        "  if variable_name in globals() and np.random.rand() \u003c 0.99:\n",
        "    candidate_placements_tuple = [tuple(p) for p in globals()[variable_name]]\n",
        "    score, fixed_candidate = calculate_packing_score_cubes_3d(candidate_placements_tuple, num_cubes)\n",
        "    eval_count += 1\n",
        "    if score \u003e float('-inf'): # Ensure it's a valid placement\n",
        "        initial_placements_tuple = fixed_candidate\n",
        "        best_score = score\n",
        "    else: # Fallback to generating if loaded configuration is invalid\n",
        "        logging.warning(f\"Loaded configuration for {num_cubes} cubes was invalid. Generating new.\")\n",
        "\n",
        "  # Option 2: If no valid loaded configuration, generate and evaluate initial strategies\n",
        "  if not initial_placements_tuple or best_score == float('-inf'):\n",
        "    # List of initial placement strategies\n",
        "    initial_strategies_funcs = [\n",
        "        get_predefined_placements_for_packing,\n",
        "        generate_crystalline_checkerboard_placements, # New strategy: Crystalline Checkerboard\n",
        "        generate_centered_grid_placements,\n",
        "        generate_staggered_placements,\n",
        "        generate_density_gradient_placements,\n",
        "    ]\n",
        "\n",
        "    current_best_initial_score = -float('inf')\n",
        "    current_best_initial_placements = []\n",
        "\n",
        "    for generate_func in initial_strategies_funcs:\n",
        "        if num_cubes == 0: continue\n",
        "\n",
        "        temp_placements_list_tuples = generate_func(num_cubes)\n",
        "        if temp_placements_list_tuples is None: # For \"Predefined\" strategy, it might return None\n",
        "            continue\n",
        "\n",
        "        # Convert to list of lists for potential modification\n",
        "        temp_placements_list_mutable = [list(p) for p in temp_placements_list_tuples]\n",
        "\n",
        "        # Apply additional angle strategies only if the generator didn't already handle complex angles\n",
        "        # Apply additional angle strategies only if the generator didn't already handle complex angles.\n",
        "        # Functions that produce their own angles: get_predefined_placements_for_packing,\n",
        "        # generate_density_gradient_placements, and generate_crystalline_checkerboard_placements.\n",
        "        # Functions that start with (0,0,0) angles: generate_centered_grid_placements, generate_staggered_placements.\n",
        "        if generate_func in [generate_centered_grid_placements, generate_staggered_placements]:\n",
        "            _apply_strategic_initial_angles(temp_placements_list_mutable)\n",
        "\n",
        "        strategy_name = generate_func.__name__ # Use function name for logging\n",
        "        logging.info(f'Evaluating initial configuration: {strategy_name} for num_cubes={num_cubes}')\n",
        "\n",
        "        score, fixed_placements = calculate_packing_score_cubes_3d(temp_placements_list_mutable, num_cubes)\n",
        "        eval_count += 1\n",
        "\n",
        "        squeezed_placements = squeeze_placements_3d(\n",
        "            [tuple(item) for item in fixed_placements],\n",
        "            num_passes=20, # Aggressive squeeze for initial configurations\n",
        "            binary_search_iterations=40,\n",
        "        )\n",
        "        squeezed_score, fixed_squeezed = calculate_packing_score_cubes_3d(squeezed_placements, num_cubes)\n",
        "        eval_count += 1\n",
        "\n",
        "        if squeezed_score \u003e current_best_initial_score:\n",
        "            current_best_initial_score = squeezed_score\n",
        "            current_best_initial_placements = copy.deepcopy(fixed_squeezed)\n",
        "            logging.info(f'New best initial from {strategy_name}: {current_best_initial_score}, side: {-current_best_initial_score}')\n",
        "\n",
        "    initial_placements_tuple = current_best_initial_placements\n",
        "    best_score = current_best_initial_score\n",
        "\n",
        "    # Handle case where num_cubes is 0 or initial generation fails somehow\n",
        "    if not initial_placements_tuple or best_score == float('-inf'):\n",
        "        initial_placements_tuple = [(0.0, 0.0, 0.0, 0.0, 0.0, 0.0)] * num_cubes\n",
        "        if num_cubes \u003e 0:\n",
        "            logging.warning(\"Initial placement generation failed or was invalid. Using fallback to default origin cube(s).\")\n",
        "        score_fallback, fixed_fallback = calculate_packing_score_cubes_3d(\n",
        "            initial_placements_tuple, num_cubes\n",
        "        )\n",
        "        eval_count += 1\n",
        "        initial_placements_tuple = fixed_fallback\n",
        "        best_score = score_fallback\n",
        "\n",
        "  current_score, fixed_current_placements = calculate_packing_score_cubes_3d(\n",
        "      initial_placements_tuple, num_cubes # initial_placements_tuple is already prepared (loaded or generated)\n",
        "  )\n",
        "  current_placements_tuple = [tuple(p) for p in fixed_current_placements]\n",
        "  eval_count += 1 # Count initial score evaluation\n",
        "\n",
        "  best_placements = copy.deepcopy(current_placements_tuple)\n",
        "  best_score = current_score\n",
        "\n",
        "  print(\n",
        "      f'Initial score: {best_score}, side:'\n",
        "      f' {-best_score if best_score \u003e -1000 else \"N/A\"}'\n",
        "  )\n",
        "\n",
        "  start_time = time.time()\n",
        "  # eval_count is already initialized and incremented in the initial placement block.\n",
        "  last_best_score_update_eval = eval_count # Initialize stagnation tracker with initial evaluations\n",
        "  max_running_time = 990  # Use almost full allocated time for the search\n",
        "\n",
        "  # SA temperature parameters (Adjusted for simpler mutation scheme)\n",
        "  initial_temperature = 1.0 # Higher initial temperature for more aggressive exploration\n",
        "  min_temperature = 1e-7 # Standard minimum temperature\n",
        "\n",
        "  # SA temperature parameters\n",
        "  initial_temperature = 1.5 # Start hotter for more exploration\n",
        "  min_temperature = 1e-8 # Slightly lower min temp\n",
        "\n",
        "  # Parameters for individual_perturbation, local_correlated_perturbation, correlated_subset_perturbation\n",
        "  base_pos_std_initial = 0.20 # Slightly larger initial positional noise\n",
        "  base_pos_std_min = 0.000005 # Slightly smaller final positional noise\n",
        "  base_angle_std_initial = 30.0 # Slightly larger initial angular noise\n",
        "  base_angle_std_min = 0.0005 # Slightly smaller final angular noise\n",
        "\n",
        "  # Parameters for Global Rotation Mutation (kept separate due to larger range)\n",
        "  global_rot_std_initial = 90.0 # Degrees, focus on more common global rotations\n",
        "  global_rot_std_min = 0.5 # Degrees\n",
        "\n",
        "  # Parameters for Slip Plane Mutation\n",
        "  slip_magnitude_std_initial = 0.30 # Units of distance\n",
        "  slip_magnitude_std_min = 0.001 # Units of distance\n",
        "\n",
        "  # Parameters for Rigid Sub-Cluster Transformation\n",
        "  sub_cluster_rigid_pos_std_initial = 0.5 # Larger initial position shift for rigid clusters\n",
        "  sub_cluster_rigid_pos_std_min = 0.005 # Final position shift for rigid clusters\n",
        "  sub_cluster_rigid_angle_std_initial = 45.0 # Larger initial angle for rigid clusters\n",
        "  sub_cluster_rigid_angle_std_min = 0.5 # Final angle for rigid clusters\n",
        "\n",
        "  # Parameters for Periodic Squeeze of current SA state\n",
        "  initial_periodic_squeeze_prob = 0.05 # Start lower for more exploration\n",
        "  final_periodic_squeeze_prob = 0.20 # End higher for more exploitation via squeeze\n",
        "\n",
        "  initial_periodic_squeezing_passes = 3 # Start with fewer passes\n",
        "  final_periodic_squeezing_passes = 15 # End with more thorough passes\n",
        "\n",
        "  initial_periodic_squeezing_iterations = 5 # Start with fewer iterations\n",
        "  final_periodic_squeezing_iterations = 30 # End with more thorough iterations\n",
        "\n",
        "  # Mutation probabilities (initial and final for annealing)\n",
        "  # Sum of these probabilities should be 1.0.\n",
        "  mutation_probs_initial = {\n",
        "      'revert_to_best': 0.001, # Renamed from full_reset\n",
        "      'global_scaling': 0.02,\n",
        "      'global_rotation': 0.03,\n",
        "      'snap_to_angle': 0.05666,\n",
        "      'crystalline_lattice_mutation': 0.14,\n",
        "      'rigid_sub_cluster_transformation': 0.08,\n",
        "      'local_correlated_perturbation': 0.35,\n",
        "      'individual_perturbation': 0.15,\n",
        "      'cohesive_force_mutation': 0.08,\n",
        "      'stochastic_relocation_mutation': 0.04, # Reduced slightly\n",
        "      'layer_shift_mutation': 0.03, # Reduced slightly\n",
        "      'quantum_leap_mutation': 0.01, # New mutation, low initial probability\n",
        "      'crystalline_shear_mutation': 0.03, # New mutation, medium initial probability\n",
        "  }\n",
        "  mutation_probs_final = {\n",
        "      'revert_to_best': 0.0005,\n",
        "      'global_scaling': 0.005,\n",
        "      'global_rotation': 0.002,\n",
        "      'snap_to_angle': 0.23,\n",
        "      'crystalline_lattice_mutation': 0.06,\n",
        "      'rigid_sub_cluster_transformation': 0.04,\n",
        "      'local_correlated_perturbation': 0.38,\n",
        "      'individual_perturbation': 0.10,\n",
        "      'cohesive_force_mutation': 0.14,\n",
        "      'stochastic_relocation_mutation': 0.005, # Reduced more\n",
        "      'layer_shift_mutation': 0.025, # Reduced more\n",
        "      'quantum_leap_mutation': 0.005, # Kept low, more of a disruptor\n",
        "      'crystalline_shear_mutation': 0.06, # Increased in final stages for exploitation\n",
        "  }\n",
        "\n",
        "  while time.time() - start_time \u003c max_running_time:\n",
        "    elapsed_time_ratio = (time.time() - start_time) / max_running_time\n",
        "    elapsed_time_ratio = min(max(elapsed_time_ratio, 0.0), 1.0) # Clamp\n",
        "\n",
        "    # Annealing schedule for temperature\n",
        "    current_T = initial_temperature * (min_temperature / initial_temperature) ** elapsed_time_ratio\n",
        "    current_T = max(min_temperature, current_T)\n",
        "\n",
        "    # --- Adaptive Reheating Logic ---\n",
        "    # If a certain number of evaluations have passed without improvement, reheat.\n",
        "    stagnation_threshold_evals = 1000 + 50 * num_cubes # Adjust threshold dynamically, more for larger N\n",
        "    if eval_count - last_best_score_update_eval \u003e stagnation_threshold_evals:\n",
        "        # Reheat temperature to a fraction of initial temperature or current T.\n",
        "        reheat_factor = 0.5 # Reheat to 50% of initial temperature or a higher fraction of current T\n",
        "        current_T = max(initial_temperature * reheat_factor, current_T * 1.5) # Reheat or increase by 1.5x, whichever is higher\n",
        "        logging.info(f\"Reheating SA: score stagnated for {stagnation_threshold_evals} evals. New Temp: {current_T:.4f}\")\n",
        "        last_best_score_update_eval = eval_count # Reset stagnation tracker after reheating\n",
        "\n",
        "    # Anneal step sizes for perturbations\n",
        "    pos_std = base_pos_std_initial * (base_pos_std_min / base_pos_std_initial) ** elapsed_time_ratio\n",
        "    pos_std = max(base_pos_std_min, pos_std)\n",
        "    angle_std = base_angle_std_initial * (base_angle_std_min / base_angle_std_initial) ** elapsed_time_ratio\n",
        "    angle_std = max(base_angle_std_min, angle_std)\n",
        "\n",
        "    # Anneal global rotation std\n",
        "    global_rot_std = global_rot_std_initial * (global_rot_std_min / global_rot_std_initial) ** elapsed_time_ratio\n",
        "    global_rot_std = max(global_rot_std_min, global_rot_std)\n",
        "\n",
        "    # Anneal slip magnitude std\n",
        "    slip_magnitude_std = slip_magnitude_std_initial * (slip_magnitude_std_min / slip_magnitude_std_initial) ** elapsed_time_ratio\n",
        "    slip_magnitude_std = max(slip_magnitude_std_min, slip_magnitude_std)\n",
        "\n",
        "    # Anneal rigid sub-cluster transformation stds\n",
        "    sub_cluster_rigid_pos_std = sub_cluster_rigid_pos_std_initial * (sub_cluster_rigid_pos_std_min / sub_cluster_rigid_pos_std_initial) ** elapsed_time_ratio\n",
        "    sub_cluster_rigid_pos_std = max(sub_cluster_rigid_pos_std_min, sub_cluster_rigid_pos_std)\n",
        "    sub_cluster_rigid_angle_std = sub_cluster_rigid_angle_std_initial * (sub_cluster_rigid_angle_std_min / sub_cluster_rigid_angle_std_initial) ** elapsed_time_ratio\n",
        "    sub_cluster_rigid_angle_std = max(sub_cluster_rigid_angle_std_min, sub_cluster_rigid_angle_std)\n",
        "\n",
        "    # Anneal periodic squeeze probability and passes/iterations\n",
        "    periodic_squeeze_prob = initial_periodic_squeeze_prob * (final_periodic_squeeze_prob / initial_periodic_squeeze_prob) ** (1 - elapsed_time_ratio)\n",
        "    periodic_squeezing_passes_current = int(initial_periodic_squeezing_passes + (final_periodic_squeezing_passes - initial_periodic_squeezing_passes) * elapsed_time_ratio)\n",
        "    periodic_squeezing_iterations_current = int(initial_periodic_squeezing_iterations + (final_periodic_squeezing_iterations - initial_periodic_squeezing_iterations) * elapsed_time_ratio)\n",
        "\n",
        "    # PERIODIC SQUEEZE ON CURRENT SA STATE (Greedy Local Optimization)\n",
        "    if np.random.rand() \u003c periodic_squeeze_prob:\n",
        "        logging.info(f\"Applying periodic squeeze to current SA state. Temp: {current_T:.4f}, Passes: {periodic_squeezing_passes_current}, Iterations: {periodic_squeezing_iterations_current}\")\n",
        "        squeezed_sa_state = squeeze_placements_3d(\n",
        "            current_placements_tuple, # Use the current SA state\n",
        "            num_passes=periodic_squeezing_passes_current,\n",
        "            binary_search_iterations=periodic_squeezing_iterations_current,\n",
        "        )\n",
        "        squeezed_sa_score, fixed_squeezed_sa_state = calculate_packing_score_cubes_3d(squeezed_sa_state, num_cubes)\n",
        "        eval_count += 1 # Count this evaluation\n",
        "\n",
        "        # If the squeezed state is an improvement, update current SA state.\n",
        "        if squeezed_sa_score \u003e current_score:\n",
        "            current_score = squeezed_sa_score\n",
        "            current_placements_tuple = fixed_squeezed_sa_state\n",
        "            logging.info(f\"Periodic squeeze improved current SA state to score: {current_score}, side: {-current_score}\")\n",
        "            if current_score \u003e best_score:\n",
        "                best_score = current_score\n",
        "                best_placements = copy.deepcopy(current_placements_tuple)\n",
        "                logging.info(f'New absolute best score (from periodic squeeze): {best_score}, side: {-best_score if best_score \u003e -1000 else \"N/A\"}')\n",
        "\n",
        "\n",
        "    candidate_placements_list = [list(p) for p in current_placements_tuple] # Start from current SA state\n",
        "\n",
        "    # Anneal mutation probabilities\n",
        "    current_mutation_probs = {}\n",
        "    for key in mutation_probs_initial:\n",
        "        initial_p = mutation_probs_initial[key]\n",
        "        final_p = mutation_probs_final[key]\n",
        "        # Linear interpolation of probabilities: initial_p at ratio=0, final_p at ratio=1\n",
        "        current_mutation_probs[key] = initial_p + (final_p - initial_p) * elapsed_time_ratio\n",
        "\n",
        "    # Normalize probabilities to ensure they sum to 1\n",
        "    sum_current_probs = sum(current_mutation_probs.values())\n",
        "    if sum_current_probs \u003e 0: # Avoid division by zero\n",
        "        for key in current_mutation_probs:\n",
        "            current_mutation_probs[key] /= sum_current_probs\n",
        "    else: # Fallback to equal probabilities if sum is zero (should not happen with current defs)\n",
        "        num_mutations = len(mutation_probs_initial)\n",
        "        for key in mutation_probs_initial:\n",
        "            current_mutation_probs[key] = 1.0 / num_mutations\n",
        "\n",
        "    mutation_types = list(current_mutation_probs.keys())\n",
        "    mutation_probabilities = list(current_mutation_probs.values())\n",
        "\n",
        "    # Determine which mutation to apply\n",
        "    mutation_choice = np.random.choice(mutation_types, p=mutation_probabilities)\n",
        "\n",
        "    if mutation_choice == 'revert_to_best': # Renamed from full_reset\n",
        "        candidate_placements_list = [list(p) for p in best_placements]\n",
        "        logging.info(f\"Reverted to best placements.\")\n",
        "    elif mutation_choice == 'global_scaling':\n",
        "        # Apply scaling relative to the current centroid of the cubes\n",
        "        current_centroid = get_centroid([tuple(p) for p in candidate_placements_list])\n",
        "        # scale_factor varies less aggressively than pos_std\n",
        "        scale_perturb_std = (base_pos_std_initial * 0.1) * ((base_pos_std_min * 0.1) / (base_pos_std_initial * 0.1)) ** elapsed_time_ratio\n",
        "        scale_factor = 1.0 + np.random.normal(0, scale_perturb_std)\n",
        "        scale_factor = np.clip(scale_factor, 0.95, 1.05) # Prevent extreme scaling\n",
        "        for i in range(num_cubes):\n",
        "            candidate_placements_list[i][0] = current_centroid[0] + (candidate_placements_list[i][0] - current_centroid[0]) * scale_factor\n",
        "            candidate_placements_list[i][1] = current_centroid[1] + (candidate_placements_list[i][1] - current_centroid[1]) * scale_factor\n",
        "            candidate_placements_list[i][2] = current_centroid[2] + (candidate_placements_list[i][2] - current_centroid[2]) * scale_factor\n",
        "    elif mutation_choice == 'global_rotation':\n",
        "        rot_x_global = np.random.normal(0, global_rot_std)\n",
        "        rot_y_global = np.random.normal(0, global_rot_std)\n",
        "        rot_z_global = np.random.normal(0, global_rot_std)\n",
        "        global_rot_obj = R.from_euler('xyz', [rot_x_global, rot_y_global, rot_z_global], degrees=True)\n",
        "        current_centroid = get_centroid([tuple(p) for p in candidate_placements_list])\n",
        "        for i in range(num_cubes):\n",
        "            # Rotate position relative to centroid\n",
        "            pos = np.array(candidate_placements_list[i][:3]) - current_centroid\n",
        "            rotated_pos = global_rot_obj.apply(pos)\n",
        "            candidate_placements_list[i][0] = rotated_pos[0] + current_centroid[0]\n",
        "            candidate_placements_list[i][1] = rotated_pos[1] + current_centroid[1]\n",
        "            candidate_placements_list[i][2] = rotated_pos[2] + current_centroid[2]\n",
        "            # Combine cube's own rotation with global rotation\n",
        "            current_cube_rot = R.from_euler('xyz', candidate_placements_list[i][3:6], degrees=True)\n",
        "            new_cube_rot_obj = global_rot_obj * current_cube_rot\n",
        "            new_angles = new_cube_rot_obj.as_euler('xyz', degrees=True)\n",
        "            candidate_placements_list[i][3] = normalize_angle(new_angles[0])\n",
        "            candidate_placements_list[i][4] = normalize_angle(new_angles[1])\n",
        "            candidate_placements_list[i][5] = normalize_angle(new_angles[2])\n",
        "    elif mutation_choice == 'snap_to_angle':\n",
        "        if num_cubes == 0: continue\n",
        "        idx_to_mutate = np.random.randint(0, num_cubes)\n",
        "        # Apply small position perturbation for shaking\n",
        "        candidate_placements_list[idx_to_mutate][0] += np.random.normal(0, pos_std * 0.1)\n",
        "        candidate_placements_list[idx_to_mutate][1] += np.random.normal(0, pos_std * 0.1)\n",
        "        candidate_placements_list[idx_to_mutate][2] += np.random.normal(0, pos_std * 0.1)\n",
        "        # Snap angles and add small perturbation\n",
        "        for angle_idx in range(3, 6):\n",
        "            snapped_angle = snap_angle_to_nearest_optimal(candidate_placements_list[idx_to_mutate][angle_idx])\n",
        "            candidate_placements_list[idx_to_mutate][angle_idx] = normalize_angle(snapped_angle + np.random.normal(0, angle_std * 0.05))\n",
        "    elif mutation_choice == 'correlated_subset_perturbation': # Formerly 'cluster_mutation'\n",
        "        if num_cubes \u003c 2: continue\n",
        "        # Cluster size adapts: larger clusters early, smaller for fine-tuning\n",
        "        max_cluster_size = max(1, int(num_cubes * (0.6 - 0.5 * elapsed_time_ratio))) # Max 0.6*N, min 0.1*N\n",
        "        min_cluster_size = 1\n",
        "        cluster_size = np.random.randint(min_cluster_size, max_cluster_size + 1)\n",
        "\n",
        "        cluster_indices = np.random.choice(num_cubes, cluster_size, replace=False)\n",
        "\n",
        "        trans_x = np.random.normal(0, pos_std * 2.0) # Larger step for clusters\n",
        "        trans_y = np.random.normal(0, pos_std * 2.0)\n",
        "        trans_z = np.random.normal(0, pos_std * 2.0)\n",
        "        rot_x = np.random.normal(0, angle_std * 1.5) # Larger angle for clusters\n",
        "        rot_y = np.random.normal(0, angle_std * 1.5)\n",
        "        rot_z = np.random.normal(0, angle_std * 1.5)\n",
        "\n",
        "        for idx in cluster_indices:\n",
        "            candidate_placements_list[idx][0] += trans_x\n",
        "            candidate_placements_list[idx][1] += trans_y\n",
        "            candidate_placements_list[idx][2] += trans_z\n",
        "            candidate_placements_list[idx][3] = normalize_angle(candidate_placements_list[idx][3] + rot_x)\n",
        "            candidate_placements_list[idx][4] = normalize_angle(candidate_placements_list[idx][4] + rot_y)\n",
        "            candidate_placements_list[idx][5] = normalize_angle(candidate_placements_list[idx][5] + rot_z)\n",
        "    elif mutation_choice == 'crystalline_lattice_mutation':\n",
        "        if num_cubes == 0: continue\n",
        "        available_motif_sizes = [s for s in MOTIFS.keys() if s \u003c= num_cubes]\n",
        "        if not available_motif_sizes:\n",
        "            logging.debug(\"No suitable motifs for Crystalline Lattice Mutation, falling back to local correlated.\")\n",
        "            # Fallback to local correlated perturbation if no motifs available for current num_cubes\n",
        "            mutation_choice = 'local_correlated_perturbation'\n",
        "        else:\n",
        "            motif_size = np.random.choice(available_motif_sizes)\n",
        "            chosen_motif = MOTIFS[motif_size]\n",
        "\n",
        "            # Choose a strategic global rotation from the predefined list\n",
        "            if CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ:\n",
        "                global_rot_euler = random.choice(CANONICAL_GLOBAL_ROTATIONS_EULER_XYZ)\n",
        "                global_rot_matrix = R.from_euler('xyz', global_rot_euler, degrees=True)\n",
        "                # Add a small perturbation to the strategic rotation to allow fine-tuning\n",
        "                global_rot_noise_std = angle_std * 0.1 # Use annealed angle_std for noise\n",
        "                global_rot_matrix = R.from_euler('xyz', np.array(global_rot_euler) + np.random.normal(0, global_rot_noise_std, 3), degrees=True)\n",
        "            else: # Fallback to random if for some reason canonical rotations are empty\n",
        "                global_rot_rand_euler = np.random.uniform(0, 360, 3)\n",
        "                global_rot_matrix = R.from_euler('xyz', global_rot_rand_euler, degrees=True)\n",
        "\n",
        "            # Apply a smaller perturbation factor when closer to optimal temperature\n",
        "            # This applies to the noise added to motif positions and orientations\n",
        "            perturb_factor = 0.05 + 0.1 * (1.0 - elapsed_time_ratio)\n",
        "            perturb_factor = max(0.01, perturb_factor) # Minimum perturb factor\n",
        "\n",
        "            if num_cubes == motif_size: # If motif size matches total cubes, replace all\n",
        "                new_placements_from_motif = []\n",
        "                for mx, my, mz, max_orig, may_orig, maz_orig in chosen_motif:\n",
        "                    new_x, new_y, new_z, new_ax, new_ay, new_az = apply_global_transformation_to_cube(\n",
        "                        mx, my, mz, max_orig, may_orig, maz_orig, global_rot_matrix, np.array([0.0,0.0,0.0])\n",
        "                    )\n",
        "                    # Add noise\n",
        "                    new_x += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_y += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_z += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_ax = normalize_angle(new_ax + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_ay = normalize_angle(new_ay + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_az = normalize_angle(new_az + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_placements_from_motif.append([new_x, new_y, new_z, new_ax, new_ay, new_az])\n",
        "\n",
        "                candidate_placements_list = recenter_placements([tuple(p) for p in new_placements_from_motif])\n",
        "                candidate_placements_list = [list(p) for p in candidate_placements_list]\n",
        "\n",
        "            else: # Replace a subset with the motif\n",
        "                indices_to_replace = np.random.choice(num_cubes, motif_size, replace=False)\n",
        "\n",
        "                selected_cubes_positions = np.array([\n",
        "                    candidate_placements_list[i][:3] for i in indices_to_replace\n",
        "                ])\n",
        "                if len(selected_cubes_positions) == 0: continue\n",
        "                current_subset_centroid = np.mean(selected_cubes_positions, axis=0)\n",
        "\n",
        "                new_motif_placements = []\n",
        "                for mx, my, mz, max_orig, may_orig, maz_orig in chosen_motif:\n",
        "                    new_x, new_y, new_z, new_ax, new_ay, new_az = apply_global_transformation_to_cube(\n",
        "                        mx, my, mz, max_orig, may_orig, maz_orig, global_rot_matrix, current_subset_centroid\n",
        "                    )\n",
        "                    # Add noise\n",
        "                    new_x += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_y += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_z += np.random.normal(0, pos_std * perturb_factor)\n",
        "                    new_ax = normalize_angle(new_ax + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_ay = normalize_angle(new_ay + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_az = normalize_angle(new_az + np.random.normal(0, angle_std * perturb_factor))\n",
        "                    new_motif_placements.append([new_x, new_y, new_z, new_ax, new_ay, new_az])\n",
        "\n",
        "                for i, original_idx in enumerate(indices_to_replace):\n",
        "                    if i \u003c len(new_motif_placements):\n",
        "                       candidate_placements_list[original_idx] = new_motif_placements[i]\n",
        "    elif mutation_choice == 'rigid_sub_cluster_transformation':\n",
        "        if num_cubes \u003c 2: continue # Needs at least 2 cubes for a cluster\n",
        "\n",
        "        # Choose a cluster size between 2 and N/2, or at least 2\n",
        "        cluster_size = np.random.randint(2, max(3, num_cubes // 2 + 1))\n",
        "        cluster_indices = np.random.choice(num_cubes, cluster_size, replace=False)\n",
        "\n",
        "        # Calculate centroid of the selected sub-cluster\n",
        "        cluster_positions = np.array([candidate_placements_list[idx][:3] for idx in cluster_indices])\n",
        "        if cluster_positions.shape[0] == 0: continue # Should not happen if cluster_size \u003e= 1\n",
        "        cluster_centroid = np.mean(cluster_positions, axis=0)\n",
        "\n",
        "        # Generate translation for the rigid sub-cluster\n",
        "        trans_offset = np.random.normal(0, sub_cluster_rigid_pos_std, 3)\n",
        "\n",
        "        # Generate rotation for the rigid sub-cluster\n",
        "        rot_x_cluster = np.random.normal(0, sub_cluster_rigid_angle_std)\n",
        "        rot_y_cluster = np.random.normal(0, sub_cluster_rigid_angle_std)\n",
        "        rot_z_cluster = np.random.normal(0, sub_cluster_rigid_angle_std)\n",
        "        cluster_rot_obj = R.from_euler('xyz', [rot_x_cluster, rot_y_cluster, rot_z_cluster], degrees=True)\n",
        "\n",
        "        for idx in cluster_indices:\n",
        "            # Apply translation relative to cluster centroid, then add offset\n",
        "            pos_vec = np.array(candidate_placements_list[idx][:3])\n",
        "            pos_relative_to_centroid = pos_vec - cluster_centroid\n",
        "            rotated_pos_relative = cluster_rot_obj.apply(pos_relative_to_centroid)\n",
        "            final_pos = rotated_pos_relative + cluster_centroid + trans_offset\n",
        "\n",
        "            candidate_placements_list[idx][0] = final_pos[0]\n",
        "            candidate_placements_list[idx][1] = final_pos[1]\n",
        "            candidate_placements_list[idx][2] = final_pos[2]\n",
        "\n",
        "            # Combine current cube rotation with cluster rotation\n",
        "            current_cube_rot = R.from_euler('xyz', candidate_placements_list[idx][3:6], degrees=True)\n",
        "            new_cube_rot_obj = cluster_rot_obj * current_cube_rot # Apply cluster rot, then cube's own\n",
        "            new_angles = new_cube_rot_obj.as_euler('xyz', degrees=True)\n",
        "            candidate_placements_list[idx][3] = normalize_angle(new_angles[0])\n",
        "            candidate_placements_list[idx][4] = normalize_angle(new_angles[1])\n",
        "            candidate_placements_list[idx][5] = normalize_angle(new_angles[2])\n",
        "        logging.debug(f\"Rigid Sub-Cluster Transformation applied to {cluster_size} cubes.\")\n",
        "\n",
        "    elif mutation_choice == 'cohesive_force_mutation':\n",
        "        if num_cubes == 0: continue\n",
        "        current_centroid = get_centroid([tuple(p) for p in candidate_placements_list])\n",
        "        for i in range(num_cubes):\n",
        "            pos_vec = np.array(candidate_placements_list[i][:3])\n",
        "            direction_vector = current_centroid - pos_vec\n",
        "            dist = np.linalg.norm(direction_vector)\n",
        "            if dist \u003e 1e-9: # Avoid division by zero for cube at centroid\n",
        "                normalized_direction = direction_vector / dist\n",
        "                # Move magnitude scales with pos_std and also with current distance (for stronger pull on outliers)\n",
        "                # Max 0.5 * pos_std to keep it gentle. Clamp to avoid overshooting.\n",
        "                move_magnitude = np.random.normal(0, pos_std * 0.5)\n",
        "                move_magnitude = np.clip(move_magnitude, -0.1, 0.1) # Prevent too large steps\n",
        "\n",
        "                candidate_placements_list[i][0] += normalized_direction[0] * move_magnitude\n",
        "                candidate_placements_list[i][1] += normalized_direction[1] * move_magnitude\n",
        "                candidate_placements_list[i][2] += normalized_direction[2] * move_magnitude\n",
        "        logging.debug(\"Cohesive Force (Simulated Gravity) mutation applied.\")\n",
        "    elif mutation_choice == 'stochastic_relocation_mutation':\n",
        "        if num_cubes == 0: continue\n",
        "        # Estimate current bounding box side length from best_score, or a fallback\n",
        "        current_side_length_estimate = -best_score if best_score \u003e -1000 else 2.0 * math.ceil(num_cubes**(1/3.0))\n",
        "        relocation_range_half = current_side_length_estimate * 0.75 # Allow a bit beyond current bounds for exploration\n",
        "\n",
        "        # Select 1 to N/4 cubes for aggressive relocation\n",
        "        num_to_relocate = np.random.randint(1, max(2, num_cubes // 4 + 1))\n",
        "        indices_to_relocate = np.random.choice(num_cubes, num_to_relocate, replace=False)\n",
        "\n",
        "        for idx in indices_to_relocate:\n",
        "            # Completely randomize position within the estimated bounding box range\n",
        "            candidate_placements_list[idx][0] = np.random.uniform(-relocation_range_half, relocation_range_half)\n",
        "            candidate_placements_list[idx][1] = np.random.uniform(-relocation_range_half, relocation_range_half)\n",
        "            candidate_placements_list[idx][2] = np.random.uniform(-relocation_range_half, relocation_range_half)\n",
        "\n",
        "            # Randomize angles or snap them to strategic ones with noise\n",
        "            if np.random.rand() \u003c 0.7: # 70% chance to pick a strategic angle with noise\n",
        "                ax = normalize_angle(snap_angle_to_nearest_optimal(np.random.uniform(0, 360)) + np.random.normal(0, angle_std * 0.1))\n",
        "                ay = normalize_angle(snap_angle_to_nearest_optimal(np.random.uniform(0, 360)) + np.random.normal(0, angle_std * 0.1))\n",
        "                az = normalize_angle(snap_angle_to_nearest_optimal(np.random.uniform(0, 360)) + np.random.normal(0, angle_std * 0.1))\n",
        "            else: # 30% chance for completely random angle\n",
        "                ax = normalize_angle(np.random.uniform(0, 360))\n",
        "                ay = normalize_angle(np.random.uniform(0, 360))\n",
        "                az = normalize_angle(np.random.uniform(0, 360))\n",
        "\n",
        "            candidate_placements_list[idx][3] = ax\n",
        "            candidate_placements_list[idx][4] = ay\n",
        "            candidate_placements_list[idx][5] = az\n",
        "        logging.debug(f\"Stochastic Relocation mutation applied to {num_to_relocate} cubes.\")\n",
        "    elif mutation_choice == 'layer_shift_mutation':\n",
        "        if num_cubes \u003c 2: continue # Needs at least 2 cubes for a layer shift\n",
        "\n",
        "        axis = np.random.randint(0, 3) # 0:X, 1:Y, 2:Z\n",
        "\n",
        "        # Find min/max for the chosen axis to determine a reasonable split point\n",
        "        axis_coords = [p[axis] for p in candidate_placements_list]\n",
        "        min_coord = min(axis_coords)\n",
        "        max_coord = max(axis_coords)\n",
        "\n",
        "        # Choose a random split point along the axis. Bias towards central splits.\n",
        "        # Ensure split_point is not too close to min/max to ensure both sides have cubes.\n",
        "        # A 0.1 buffer on min/max should be enough.\n",
        "        if max_coord - min_coord \u003c 0.2: # If spread is too small, no meaningful split\n",
        "            split_point = (min_coord + max_coord) / 2.0\n",
        "        else:\n",
        "            split_point = np.random.uniform(min_coord + 0.1, max_coord - 0.1)\n",
        "\n",
        "        # Determine the shift direction and magnitude\n",
        "        # Shift can be along one of the two other axes, or along the same axis (compaction/expansion)\n",
        "        possible_shift_axes = [0, 1, 2]\n",
        "        shift_axis_idx = np.random.choice(possible_shift_axes)\n",
        "\n",
        "        shift_magnitude = np.random.normal(0, pos_std * 0.75) # Use pos_std as base for magnitude\n",
        "        shift_magnitude = np.clip(shift_magnitude, -0.2, 0.2) # Limit the shift magnitude to prevent huge jumps\n",
        "\n",
        "        moved_cubes_count = 0\n",
        "        for i in range(num_cubes):\n",
        "            if candidate_placements_list[i][axis] \u003e split_point:\n",
        "                candidate_placements_list[i][shift_axis_idx] += shift_magnitude\n",
        "                moved_cubes_count += 1\n",
        "\n",
        "        if moved_cubes_count == 0 or moved_cubes_count == num_cubes:\n",
        "            # If no cubes moved or all cubes moved, it means the split didn't create two meaningful groups.\n",
        "            # While SA can filter this out, we can make it more explicit that this specific mutation\n",
        "            # might not have been effective for this split. For simplicity, we just log and proceed.\n",
        "            pass\n",
        "\n",
        "        logging.debug(f\"Layer Shift mutation applied along axis {axis} for {moved_cubes_count} cubes with shift {shift_magnitude:.3f} along axis {shift_axis_idx}.\")\n",
        "    elif mutation_choice == 'crystalline_shear_mutation':\n",
        "        if num_cubes \u003c 2: continue\n",
        "\n",
        "        # 1. Choose a shear plane axis (X, Y, or Z)\n",
        "        shear_axis_idx = np.random.randint(0, 3) # 0:X, 1:Y, 2:Z\n",
        "\n",
        "        # 2. Determine a random split point along this axis\n",
        "        axis_coords = np.array([p[shear_axis_idx] for p in candidate_placements_list])\n",
        "        min_coord, max_coord = np.min(axis_coords), np.max(axis_coords)\n",
        "\n",
        "        if max_coord - min_coord \u003c 0.2: # If spread is too small for a meaningful split\n",
        "            split_point = (min_coord + max_coord) / 2.0\n",
        "        else:\n",
        "            # Bias split point towards center, but still random. Use a normal dist around mean.\n",
        "            mean_coord = np.mean(axis_coords)\n",
        "            std_coord = np.std(axis_coords)\n",
        "            # Ensure split point is within reasonable bounds\n",
        "            split_point = np.random.normal(mean_coord, std_coord * 0.5)\n",
        "            split_point = np.clip(split_point, min_coord - 0.5, max_coord + 0.5) # Allow some extension\n",
        "\n",
        "        # 3. Determine the shear vector (translation) and shear rotation (around shear_axis_idx)\n",
        "        # The shear translation is in the plane perpendicular to the shear_axis_idx\n",
        "\n",
        "        other_axes = [i for i in [0, 1, 2] if i != shear_axis_idx]\n",
        "\n",
        "        shear_trans_magnitude = np.random.normal(0, pos_std * 0.75) # Positional shift\n",
        "        shear_trans_magnitude = np.clip(shear_trans_magnitude, -0.2, 0.2) # Limit magnitude\n",
        "\n",
        "        # Shear translation vector is along one of the other axes, or a combination\n",
        "        shear_vector = np.zeros(3)\n",
        "        # Randomly choose one of the two perpendicular axes for the primary shift direction\n",
        "        shear_vector[random.choice(other_axes)] = shear_trans_magnitude\n",
        "\n",
        "        # Shear rotation: rotation around the shear_axis_idx\n",
        "        shear_rot_angle = np.random.normal(0, angle_std * 0.5) # Angular shift\n",
        "        shear_rot_angle = np.clip(shear_rot_angle, -10.0, 10.0) # Limit rotation magnitude\n",
        "\n",
        "        # Create a rotation object for the shear rotation\n",
        "        shear_rot_euler = np.zeros(3)\n",
        "        shear_rot_euler[shear_axis_idx] = shear_rot_angle\n",
        "        shear_rot_obj = R.from_euler('xyz', shear_rot_euler, degrees=True)\n",
        "\n",
        "        # 4. Apply transformation to cubes on one side of the split plane\n",
        "        moved_cubes_count = 0\n",
        "\n",
        "        # Determine the \"reference point\" for rotation and translation, typically the split plane's center\n",
        "        shear_reference_point = np.array([0.0, 0.0, 0.0])\n",
        "        shear_reference_point[shear_axis_idx] = split_point\n",
        "\n",
        "        for i in range(num_cubes):\n",
        "            if candidate_placements_list[i][shear_axis_idx] \u003e split_point: # Move cubes on one side\n",
        "                # Translate position relative to the shear reference point, then rotate, then add back reference + shear vector\n",
        "                pos_vec = np.array(candidate_placements_list[i][:3])\n",
        "                pos_relative_to_ref = pos_vec - shear_reference_point\n",
        "                rotated_pos_relative = shear_rot_obj.apply(pos_relative_to_ref)\n",
        "                final_pos = rotated_pos_relative + shear_reference_point + shear_vector\n",
        "\n",
        "                candidate_placements_list[i][0] = final_pos[0]\n",
        "                candidate_placements_list[i][1] = final_pos[1]\n",
        "                candidate_placements_list[i][2] = final_pos[2]\n",
        "\n",
        "                # Combine cube's own rotation with shear rotation\n",
        "                current_cube_rot = R.from_euler('xyz', candidate_placements_list[i][3:6], degrees=True)\n",
        "                new_cube_rot_obj = shear_rot_obj * current_cube_rot\n",
        "                new_angles = new_cube_rot_obj.as_euler('xyz', degrees=True)\n",
        "                candidate_placements_list[i][3] = normalize_angle(new_angles[0])\n",
        "                candidate_placements_list[i][4] = normalize_angle(new_angles[1])\n",
        "                candidate_placements_list[i][5] = normalize_angle(new_angles[2])\n",
        "\n",
        "                moved_cubes_count += 1\n",
        "\n",
        "        logging.debug(f\"Crystalline Shear mutation applied along axis {shear_axis_idx} for {moved_cubes_count} cubes.\")\n",
        "    elif mutation_choice == 'quantum_leap_mutation':\n",
        "        if num_cubes == 0: continue\n",
        "\n",
        "        # Select a random subset of cubes for the \"quantum leap\"\n",
        "        # Number of cubes to affect: between 1 and N/3, but at least 1.\n",
        "        num_to_affect = np.random.randint(1, max(2, num_cubes // 3 + 1))\n",
        "        indices_to_affect = np.random.choice(num_cubes, num_to_affect, replace=False)\n",
        "\n",
        "        # Get the centroid of the selected subset for rigid transformation\n",
        "        subset_positions = np.array([candidate_placements_list[idx][:3] for idx in indices_to_affect])\n",
        "        if len(subset_positions) == 0: continue\n",
        "        subset_centroid = np.mean(subset_positions, axis=0)\n",
        "\n",
        "        # Apply a random *global* transformation (translation + rotation) to the subset\n",
        "        # This translation can be significant. Scale by an estimate of the current packing size.\n",
        "        current_side_length_estimate = -best_score if best_score \u003e -1000 else 2.0 * math.ceil(num_cubes**(1/3.0))\n",
        "        # Larger translation for early stages, smaller later\n",
        "        leap_pos_std = current_side_length_estimate * (0.5 - 0.4 * elapsed_time_ratio)\n",
        "        leap_angle_std = 90.0 * (0.5 - 0.4 * elapsed_time_ratio) # Large angle shift\n",
        "\n",
        "        trans_offset = np.random.normal(0, leap_pos_std, 3)\n",
        "        rot_angles = np.random.normal(0, leap_angle_std, 3)\n",
        "        leap_rot_obj = R.from_euler('xyz', rot_angles, degrees=True)\n",
        "\n",
        "        for idx in indices_to_affect:\n",
        "            # Apply rigid transformation\n",
        "            pos_vec = np.array(candidate_placements_list[idx][:3])\n",
        "            pos_relative_to_subset_centroid = pos_vec - subset_centroid\n",
        "            rotated_pos_relative = leap_rot_obj.apply(pos_relative_to_subset_centroid)\n",
        "            final_pos = rotated_pos_relative + subset_centroid + trans_offset\n",
        "\n",
        "            candidate_placements_list[idx][0] = final_pos[0]\n",
        "            candidate_placements_list[idx][1] = final_pos[1]\n",
        "            candidate_placements_list[idx][2] = final_pos[2]\n",
        "\n",
        "            # Re-project angles to be near optimal/strategic ones, with noise\n",
        "            # Instead of just adding noise to current angles, re-initialize them strategically\n",
        "            chosen_snap_angle_x = snap_angle_to_nearest_optimal(np.random.uniform(0, 360))\n",
        "            chosen_snap_angle_y = snap_angle_to_nearest_optimal(np.random.uniform(0, 360))\n",
        "            chosen_snap_angle_z = snap_angle_to_nearest_optimal(np.random.uniform(0, 360))\n",
        "\n",
        "            # Apply a small amount of annealed angle_std noise\n",
        "            candidate_placements_list[idx][3] = normalize_angle(chosen_snap_angle_x + np.random.normal(0, angle_std * 0.1))\n",
        "            candidate_placements_list[idx][4] = normalize_angle(chosen_snap_angle_y + np.random.normal(0, angle_std * 0.1))\n",
        "            candidate_placements_list[idx][5] = normalize_angle(chosen_snap_angle_z + np.random.normal(0, angle_std * 0.1))\n",
        "\n",
        "        logging.debug(f\"Quantum Leap mutation applied to {num_to_affect} cubes.\")\n",
        "\n",
        "    else: # 'individual_perturbation' is the fallback, but now it's explicit in probabilities\n",
        "        # This branch should ideally not be hit if probabilities sum to 1 and all choices are covered.\n",
        "        # But for safety, keep it as the last-resort default.\n",
        "        if num_cubes == 0: continue\n",
        "        idx_to_mutate = np.random.randint(0, num_cubes)\n",
        "        candidate_placements_list[idx_to_mutate][0] += np.random.normal(0, pos_std)\n",
        "        candidate_placements_list[idx_to_mutate][1] += np.random.normal(0, pos_std)\n",
        "        candidate_placements_list[idx_to_mutate][2] += np.random.normal(0, pos_std)\n",
        "        for i in range(3, 6):\n",
        "            candidate_placements_list[idx_to_mutate][i] = normalize_angle(candidate_placements_list[idx_to_mutate][i] + np.random.normal(0, angle_std))\n",
        "\n",
        "    # Ensure all angles are within [0, 360) after all mutations\n",
        "    for i in range(num_cubes):\n",
        "        for j in range(3, 6):\n",
        "            candidate_placements_list[i][j] = normalize_angle(candidate_placements_list[i][j])\n",
        "\n",
        "    # Convert to tuple list for scoring and squeezing\n",
        "    candidate_placements_tuple = [tuple(p) for p in candidate_placements_list]\n",
        "\n",
        "    candidate_score, fixed_candidate_placements = calculate_packing_score_cubes_3d(\n",
        "        candidate_placements_tuple, num_cubes\n",
        "    )\n",
        "    candidate_placements_tuple = [tuple(p) for p in fixed_candidate_placements] # Use the fixed version\n",
        "    eval_count += 1\n",
        "\n",
        "    # Adaptive Squeezing on Candidate Placements\n",
        "    # Only squeeze if the candidate is already performing well (i.e., better than current_score)\n",
        "    # and occasionally, to give it a chance to improve further before acceptance.\n",
        "    if candidate_score \u003e current_score and np.random.rand() \u003c 0.3: # ~30% chance if candidate is better\n",
        "        squeezed_candidate_tuple = squeeze_placements_3d(\n",
        "            [tuple(item) for item in candidate_placements_tuple],\n",
        "            num_passes=2, # Lighter squeeze for promising candidates\n",
        "            binary_search_iterations=5,\n",
        "        )\n",
        "        if len(squeezed_candidate_tuple) == num_cubes:\n",
        "            squeezed_score, fixed_squeezed_candidate = calculate_packing_score_cubes_3d(\n",
        "                squeezed_candidate_tuple, num_cubes\n",
        "            )\n",
        "            eval_count += 1 # Count this squeeze evaluation\n",
        "            if squeezed_score \u003e candidate_score: # Only use if squeeze actually improved it\n",
        "                candidate_score = squeezed_score\n",
        "                candidate_placements_tuple = [tuple(p) for p in fixed_squeezed_candidate]\n",
        "\n",
        "    # --- Simulated Annealing (SA) Acceptance Criterion ---\n",
        "    # T is already calculated as current_T\n",
        "\n",
        "    accept_move = False\n",
        "    if candidate_score \u003e current_score: # Always accept improvements\n",
        "        accept_move = True\n",
        "    else: # Accept worse solutions with probability\n",
        "        delta_score = candidate_score - current_score # This will be negative\n",
        "        acceptance_prob = np.exp(delta_score / max(current_T, 1e-10)) # Use max with small epsilon to avoid division by zero\n",
        "        accept_move = np.random.rand() \u003c acceptance_prob\n",
        "\n",
        "    if accept_move:\n",
        "        current_score = candidate_score\n",
        "        # The 'fixed_candidate_placements' from calculate_packing_score_cubes_3d are generally recentered.\n",
        "        # So no explicit recentering is needed here.\n",
        "        current_placements_tuple = copy.deepcopy(candidate_placements_tuple)\n",
        "\n",
        "        # If the accepted solution is also the overall best found so far\n",
        "        if current_score \u003e best_score:\n",
        "            best_score = current_score\n",
        "            # best_placements should also be fixed by calculate_packing_score_cubes_3d\n",
        "            best_placements = copy.deepcopy(current_placements_tuple)\n",
        "            last_best_score_update_eval = eval_count # Update stagnation tracker\n",
        "            logging.info(\n",
        "                f'New best score: {best_score}, side: {-best_score if best_score \u003e -1000 else \"N/A\"}, evals: {eval_count}, Temp: {current_T:.4f}'\n",
        "            )\n",
        "            # Aggressively squeeze the new best configuration, same intensity as initial strategies\n",
        "            squeezed_best_tuple = squeeze_placements_3d(\n",
        "                [tuple(item) for item in best_placements],\n",
        "                num_passes=20, # Increased\n",
        "                binary_search_iterations=40, # Increased\n",
        "            )\n",
        "            score_after_squeeze, fixed_squeezed_best = calculate_packing_score_cubes_3d(\n",
        "                squeezed_best_tuple, num_cubes\n",
        "            )\n",
        "            eval_count += 1 # Count this evaluation too\n",
        "            logging.info(f'Score after squeeze (on best): {score_after_squeeze}')\n",
        "            if score_after_squeeze \u003e best_score: # Only update if squeeze truly improved\n",
        "                best_score = score_after_squeeze\n",
        "                best_placements = copy.deepcopy(fixed_squeezed_best)\n",
        "                current_placements_tuple = copy.deepcopy(fixed_squeezed_best)\n",
        "                last_best_score_update_eval = eval_count # Update stagnation tracker again if squeeze improved\n",
        "\n",
        "  logging.info(f'Final score: {best_score}, side: {-best_score}')\n",
        "  logging.info(f'Total Evaluations: {eval_count}')\n",
        "  return best_placements\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Dgf7P0JFfC_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "46-U096rrlU-"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
